{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3e1afc-bc5d-4658-a1b0-2b39e87f9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91d32ddb-b9a8-484c-9ba2-9d4a5a754766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- SCIANN 0.6.4.5 ---------------------- \n",
      "For details, check out our review paper and the documentation at: \n",
      " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
      " +  \"https://arxiv.org/abs/2005.08803\", \n",
      " +  \"https://www.sciann.com\". \n",
      "\n",
      " Need support or would like to contribute, please join sciann`s slack group: \n",
      " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
      " \n",
      "TensorFlow Version: 2.3.0 \n",
      "Python Version: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "\n",
    "import System as SEQ\n",
    "%run flow_EQS.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1ea70e-865b-4792-8d73-485603c7c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pinn_Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac20dc32-5471-40f9-a4bc-8296bdd3faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = [['p.txt','u.txt','v.txt'],'wtunnel']\n",
    "\n",
    "\n",
    "test_gridObj = SEQ.Grid(3,{'x':0,'y':1,'t':2},[[[-2,0],[0,1],[0,20]],[[0,18],[-0.5,1],[0,20]]],9)\n",
    "configspecs = {\n",
    "    'denspt':[3,6],\n",
    "    'numNeurons':[10,100],\n",
    "    'numLayers':[2,50],\n",
    "    'activator':['tanh','relu','softmax','sigmoid'],\n",
    "    'loss':['mae','mse'],\n",
    "    'optimizer':['Adam','RMSprop','SGD','Nadam','Ftrl'],\n",
    "    'batch_size':[5000,10000,15000],\n",
    "    'initial_lr':[1e-4,1e-2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "615d3c72-ed31-4564-9d2f-f3dc5c13e975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating worker\n",
      "Creating client\n",
      "Existing experiment. Recovering id.\n",
      "Parsing validation data\n",
      "Applying validation data to test grid\n",
      "Saving PDE and config\n",
      "Worker ready\n",
      "Worker created, starting it\n",
      "Worker running, adding it to the list\n",
      "Worker added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:14:01 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x21381d68b88; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "23:14:01 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "23:14:01 WORKER: start listening for jobs\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Start a nameserver\n",
    "# Every run needs a nameserver. It could be a 'static' server with a\n",
    "# permanent address, but here it will be started for the local machine with the default port.\n",
    "# The nameserver manages the concurrent running workers across all possible threads or clusternodes.\n",
    "# Note the run_id argument. This uniquely identifies a run of any HpBandSter optimizer.\n",
    "\n",
    "numWorkers = 1\n",
    "experiment_name = 'flow_exp'\n",
    "run_id = 'flow_GridSearch'\n",
    "\n",
    "NS = hpns.NameServer(run_id=run_id, host='127.0.0.1', port=None)\n",
    "NS.start()\n",
    "\n",
    "# Step 2: Start a worker\n",
    "# Now we can instantiate a worker, providing the mandatory information\n",
    "# Besides the sleep_interval, we need to define the nameserver information and\n",
    "# the same run_id as above. After that, we can start the worker in the background,\n",
    "# where it will wait for incoming configurations to evaluate.\n",
    "\n",
    "\n",
    "workers=[]\n",
    "for i in range(1,numWorkers+1):\n",
    "    print('Creating worker')\n",
    "    w = Pinn_Worker.PINN_Worker(\n",
    "    valData = valData,\n",
    "    test_gridObj=test_gridObj,\n",
    "    PDESystem=mySys,\n",
    "    configspecs = configspecs,\n",
    "    valFromFEM=True,\n",
    "    experiment_name = experiment_name,\n",
    "    eval_mode = 'parameter',\n",
    "    valParams = {'rey':0.0025},\n",
    "    eval_functionals = ['p','u','v'],\n",
    "    nameserver='127.0.0.1',\n",
    "    run_id=run_id,\n",
    "    id=i)\n",
    "    \n",
    "    print('Worker created, starting it')\n",
    "    w.run(background=True)\n",
    "    print('Worker running, adding it to the list')\n",
    "    workers.append(w)\n",
    "    print('Worker added')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093e932-724c-452d-a8e8-7e907382aeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:14:25 wait_for_workers trying to get the condition\n",
      "23:14:25 DISPATCHER: started the 'discover_worker' thread\n",
      "23:14:25 DISPATCHER: started the 'job_runner' thread\n",
      "23:14:25 DISPATCHER: Pyro daemon running on localhost:58320\n",
      "23:14:25 DISPATCHER: Starting worker discovery\n",
      "23:14:25 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "23:14:25 DISPATCHER: discovered new worker, hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:14:25 HBMASTER: number of workers changed to 1\n",
      "23:14:25 Enough workers to start this run!\n",
      "23:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:14:25 adjust_queue_size: lock accquired\n",
      "23:14:25 HBMASTER: starting run at 1648415665.8825176\n",
      "23:14:25 HBMASTER: adjusted queue size to (0, 1)\n",
      "23:14:25 DISPATCHER: Finished worker discovery\n",
      "23:14:25 start sampling a new configuration.\n",
      "23:14:25 done sampling a new configuration.\n",
      "23:14:25 DISPATCHER: Trying to submit another job.\n",
      "23:14:25 HBMASTER: schedule new run for iteration 0\n",
      "23:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:14:25 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "23:14:25 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "23:14:25 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "23:14:25 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:14:25 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "23:14:25 DISPATCHER: Trying to submit another job.\n",
      "23:14:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:14:25 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:14:25 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:14:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:14:25 WORKER: start processing job (0, 0, 0)\n",
      "23:14:25 WORKER: args: ()\n",
      "23:14:25 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.004942500871467096, 'loss': 'mse', 'numLayers': 48, 'numNeurons': 47, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 15000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:15:25 DISPATCHER: Starting worker discovery\n",
      "23:15:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:15:25 DISPATCHER: Finished worker discovery\n",
      "23:16:25 DISPATCHER: Starting worker discovery\n",
      "23:16:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:16:25 DISPATCHER: Finished worker discovery\n",
      "23:16:48 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "23:16:48 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "23:16:48 DISPATCHER: job (0, 0, 0) finished\n",
      "23:16:48 DISPATCHER: register_result: lock acquired\n",
      "23:16:48 DISPATCHER: job (0, 0, 0) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:16:48 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.004942500871467096, 'loss': 'mse', 'numLayers': 48, 'numNeurons': 47, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:16:48 job_callback for (0, 0, 0) started\n",
      "23:16:48 job_callback for (0, 0, 0) got condition\n",
      "23:16:48 DISPATCHER: Trying to submit another job.\n",
      "23:16:48 job (0, 0, 0) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:16:48 Only 1 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:16:48 HBMASTER: Trying to run another job!\n",
      "23:16:48 job_callback for (0, 0, 0) finished\n",
      "23:16:48 start sampling a new configuration.\n",
      "23:16:48 done sampling a new configuration.\n",
      "23:16:48 HBMASTER: schedule new run for iteration 0\n",
      "23:16:48 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "23:16:48 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "23:16:48 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "23:16:48 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:16:48 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "23:16:48 DISPATCHER: Trying to submit another job.\n",
      "23:16:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:16:48 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:16:48 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:16:48 WORKER: start processing job (0, 0, 1)\n",
      "23:16:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:16:48 WORKER: args: ()\n",
      "23:16:48 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0011765460994350027, 'loss': 'mae', 'numLayers': 31, 'numNeurons': 49, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 15000 \n",
      "Total batches: 9 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:17:25 DISPATCHER: Starting worker discovery\n",
      "23:17:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:17:25 DISPATCHER: Finished worker discovery\n",
      "23:18:13 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "23:18:13 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "23:18:13 DISPATCHER: job (0, 0, 1) finished\n",
      "23:18:13 DISPATCHER: register_result: lock acquired\n",
      "23:18:13 DISPATCHER: job (0, 0, 1) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:18:13 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0011765460994350027, 'loss': 'mae', 'numLayers': 31, 'numNeurons': 49, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:18:13 job_callback for (0, 0, 1) started\n",
      "23:18:13 job_callback for (0, 0, 1) got condition\n",
      "23:18:13 job (0, 0, 1) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:18:13 Only 2 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:18:13 HBMASTER: Trying to run another job!\n",
      "23:18:13 job_callback for (0, 0, 1) finished\n",
      "23:18:13 DISPATCHER: Trying to submit another job.\n",
      "23:18:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:18:13 start sampling a new configuration.\n",
      "23:18:13 done sampling a new configuration.\n",
      "23:18:13 HBMASTER: schedule new run for iteration 0\n",
      "23:18:13 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "23:18:13 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "23:18:13 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "23:18:13 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:18:13 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "23:18:13 DISPATCHER: Trying to submit another job.\n",
      "23:18:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:18:13 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:13 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:18:13 WORKER: start processing job (0, 0, 2)\n",
      "23:18:13 WORKER: args: ()\n",
      "23:18:13 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 5, 'initial_lr': 0.0025891297629253456, 'loss': 'mae', 'numLayers': 7, 'numNeurons': 92, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 68000 \n",
      "Batch size: 10000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:18:25 DISPATCHER: Starting worker discovery\n",
      "23:18:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:18:25 DISPATCHER: Finished worker discovery\n",
      "23:18:32 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "23:18:32 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "23:18:32 DISPATCHER: job (0, 0, 2) finished\n",
      "23:18:32 DISPATCHER: register_result: lock acquired\n",
      "23:18:32 DISPATCHER: job (0, 0, 2) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:18:32 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 5, 'initial_lr': 0.0025891297629253456, 'loss': 'mae', 'numLayers': 7, 'numNeurons': 92, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:18:32 job_callback for (0, 0, 2) started\n",
      "23:18:32 job_callback for (0, 0, 2) got condition\n",
      "23:18:32 job (0, 0, 2) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:18:32 Only 3 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:18:32 HBMASTER: Trying to run another job!\n",
      "23:18:32 job_callback for (0, 0, 2) finished\n",
      "23:18:32 DISPATCHER: Trying to submit another job.\n",
      "23:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:18:32 start sampling a new configuration.\n",
      "23:18:32 done sampling a new configuration.\n",
      "23:18:32 HBMASTER: schedule new run for iteration 0\n",
      "23:18:32 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "23:18:32 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "23:18:32 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "23:18:32 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:18:32 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "23:18:32 DISPATCHER: Trying to submit another job.\n",
      "23:18:32 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:18:32 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:32 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:32 WORKER: start processing job (0, 0, 3)\n",
      "23:18:32 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:18:32 WORKER: args: ()\n",
      "23:18:32 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.006512280008971278, 'loss': 'mse', 'numLayers': 11, 'numNeurons': 48, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 15000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:18:46 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "23:18:46 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "23:18:46 DISPATCHER: job (0, 0, 3) finished\n",
      "23:18:46 DISPATCHER: register_result: lock acquired\n",
      "23:18:46 DISPATCHER: job (0, 0, 3) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:18:46 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.006512280008971278, 'loss': 'mse', 'numLayers': 11, 'numNeurons': 48, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:18:46 job_callback for (0, 0, 3) started\n",
      "23:18:46 job_callback for (0, 0, 3) got condition\n",
      "23:18:46 job (0, 0, 3) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:18:46 Only 4 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:18:46 HBMASTER: Trying to run another job!\n",
      "23:18:46 job_callback for (0, 0, 3) finished\n",
      "23:18:46 DISPATCHER: Trying to submit another job.\n",
      "23:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:18:46 start sampling a new configuration.\n",
      "23:18:46 done sampling a new configuration.\n",
      "23:18:46 HBMASTER: schedule new run for iteration 0\n",
      "23:18:46 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "23:18:46 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "23:18:46 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "23:18:46 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:18:46 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "23:18:46 DISPATCHER: Trying to submit another job.\n",
      "23:18:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:18:46 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:46 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:18:46 WORKER: start processing job (0, 0, 4)\n",
      "23:18:46 WORKER: args: ()\n",
      "23:18:46 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 6, 'initial_lr': 0.007239031521053674, 'loss': 'mse', 'numLayers': 33, 'numNeurons': 95, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "23:19:25 DISPATCHER: Starting worker discovery\n",
      "23:19:25 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:19:26 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 10000 \n",
      "Total batches: 13 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:20:26 DISPATCHER: Starting worker discovery\n",
      "23:20:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:20:26 DISPATCHER: Finished worker discovery\n",
      "23:21:26 DISPATCHER: Starting worker discovery\n",
      "23:21:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:21:26 DISPATCHER: Finished worker discovery\n",
      "23:21:33 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "23:21:33 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "23:21:33 DISPATCHER: job (0, 0, 4) finished\n",
      "23:21:33 DISPATCHER: register_result: lock acquired\n",
      "23:21:33 DISPATCHER: job (0, 0, 4) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:21:33 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 6, 'initial_lr': 0.007239031521053674, 'loss': 'mse', 'numLayers': 33, 'numNeurons': 95, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:21:33 job_callback for (0, 0, 4) started\n",
      "23:21:33 DISPATCHER: Trying to submit another job.\n",
      "23:21:33 job_callback for (0, 0, 4) got condition\n",
      "23:21:33 job (0, 0, 4) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:21:33 Only 5 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:21:33 HBMASTER: Trying to run another job!\n",
      "23:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:21:33 job_callback for (0, 0, 4) finished\n",
      "23:21:33 start sampling a new configuration.\n",
      "23:21:33 done sampling a new configuration.\n",
      "23:21:33 HBMASTER: schedule new run for iteration 0\n",
      "23:21:33 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "23:21:33 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "23:21:33 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "23:21:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:21:33 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "23:21:33 DISPATCHER: Trying to submit another job.\n",
      "23:21:33 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:21:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:21:33 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:21:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:21:33 WORKER: start processing job (0, 0, 5)\n",
      "23:21:33 WORKER: args: ()\n",
      "23:21:33 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.008348733579790723, 'loss': 'mse', 'numLayers': 46, 'numNeurons': 73, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 15000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:22:26 DISPATCHER: Starting worker discovery\n",
      "23:22:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:22:26 DISPATCHER: Finished worker discovery\n",
      "23:22:27 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "23:22:27 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "23:22:27 DISPATCHER: job (0, 0, 5) finished\n",
      "23:22:27 DISPATCHER: register_result: lock acquired\n",
      "23:22:27 DISPATCHER: job (0, 0, 5) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:22:27 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 4, 'initial_lr': 0.008348733579790723, 'loss': 'mse', 'numLayers': 46, 'numNeurons': 73, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:22:27 job_callback for (0, 0, 5) started\n",
      "23:22:27 DISPATCHER: Trying to submit another job.\n",
      "23:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:22:27 job_callback for (0, 0, 5) got condition\n",
      "23:22:27 job (0, 0, 5) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:22:27 Only 6 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:22:27 HBMASTER: Trying to run another job!\n",
      "23:22:27 job_callback for (0, 0, 5) finished\n",
      "23:22:27 start sampling a new configuration.\n",
      "23:22:27 done sampling a new configuration.\n",
      "23:22:27 HBMASTER: schedule new run for iteration 0\n",
      "23:22:27 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "23:22:27 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "23:22:27 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "23:22:27 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:22:27 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "23:22:27 DISPATCHER: Trying to submit another job.\n",
      "23:22:27 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:22:27 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:22:27 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:22:27 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:22:27 WORKER: start processing job (0, 0, 6)\n",
      "23:22:27 WORKER: args: ()\n",
      "23:22:27 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 3, 'initial_lr': 0.007421442299689945, 'loss': 'mae', 'numLayers': 36, 'numNeurons': 86, 'optimizer': 'Nadam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 14040 \n",
      "Batch size: 10000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:23:26 DISPATCHER: Starting worker discovery\n",
      "23:23:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:23:26 DISPATCHER: Finished worker discovery\n",
      "23:24:26 DISPATCHER: Starting worker discovery\n",
      "23:24:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:24:26 DISPATCHER: Finished worker discovery\n",
      "23:25:26 DISPATCHER: Starting worker discovery\n",
      "23:25:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:25:26 DISPATCHER: Finished worker discovery\n",
      "23:25:40 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "23:25:40 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "23:25:40 DISPATCHER: job (0, 0, 6) finished\n",
      "23:25:40 DISPATCHER: register_result: lock acquired\n",
      "23:25:40 DISPATCHER: job (0, 0, 6) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:25:40 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 3, 'initial_lr': 0.007421442299689945, 'loss': 'mae', 'numLayers': 36, 'numNeurons': 86, 'optimizer': 'Nadam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:25:40 job_callback for (0, 0, 6) started\n",
      "23:25:40 job_callback for (0, 0, 6) got condition\n",
      "23:25:40 job (0, 0, 6) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:25:40 Only 7 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:25:40 HBMASTER: Trying to run another job!\n",
      "23:25:40 job_callback for (0, 0, 6) finished\n",
      "23:25:40 DISPATCHER: Trying to submit another job.\n",
      "23:25:40 start sampling a new configuration.\n",
      "23:25:40 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:25:40 done sampling a new configuration.\n",
      "23:25:40 HBMASTER: schedule new run for iteration 0\n",
      "23:25:40 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "23:25:40 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "23:25:40 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "23:25:40 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:25:40 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "23:25:40 DISPATCHER: Trying to submit another job.\n",
      "23:25:40 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:25:40 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:25:40 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:25:40 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:25:40 WORKER: start processing job (0, 0, 7)\n",
      "23:25:40 WORKER: args: ()\n",
      "23:25:40 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 4, 'initial_lr': 0.006971304830026456, 'loss': 'mae', 'numLayers': 6, 'numNeurons': 42, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 10000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:12 WORKER: done with job (0, 0, 7), trying to register it.\n",
      "23:26:12 WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "23:26:12 DISPATCHER: job (0, 0, 7) finished\n",
      "23:26:12 DISPATCHER: register_result: lock acquired\n",
      "23:26:12 DISPATCHER: job (0, 0, 7) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:26:12 job_id: (0, 0, 7)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 4, 'initial_lr': 0.006971304830026456, 'loss': 'mae', 'numLayers': 6, 'numNeurons': 42, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:26:12 job_callback for (0, 0, 7) started\n",
      "23:26:12 DISPATCHER: Trying to submit another job.\n",
      "23:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:26:12 job_callback for (0, 0, 7) got condition\n",
      "23:26:12 job (0, 0, 7) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:26:12 Only 8 run(s) for budget 18.518519 available, need more than 10 -> can't build model!\n",
      "23:26:12 HBMASTER: Trying to run another job!\n",
      "23:26:12 job_callback for (0, 0, 7) finished\n",
      "23:26:12 start sampling a new configuration.\n",
      "23:26:12 done sampling a new configuration.\n",
      "23:26:12 HBMASTER: schedule new run for iteration 0\n",
      "23:26:12 HBMASTER: trying submitting job (0, 0, 8) to dispatcher\n",
      "23:26:12 HBMASTER: submitting job (0, 0, 8) to dispatcher\n",
      "23:26:12 DISPATCHER: trying to submit job (0, 0, 8)\n",
      "23:26:12 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:26:12 HBMASTER: job (0, 0, 8) submitted to dispatcher\n",
      "23:26:12 DISPATCHER: Trying to submit another job.\n",
      "23:26:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:26:12 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:26:12 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:26:12 WORKER: start processing job (0, 0, 8)\n",
      "23:26:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:26:12 WORKER: args: ()\n",
      "23:26:12 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 5, 'initial_lr': 0.0015486159236801783, 'loss': 'mse', 'numLayers': 24, 'numNeurons': 77, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 68000 \n",
      "Batch size: 15000 \n",
      "Total batches: 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:26:26 DISPATCHER: Starting worker discovery\n",
      "23:26:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:26:26 DISPATCHER: Finished worker discovery\n",
      "23:26:41 WORKER: done with job (0, 0, 8), trying to register it.\n",
      "23:26:41 WORKER: registered result for job (0, 0, 8) with dispatcher\n",
      "23:26:41 DISPATCHER: job (0, 0, 8) finished\n",
      "23:26:41 DISPATCHER: register_result: lock acquired\n",
      "23:26:41 DISPATCHER: job (0, 0, 8) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:26:41 job_id: (0, 0, 8)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 5, 'initial_lr': 0.0015486159236801783, 'loss': 'mse', 'numLayers': 24, 'numNeurons': 77, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:26:41 job_callback for (0, 0, 8) started\n",
      "23:26:41 DISPATCHER: Trying to submit another job.\n",
      "23:26:41 job_callback for (0, 0, 8) got condition\n",
      "23:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:26:41 job (0, 0, 8) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:26:41 HBMASTER: Trying to run another job!\n",
      "23:26:41 job_callback for (0, 0, 8) finished\n",
      "23:26:41 start sampling a new configuration.\n",
      "23:26:41 done sampling a new configuration.\n",
      "23:26:41 HBMASTER: schedule new run for iteration 0\n",
      "23:26:41 HBMASTER: trying submitting job (0, 0, 9) to dispatcher\n",
      "23:26:41 HBMASTER: submitting job (0, 0, 9) to dispatcher\n",
      "23:26:41 DISPATCHER: trying to submit job (0, 0, 9)\n",
      "23:26:41 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:26:41 HBMASTER: job (0, 0, 9) submitted to dispatcher\n",
      "23:26:41 DISPATCHER: Trying to submit another job.\n",
      "23:26:41 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:26:41 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:26:41 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:26:41 WORKER: start processing job (0, 0, 9)\n",
      "23:26:41 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:26:41 WORKER: args: ()\n",
      "23:26:41 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'initial_lr': 0.004839187608530298, 'loss': 'mse', 'numLayers': 43, 'numNeurons': 52, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 5000 \n",
      "Total batches: 26 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:27:26 DISPATCHER: Starting worker discovery\n",
      "23:27:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:27:26 DISPATCHER: Finished worker discovery\n",
      "23:27:34 WORKER: done with job (0, 0, 9), trying to register it.\n",
      "23:27:34 WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "23:27:34 DISPATCHER: job (0, 0, 9) finished\n",
      "23:27:34 DISPATCHER: register_result: lock acquired\n",
      "23:27:34 DISPATCHER: job (0, 0, 9) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:27:34 job_id: (0, 0, 9)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'initial_lr': 0.004839187608530298, 'loss': 'mse', 'numLayers': 43, 'numNeurons': 52, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:27:34 job_callback for (0, 0, 9) started\n",
      "23:27:34 DISPATCHER: Trying to submit another job.\n",
      "23:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:27:34 job_callback for (0, 0, 9) got condition\n",
      "23:27:34 job (0, 0, 9) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:27:34 HBMASTER: Trying to run another job!\n",
      "23:27:34 job_callback for (0, 0, 9) finished\n",
      "23:27:34 start sampling a new configuration.\n",
      "23:27:34 done sampling a new configuration.\n",
      "23:27:34 HBMASTER: schedule new run for iteration 0\n",
      "23:27:34 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "23:27:34 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "23:27:34 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "23:27:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:27:34 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "23:27:34 DISPATCHER: Trying to submit another job.\n",
      "23:27:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:27:34 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:27:34 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:27:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:27:34 WORKER: start processing job (0, 0, 10)\n",
      "23:27:34 WORKER: args: ()\n",
      "23:27:34 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0005717464741141506, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 48, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 15000 \n",
      "Total batches: 9 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:28:26 DISPATCHER: Starting worker discovery\n",
      "23:28:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:28:26 DISPATCHER: Finished worker discovery\n",
      "23:28:42 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "23:28:42 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "23:28:42 DISPATCHER: job (0, 0, 10) finished\n",
      "23:28:42 DISPATCHER: register_result: lock acquired\n",
      "23:28:42 DISPATCHER: job (0, 0, 10) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:28:42 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0005717464741141506, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 48, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:28:42 job_callback for (0, 0, 10) started\n",
      "23:28:42 job_callback for (0, 0, 10) got condition\n",
      "23:28:42 job (0, 0, 10) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:28:42 DISPATCHER: Trying to submit another job.\n",
      "23:28:42 HBMASTER: Trying to run another job!\n",
      "23:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:28:42 job_callback for (0, 0, 10) finished\n",
      "23:28:42 start sampling a new configuration.\n",
      "23:28:42 done sampling a new configuration.\n",
      "23:28:42 HBMASTER: schedule new run for iteration 0\n",
      "23:28:42 HBMASTER: trying submitting job (0, 0, 11) to dispatcher\n",
      "23:28:42 HBMASTER: submitting job (0, 0, 11) to dispatcher\n",
      "23:28:42 DISPATCHER: trying to submit job (0, 0, 11)\n",
      "23:28:42 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:28:42 HBMASTER: job (0, 0, 11) submitted to dispatcher\n",
      "23:28:42 DISPATCHER: Trying to submit another job.\n",
      "23:28:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:28:42 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:28:42 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:28:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:28:42 WORKER: start processing job (0, 0, 11)\n",
      "23:28:42 WORKER: args: ()\n",
      "23:28:42 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'initial_lr': 0.0027350805517285547, 'loss': 'mae', 'numLayers': 17, 'numNeurons': 62, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 68000 \n",
      "Batch size: 5000 \n",
      "Total batches: 14 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:26 DISPATCHER: Starting worker discovery\n",
      "23:29:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:29:26 DISPATCHER: Finished worker discovery\n",
      "23:29:30 WORKER: done with job (0, 0, 11), trying to register it.\n",
      "23:29:30 WORKER: registered result for job (0, 0, 11) with dispatcher\n",
      "23:29:30 DISPATCHER: job (0, 0, 11) finished\n",
      "23:29:30 DISPATCHER: register_result: lock acquired\n",
      "23:29:30 DISPATCHER: job (0, 0, 11) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:29:30 job_id: (0, 0, 11)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'initial_lr': 0.0027350805517285547, 'loss': 'mae', 'numLayers': 17, 'numNeurons': 62, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:29:30 job_callback for (0, 0, 11) started\n",
      "23:29:30 DISPATCHER: Trying to submit another job.\n",
      "23:29:30 job_callback for (0, 0, 11) got condition\n",
      "23:29:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:29:30 job (0, 0, 11) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:29:30 HBMASTER: Trying to run another job!\n",
      "23:29:30 job_callback for (0, 0, 11) finished\n",
      "23:29:30 start sampling a new configuration.\n",
      "23:29:30 done sampling a new configuration.\n",
      "23:29:30 HBMASTER: schedule new run for iteration 0\n",
      "23:29:30 HBMASTER: trying submitting job (0, 0, 12) to dispatcher\n",
      "23:29:30 HBMASTER: submitting job (0, 0, 12) to dispatcher\n",
      "23:29:30 DISPATCHER: trying to submit job (0, 0, 12)\n",
      "23:29:30 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:29:30 HBMASTER: job (0, 0, 12) submitted to dispatcher\n",
      "23:29:30 DISPATCHER: Trying to submit another job.\n",
      "23:29:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:29:30 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:29:30 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:29:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:29:30 WORKER: start processing job (0, 0, 12)\n",
      "23:29:30 WORKER: args: ()\n",
      "23:29:30 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 3, 'initial_lr': 0.0024260802604358263, 'loss': 'mse', 'numLayers': 20, 'numNeurons': 23, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 14040 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:54 WORKER: done with job (0, 0, 12), trying to register it.\n",
      "23:29:54 WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "23:29:54 DISPATCHER: job (0, 0, 12) finished\n",
      "23:29:54 DISPATCHER: register_result: lock acquired\n",
      "23:29:54 DISPATCHER: job (0, 0, 12) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:29:54 job_id: (0, 0, 12)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 3, 'initial_lr': 0.0024260802604358263, 'loss': 'mse', 'numLayers': 20, 'numNeurons': 23, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:29:54 job_callback for (0, 0, 12) started\n",
      "23:29:54 DISPATCHER: Trying to submit another job.\n",
      "23:29:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:29:54 job_callback for (0, 0, 12) got condition\n",
      "23:29:54 job (0, 0, 12) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:29:54 HBMASTER: Trying to run another job!\n",
      "23:29:54 job_callback for (0, 0, 12) finished\n",
      "23:29:54 start sampling a new configuration.\n",
      "23:29:54 done sampling a new configuration.\n",
      "23:29:54 HBMASTER: schedule new run for iteration 0\n",
      "23:29:54 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "23:29:54 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "23:29:54 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "23:29:54 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:29:54 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "23:29:54 DISPATCHER: Trying to submit another job.\n",
      "23:29:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:29:54 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:29:54 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:29:54 WORKER: start processing job (0, 0, 13)\n",
      "23:29:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:29:54 WORKER: args: ()\n",
      "23:29:54 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 3, 'initial_lr': 0.009356793991164803, 'loss': 'mse', 'numLayers': 19, 'numNeurons': 45, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 14040 \n",
      "Batch size: 10000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:30:26 DISPATCHER: Starting worker discovery\n",
      "23:30:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:30:26 DISPATCHER: Finished worker discovery\n",
      "23:30:52 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "23:30:52 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "23:30:52 DISPATCHER: job (0, 0, 13) finished\n",
      "23:30:52 DISPATCHER: register_result: lock acquired\n",
      "23:30:52 DISPATCHER: job (0, 0, 13) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:30:52 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 3, 'initial_lr': 0.009356793991164803, 'loss': 'mse', 'numLayers': 19, 'numNeurons': 45, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:30:52 job_callback for (0, 0, 13) started\n",
      "23:30:52 DISPATCHER: Trying to submit another job.\n",
      "23:30:52 job_callback for (0, 0, 13) got condition\n",
      "23:30:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:30:52 job (0, 0, 13) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:30:52 HBMASTER: Trying to run another job!\n",
      "23:30:52 job_callback for (0, 0, 13) finished\n",
      "23:30:52 start sampling a new configuration.\n",
      "23:30:52 done sampling a new configuration.\n",
      "23:30:52 HBMASTER: schedule new run for iteration 0\n",
      "23:30:52 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "23:30:52 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "23:30:52 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "23:30:52 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:30:52 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "23:30:52 DISPATCHER: Trying to submit another job.\n",
      "23:30:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:30:52 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:30:52 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:30:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:30:52 WORKER: start processing job (0, 0, 14)\n",
      "23:30:52 WORKER: args: ()\n",
      "23:30:52 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 6, 'initial_lr': 0.008125734876037571, 'loss': 'mse', 'numLayers': 26, 'numNeurons': 59, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 10000 \n",
      "Total batches: 13 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:31:26 DISPATCHER: Starting worker discovery\n",
      "23:31:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:31:26 DISPATCHER: Finished worker discovery\n",
      "23:32:05 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "23:32:05 WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "23:32:05 DISPATCHER: job (0, 0, 14) finished\n",
      "23:32:05 DISPATCHER: register_result: lock acquired\n",
      "23:32:05 DISPATCHER: job (0, 0, 14) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:32:05 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 6, 'initial_lr': 0.008125734876037571, 'loss': 'mse', 'numLayers': 26, 'numNeurons': 59, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:32:05 job_callback for (0, 0, 14) started\n",
      "23:32:05 DISPATCHER: Trying to submit another job.\n",
      "23:32:05 job_callback for (0, 0, 14) got condition\n",
      "23:32:05 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:32:05 job (0, 0, 14) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:32:05 HBMASTER: Trying to run another job!\n",
      "23:32:05 job_callback for (0, 0, 14) finished\n",
      "23:32:05 start sampling a new configuration.\n",
      "23:32:05 done sampling a new configuration.\n",
      "23:32:05 HBMASTER: schedule new run for iteration 0\n",
      "23:32:05 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "23:32:05 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "23:32:05 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "23:32:05 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:32:05 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "23:32:05 DISPATCHER: Trying to submit another job.\n",
      "23:32:05 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:32:05 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:32:05 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:32:05 WORKER: start processing job (0, 0, 15)\n",
      "23:32:05 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:32:06 WORKER: args: ()\n",
      "23:32:06 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 4, 'initial_lr': 0.001257541240275399, 'loss': 'mae', 'numLayers': 40, 'numNeurons': 78, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "23:32:26 DISPATCHER: Starting worker discovery\n",
      "23:32:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:32:26 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 5000 \n",
      "Total batches: 8 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:33:26 DISPATCHER: Starting worker discovery\n",
      "23:33:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:33:26 DISPATCHER: Finished worker discovery\n",
      "23:34:26 DISPATCHER: Starting worker discovery\n",
      "23:34:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:34:26 DISPATCHER: Finished worker discovery\n",
      "23:35:26 DISPATCHER: Starting worker discovery\n",
      "23:35:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:35:26 DISPATCHER: Finished worker discovery\n",
      "23:35:33 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "23:35:33 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "23:35:33 DISPATCHER: job (0, 0, 15) finished\n",
      "23:35:33 DISPATCHER: register_result: lock acquired\n",
      "23:35:33 DISPATCHER: job (0, 0, 15) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:35:33 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 4, 'initial_lr': 0.001257541240275399, 'loss': 'mae', 'numLayers': 40, 'numNeurons': 78, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:35:33 job_callback for (0, 0, 15) started\n",
      "23:35:33 DISPATCHER: Trying to submit another job.\n",
      "23:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:35:33 job_callback for (0, 0, 15) got condition\n",
      "23:35:33 job (0, 0, 15) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:35:33 HBMASTER: Trying to run another job!\n",
      "23:35:33 job_callback for (0, 0, 15) finished\n",
      "23:35:33 start sampling a new configuration.\n",
      "23:35:33 done sampling a new configuration.\n",
      "23:35:33 HBMASTER: schedule new run for iteration 0\n",
      "23:35:33 HBMASTER: trying submitting job (0, 0, 16) to dispatcher\n",
      "23:35:33 HBMASTER: submitting job (0, 0, 16) to dispatcher\n",
      "23:35:33 DISPATCHER: trying to submit job (0, 0, 16)\n",
      "23:35:33 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:35:33 HBMASTER: job (0, 0, 16) submitted to dispatcher\n",
      "23:35:33 DISPATCHER: Trying to submit another job.\n",
      "23:35:33 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:35:33 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:35:33 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:35:33 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:35:33 WORKER: start processing job (0, 0, 16)\n",
      "23:35:33 WORKER: args: ()\n",
      "23:35:33 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'initial_lr': 0.008762433971727176, 'loss': 'mae', 'numLayers': 50, 'numNeurons': 94, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 37120 \n",
      "Batch size: 5000 \n",
      "Total batches: 8 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:36:26 DISPATCHER: Starting worker discovery\n",
      "23:36:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:36:26 DISPATCHER: Finished worker discovery\n",
      "23:37:26 DISPATCHER: Starting worker discovery\n",
      "23:37:26 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:37:26 DISPATCHER: Finished worker discovery\n",
      "23:37:57 WORKER: done with job (0, 0, 16), trying to register it.\n",
      "23:37:57 WORKER: registered result for job (0, 0, 16) with dispatcher\n",
      "23:37:57 DISPATCHER: job (0, 0, 16) finished\n",
      "23:37:57 DISPATCHER: register_result: lock acquired\n",
      "23:37:57 DISPATCHER: job (0, 0, 16) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:37:57 job_id: (0, 0, 16)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'initial_lr': 0.008762433971727176, 'loss': 'mae', 'numLayers': 50, 'numNeurons': 94, 'optimizer': 'SGD'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:37:57 job_callback for (0, 0, 16) started\n",
      "23:37:57 DISPATCHER: Trying to submit another job.\n",
      "23:37:57 job_callback for (0, 0, 16) got condition\n",
      "23:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:37:57 job (0, 0, 16) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:37:57 HBMASTER: Trying to run another job!\n",
      "23:37:57 job_callback for (0, 0, 16) finished\n",
      "23:37:57 start sampling a new configuration.\n",
      "23:37:57 done sampling a new configuration.\n",
      "23:37:57 HBMASTER: schedule new run for iteration 0\n",
      "23:37:57 HBMASTER: trying submitting job (0, 0, 17) to dispatcher\n",
      "23:37:57 HBMASTER: submitting job (0, 0, 17) to dispatcher\n",
      "23:37:57 DISPATCHER: trying to submit job (0, 0, 17)\n",
      "23:37:57 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:37:57 HBMASTER: job (0, 0, 17) submitted to dispatcher\n",
      "23:37:57 DISPATCHER: Trying to submit another job.\n",
      "23:37:57 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:37:57 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:37:57 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:37:57 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:37:57 WORKER: start processing job (0, 0, 17)\n",
      "23:37:57 WORKER: args: ()\n",
      "23:37:57 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0023408003936586323, 'loss': 'mse', 'numLayers': 27, 'numNeurons': 55, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "23:38:43 DISPATCHER: Starting worker discovery\n",
      "23:38:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:38:43 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 15000 \n",
      "Total batches: 9 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:39:43 DISPATCHER: Starting worker discovery\n",
      "23:39:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:39:43 DISPATCHER: Finished worker discovery\n",
      "23:40:24 WORKER: done with job (0, 0, 17), trying to register it.\n",
      "23:40:24 WORKER: registered result for job (0, 0, 17) with dispatcher\n",
      "23:40:24 DISPATCHER: job (0, 0, 17) finished\n",
      "23:40:24 DISPATCHER: register_result: lock acquired\n",
      "23:40:24 DISPATCHER: job (0, 0, 17) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:40:24 job_id: (0, 0, 17)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'initial_lr': 0.0023408003936586323, 'loss': 'mse', 'numLayers': 27, 'numNeurons': 55, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:40:24 job_callback for (0, 0, 17) started\n",
      "23:40:24 DISPATCHER: Trying to submit another job.\n",
      "23:40:24 job_callback for (0, 0, 17) got condition\n",
      "23:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:40:24 job (0, 0, 17) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:40:24 done building a new model for budget 18.518519 based on 9/15 split\n",
      "Best loss for this budget:inf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "23:40:24 HBMASTER: Trying to run another job!\n",
      "23:40:24 job_callback for (0, 0, 17) finished\n",
      "23:40:24 start sampling a new configuration.\n",
      "23:40:24 done sampling a new configuration.\n",
      "23:40:24 HBMASTER: schedule new run for iteration 0\n",
      "23:40:24 HBMASTER: trying submitting job (0, 0, 18) to dispatcher\n",
      "23:40:24 HBMASTER: submitting job (0, 0, 18) to dispatcher\n",
      "23:40:24 DISPATCHER: trying to submit job (0, 0, 18)\n",
      "23:40:24 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:40:24 HBMASTER: job (0, 0, 18) submitted to dispatcher\n",
      "23:40:24 DISPATCHER: Trying to submit another job.\n",
      "23:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:40:24 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:40:24 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:40:24 WORKER: start processing job (0, 0, 18)\n",
      "23:40:24 WORKER: args: ()\n",
      "23:40:24 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'initial_lr': 0.009675537219769513, 'loss': 'mse', 'numLayers': 20, 'numNeurons': 79, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "23:40:43 DISPATCHER: Starting worker discovery\n",
      "23:40:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:40:43 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 125280 \n",
      "Batch size: 5000 \n",
      "Total batches: 26 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:41:43 DISPATCHER: Starting worker discovery\n",
      "23:41:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:41:43 DISPATCHER: Finished worker discovery\n",
      "23:41:50 WORKER: done with job (0, 0, 18), trying to register it.\n",
      "23:41:50 WORKER: registered result for job (0, 0, 18) with dispatcher\n",
      "23:41:50 DISPATCHER: job (0, 0, 18) finished\n",
      "23:41:50 DISPATCHER: register_result: lock acquired\n",
      "23:41:50 DISPATCHER: job (0, 0, 18) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:41:50 job_id: (0, 0, 18)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'initial_lr': 0.009675537219769513, 'loss': 'mse', 'numLayers': 20, 'numNeurons': 79, 'optimizer': 'Adam'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:41:50 job_callback for (0, 0, 18) started\n",
      "23:41:50 DISPATCHER: Trying to submit another job.\n",
      "23:41:50 job_callback for (0, 0, 18) got condition\n",
      "23:41:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:41:50 job (0, 0, 18) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:41:50 done building a new model for budget 18.518519 based on 9/16 split\n",
      "Best loss for this budget:inf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "23:41:50 HBMASTER: Trying to run another job!\n",
      "23:41:50 job_callback for (0, 0, 18) finished\n",
      "23:41:50 start sampling a new configuration.\n",
      "23:41:50 done sampling a new configuration.\n",
      "23:41:50 HBMASTER: schedule new run for iteration 0\n",
      "23:41:50 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "23:41:50 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "23:41:50 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "23:41:50 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:41:50 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "23:41:50 DISPATCHER: Trying to submit another job.\n",
      "23:41:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:41:50 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:41:50 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:41:50 WORKER: start processing job (0, 0, 19)\n",
      "23:41:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:41:50 WORKER: args: ()\n",
      "23:41:50 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 5, 'initial_lr': 0.0018515102268126533, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 11, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 68000 \n",
      "Batch size: 10000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:42:43 DISPATCHER: Starting worker discovery\n",
      "23:42:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:42:43 DISPATCHER: Finished worker discovery\n",
      "23:43:43 DISPATCHER: Starting worker discovery\n",
      "23:43:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:43:43 DISPATCHER: Finished worker discovery\n",
      "23:44:34 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "23:44:34 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "23:44:34 DISPATCHER: job (0, 0, 19) finished\n",
      "23:44:34 DISPATCHER: register_result: lock acquired\n",
      "23:44:34 DISPATCHER: job (0, 0, 19) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292 finished\n",
      "23:44:34 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 5, 'initial_lr': 0.0018515102268126533, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 11, 'optimizer': 'RMSprop'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "\n",
      "23:44:34 job_callback for (0, 0, 19) started\n",
      "23:44:34 DISPATCHER: Trying to submit another job.\n",
      "23:44:34 job_callback for (0, 0, 19) got condition\n",
      "23:44:34 job (0, 0, 19) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 121, in compute\n",
      "    batch_size=config['batch_size'],learning_rate=config['initial_lr'])\n",
      "  File \"C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\sciann\\models\\model.py\", line 569, in train\n",
      "    **kwargs\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 809, in fit\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 590, in fit\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\", line 256, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 1088, in train_on_batch\n",
      "    self._make_train_function()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\", line 2008, in _make_train_function\n",
      "    params=self._collected_trainable_weights, loss=self.total_loss)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 648, in get_updates\n",
      "    grads = self.get_gradients(loss, params)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 469, in get_gradients\n",
      "    \"K.argmax, K.round, K.eval.\".format(param))\n",
      "ValueError: Variable <tf.Variable 'psi/bias:0' shape=(1,) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\n",
      "\n",
      "23:44:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "23:44:34 done building a new model for budget 18.518519 based on 9/17 split\n",
      "Best loss for this budget:inf\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "23:44:34 HBMASTER: Trying to run another job!\n",
      "23:44:34 job_callback for (0, 0, 19) finished\n",
      "23:44:34 start sampling a new configuration.\n",
      "23:44:34 done sampling a new configuration.\n",
      "23:44:34 HBMASTER: schedule new run for iteration 0\n",
      "23:44:34 HBMASTER: trying submitting job (0, 0, 20) to dispatcher\n",
      "23:44:34 HBMASTER: submitting job (0, 0, 20) to dispatcher\n",
      "23:44:34 DISPATCHER: trying to submit job (0, 0, 20)\n",
      "23:44:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "23:44:34 HBMASTER: job (0, 0, 20) submitted to dispatcher\n",
      "23:44:34 DISPATCHER: Trying to submit another job.\n",
      "23:44:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "23:44:34 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:44:34 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_flow_GridSearch.worker.DESKTOP-NKTB8UL.6332.19292\n",
      "23:44:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "23:44:34 WORKER: start processing job (0, 0, 20)\n",
      "23:44:34 WORKER: args: ()\n",
      "23:44:34 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'initial_lr': 0.009335918795411225, 'loss': 'mse', 'numLayers': 36, 'numNeurons': 65, 'optimizer': 'Ftrl'}, 'budget': 18.51851851851852, 'working_directory': '.'}\n",
      "23:44:43 DISPATCHER: Starting worker discovery\n",
      "23:44:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:44:43 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 68000 \n",
      "Batch size: 5000 \n",
      "Total batches: 14 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:45:43 DISPATCHER: Starting worker discovery\n",
      "23:45:43 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "23:45:43 DISPATCHER: Finished worker discovery\n"
     ]
    }
   ],
   "source": [
    "# bohb = BOHB(  configspace = w.get_configspace(),\n",
    "#               run_id = 'example1', nameserver='127.0.0.1',\n",
    "#               min_budget=10, max_budget=1000\n",
    "#            )\n",
    "# res = bohb.run(n_iterations=25\n",
    "#               )\n",
    "\n",
    "bohb = BOHB(  configspace = w.get_configspace(),\n",
    "              run_id = run_id,\n",
    "              min_budget=10, max_budget=500\n",
    "           )\n",
    "res = bohb.run(n_iterations=5, min_n_workers=numWorkers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2c704-3f6e-4708-b54e-b28e7fcbd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('HpBandster_Results',res,allow_pickle=True)\n",
    "bohb.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
