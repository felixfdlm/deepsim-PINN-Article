{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f9bcfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2bf5058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- SCIANN 0.6.5.0 ---------------------- \n",
      "For details, check out our review paper and the documentation at: \n",
      " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
      " +  \"https://arxiv.org/abs/2005.08803\", \n",
      " +  \"https://www.sciann.com\". \n",
      "\n",
      " Need support or would like to contribute, please join sciann`s slack group: \n",
      " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
      " \n",
      "TensorFlow Version: 2.3.0 \n",
      "Python Version: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "%run plate_EQS.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ae1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pinn_Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661ae1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valData = [['u.txt'],'ofen']\n",
    "test_gridObj = SEQ.Grid(3,{'x':0,'y':1,'t':2},[[[-2,2],[-2,2],[0,10]]],10)\n",
    "configspecs = {\n",
    "    'denspt':[3,8],\n",
    "    'numNeurons':[10,100],\n",
    "    'numLayers':[2,50],\n",
    "    'activator':['tanh','relu','softmax','sigmoid'],\n",
    "    'loss':['mae','mse'],\n",
    "    'optimizer':['Adam','RMSprop','SGD','Nadam','Ftrl'],\n",
    "    'batch_size':[5000,10000,15000,25000]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16be55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing validation data\n",
      "Applying validation data to test grid\n",
      "Saving PDE and config\n",
      "Worker ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:10 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x1bef62c9288; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "12:30:10 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "12:30:10 WORKER: start listening for jobs\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Start a nameserver\n",
    "# Every run needs a nameserver. It could be a 'static' server with a\n",
    "# permanent address, but here it will be started for the local machine with the default port.\n",
    "# The nameserver manages the concurrent running workers across all possible threads or clusternodes.\n",
    "# Note the run_id argument. This uniquely identifies a run of any HpBandSter optimizer.\n",
    "NS = hpns.NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
    "NS.start()\n",
    "\n",
    "# Step 2: Start a worker\n",
    "# Now we can instantiate a worker, providing the mandatory information\n",
    "# Besides the sleep_interval, we need to define the nameserver information and\n",
    "# the same run_id as above. After that, we can start the worker in the background,\n",
    "# where it will wait for incoming configurations to evaluate.\n",
    "w = Pinn_Worker.PINN_Worker(\n",
    "    valData = valData,\n",
    "    test_gridObj=test_gridObj,\n",
    "    PDESystem=mySys,\n",
    "    configspecs = configspecs,\n",
    "    \n",
    "    nameserver='127.0.0.1',\n",
    "    run_id='example1')\n",
    "w.run(background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9ff26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:10 wait_for_workers trying to get the condition\n",
      "12:30:10 DISPATCHER: started the 'discover_worker' thread\n",
      "12:30:10 DISPATCHER: started the 'job_runner' thread\n",
      "12:30:11 DISPATCHER: Pyro daemon running on localhost:50450\n",
      "12:30:11 DISPATCHER: Starting worker discovery\n",
      "12:30:11 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "12:30:11 DISPATCHER: discovered new worker, hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:11 HBMASTER: number of workers changed to 1\n",
      "12:30:11 Enough workers to start this run!\n",
      "12:30:11 adjust_queue_size: lock accquired\n",
      "12:30:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:30:11 HBMASTER: starting run at 1639049411.0199268\n",
      "12:30:11 HBMASTER: adjusted queue size to (0, 1)\n",
      "12:30:11 DISPATCHER: Finished worker discovery\n",
      "12:30:11 start sampling a new configuration.\n",
      "12:30:11 DISPATCHER: Trying to submit another job.\n",
      "12:30:11 done sampling a new configuration.\n",
      "12:30:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:30:11 HBMASTER: schedule new run for iteration 0\n",
      "12:30:11 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "12:30:11 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "12:30:11 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "12:30:11 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:30:11 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "12:30:11 DISPATCHER: Trying to submit another job.\n",
      "12:30:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:30:11 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:11 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:11 WORKER: start processing job (0, 0, 0)\n",
      "12:30:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:30:11 WORKER: args: ()\n",
      "12:30:11 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 7, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 83, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "12:30:11 Popen(['git', 'version'], cwd=C:\\Users\\Felix\\Desktop\\GitHub\\deepsim-PINN-Article\\Plate Experiment, universal_newlines=False, shell=None, istream=None)\n",
      "12:30:11 Popen(['git', 'version'], cwd=C:\\Users\\Felix\\Desktop\\GitHub\\deepsim-PINN-Article\\Plate Experiment, universal_newlines=False, shell=None, istream=None)\n",
      "12:30:11 Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'El sistema no puede encontrar el archivo especificado', None, 2, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 5000 \n",
      "Total batches: 11 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:36 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "12:30:36 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "12:30:36 DISPATCHER: job (0, 0, 0) finished\n",
      "12:30:36 DISPATCHER: register_result: lock acquired\n",
      "12:30:36 DISPATCHER: job (0, 0, 0) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:30:36 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 7, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 83, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 747.4081351975464, 'info': {'L1': 747.4081351975464, 'L2': 1827.0092558532317, 'MAX': 7.746230937218353, 'TrainTime': 39.03125}}\n",
      "exception: None\n",
      "\n",
      "12:30:36 job_callback for (0, 0, 0) started\n",
      "12:30:36 job_callback for (0, 0, 0) got condition\n",
      "12:30:36 DISPATCHER: Trying to submit another job.\n",
      "12:30:36 Only 1 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:30:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:30:36 HBMASTER: Trying to run another job!\n",
      "12:30:36 job_callback for (0, 0, 0) finished\n",
      "12:30:36 start sampling a new configuration.\n",
      "12:30:36 done sampling a new configuration.\n",
      "12:30:36 HBMASTER: schedule new run for iteration 0\n",
      "12:30:36 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "12:30:36 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "12:30:36 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "12:30:36 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:30:36 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "12:30:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:30:36 DISPATCHER: Trying to submit another job.\n",
      "12:30:36 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:36 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:30:36 WORKER: start processing job (0, 0, 1)\n",
      "12:30:36 WORKER: args: ()\n",
      "12:30:36 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 76, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:30:46 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "12:30:46 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "12:30:46 DISPATCHER: job (0, 0, 1) finished\n",
      "12:30:46 DISPATCHER: register_result: lock acquired\n",
      "12:30:46 DISPATCHER: job (0, 0, 1) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:30:46 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 76, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 763.2347934562675, 'info': {'L1': 763.2347934562675, 'L2': 1901.7230972526884, 'MAX': 7.845147527432129, 'TrainTime': 10.6875}}\n",
      "exception: None\n",
      "\n",
      "12:30:46 job_callback for (0, 0, 1) started\n",
      "12:30:46 job_callback for (0, 0, 1) got condition\n",
      "12:30:46 DISPATCHER: Trying to submit another job.\n",
      "12:30:46 Only 2 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:30:46 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:30:47 HBMASTER: Trying to run another job!\n",
      "12:30:47 job_callback for (0, 0, 1) finished\n",
      "12:30:47 start sampling a new configuration.\n",
      "12:30:47 done sampling a new configuration.\n",
      "12:30:47 HBMASTER: schedule new run for iteration 0\n",
      "12:30:47 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "12:30:47 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "12:30:47 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "12:30:47 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:30:47 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "12:30:47 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:30:47 DISPATCHER: Trying to submit another job.\n",
      "12:30:47 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:47 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:30:47 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:30:47 WORKER: start processing job (0, 0, 2)\n",
      "12:30:47 WORKER: args: ()\n",
      "12:30:47 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 7, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 61, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 5000 \n",
      "Total batches: 11 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:31:10 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "12:31:10 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "12:31:10 DISPATCHER: job (0, 0, 2) finished\n",
      "12:31:10 DISPATCHER: register_result: lock acquired\n",
      "12:31:10 DISPATCHER: job (0, 0, 2) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:31:10 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 7, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 61, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 738.4433529781239, 'info': {'L1': 738.4433529781239, 'L2': 1785.3823260164907, 'MAX': 7.6901998293158265, 'TrainTime': 39.109375}}\n",
      "exception: None\n",
      "\n",
      "12:31:10 job_callback for (0, 0, 2) started\n",
      "12:31:10 DISPATCHER: Trying to submit another job.\n",
      "12:31:10 job_callback for (0, 0, 2) got condition\n",
      "12:31:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:31:10 Only 3 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:31:10 HBMASTER: Trying to run another job!\n",
      "12:31:10 job_callback for (0, 0, 2) finished\n",
      "12:31:10 start sampling a new configuration.\n",
      "12:31:10 done sampling a new configuration.\n",
      "12:31:10 HBMASTER: schedule new run for iteration 0\n",
      "12:31:10 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "12:31:10 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "12:31:10 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "12:31:10 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:31:10 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "12:31:10 DISPATCHER: Trying to submit another job.\n",
      "12:31:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:31:10 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:10 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:10 WORKER: start processing job (0, 0, 3)\n",
      "12:31:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:31:10 WORKER: args: ()\n",
      "12:31:10 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 5, 'loss': 'mse', 'numLayers': 23, 'numNeurons': 24, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "12:31:11 DISPATCHER: Starting worker discovery\n",
      "12:31:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:31:11 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 15000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:31:17 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "12:31:17 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "12:31:17 DISPATCHER: job (0, 0, 3) finished\n",
      "12:31:17 DISPATCHER: register_result: lock acquired\n",
      "12:31:17 DISPATCHER: job (0, 0, 3) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:31:17 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 15000, 'denspt': 5, 'loss': 'mse', 'numLayers': 23, 'numNeurons': 24, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 639.3071213428955, 'info': {'L1': 639.3071213428955, 'L2': 1357.5905989076944, 'MAX': 7.065323270535156, 'TrainTime': 5.421875}}\n",
      "exception: None\n",
      "\n",
      "12:31:17 job_callback for (0, 0, 3) started\n",
      "12:31:17 DISPATCHER: Trying to submit another job.\n",
      "12:31:17 job_callback for (0, 0, 3) got condition\n",
      "12:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:31:17 Only 4 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:31:17 HBMASTER: Trying to run another job!\n",
      "12:31:17 job_callback for (0, 0, 3) finished\n",
      "12:31:17 start sampling a new configuration.\n",
      "12:31:17 done sampling a new configuration.\n",
      "12:31:17 HBMASTER: schedule new run for iteration 0\n",
      "12:31:17 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "12:31:17 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "12:31:17 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "12:31:17 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:31:17 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "12:31:17 DISPATCHER: Trying to submit another job.\n",
      "12:31:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:31:17 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:17 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:31:17 WORKER: start processing job (0, 0, 4)\n",
      "12:31:17 WORKER: args: ()\n",
      "12:31:17 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 48, 'numNeurons': 66, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:31:24 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "12:31:24 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "12:31:24 DISPATCHER: job (0, 0, 4) finished\n",
      "12:31:24 DISPATCHER: register_result: lock acquired\n",
      "12:31:24 DISPATCHER: job (0, 0, 4) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:31:24 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 48, 'numNeurons': 66, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 780.0579831618778, 'info': {'L1': 780.0579831618778, 'L2': 1982.8578071037666, 'MAX': 7.950292463092193, 'TrainTime': 6.265625}}\n",
      "exception: None\n",
      "\n",
      "12:31:24 job_callback for (0, 0, 4) started\n",
      "12:31:24 DISPATCHER: Trying to submit another job.\n",
      "12:31:24 job_callback for (0, 0, 4) got condition\n",
      "12:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:31:24 Only 5 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:31:24 HBMASTER: Trying to run another job!\n",
      "12:31:24 job_callback for (0, 0, 4) finished\n",
      "12:31:24 start sampling a new configuration.\n",
      "12:31:24 done sampling a new configuration.\n",
      "12:31:24 HBMASTER: schedule new run for iteration 0\n",
      "12:31:24 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "12:31:24 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "12:31:24 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "12:31:24 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:31:24 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "12:31:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:31:24 DISPATCHER: Trying to submit another job.\n",
      "12:31:24 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:24 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:31:24 WORKER: start processing job (0, 0, 5)\n",
      "12:31:24 WORKER: args: ()\n",
      "12:31:24 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 47, 'numNeurons': 91, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:31:35 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "12:31:35 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "12:31:35 DISPATCHER: job (0, 0, 5) finished\n",
      "12:31:35 DISPATCHER: register_result: lock acquired\n",
      "12:31:35 DISPATCHER: job (0, 0, 5) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:31:35 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 47, 'numNeurons': 91, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 600.1957301694306, 'info': {'L1': 600.1957301694306, 'L2': 3346.8771174202047, 'MAX': 31.027155753644532, 'TrainTime': 14.640625}}\n",
      "exception: None\n",
      "\n",
      "12:31:35 job_callback for (0, 0, 5) started\n",
      "12:31:35 job_callback for (0, 0, 5) got condition\n",
      "12:31:35 Only 6 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:31:35 DISPATCHER: Trying to submit another job.\n",
      "12:31:35 HBMASTER: Trying to run another job!\n",
      "12:31:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:31:35 job_callback for (0, 0, 5) finished\n",
      "12:31:35 start sampling a new configuration.\n",
      "12:31:35 done sampling a new configuration.\n",
      "12:31:35 HBMASTER: schedule new run for iteration 0\n",
      "12:31:35 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "12:31:35 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "12:31:35 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "12:31:35 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:31:35 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "12:31:35 DISPATCHER: Trying to submit another job.\n",
      "12:31:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:31:35 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:35 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:31:35 WORKER: start processing job (0, 0, 6)\n",
      "12:31:35 WORKER: args: ()\n",
      "12:31:35 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 6, 'loss': 'mae', 'numLayers': 18, 'numNeurons': 91, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 25000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:31:42 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "12:31:42 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "12:31:42 DISPATCHER: job (0, 0, 6) finished\n",
      "12:31:42 DISPATCHER: register_result: lock acquired\n",
      "12:31:42 DISPATCHER: job (0, 0, 6) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:31:42 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 6, 'loss': 'mae', 'numLayers': 18, 'numNeurons': 91, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 699.1947148489512, 'info': {'L1': 699.1947148489512, 'L2': 1598.2026018403549, 'MAX': 7.282205456318481, 'TrainTime': 7.578125}}\n",
      "exception: None\n",
      "\n",
      "12:31:42 job_callback for (0, 0, 6) started\n",
      "12:31:42 DISPATCHER: Trying to submit another job.\n",
      "12:31:42 job_callback for (0, 0, 6) got condition\n",
      "12:31:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:31:42 Only 7 run(s) for budget 12.345679 available, need more than 9 -> can't build model!\n",
      "12:31:42 HBMASTER: Trying to run another job!\n",
      "12:31:42 job_callback for (0, 0, 6) finished\n",
      "12:31:42 start sampling a new configuration.\n",
      "12:31:42 done sampling a new configuration.\n",
      "12:31:42 HBMASTER: schedule new run for iteration 0\n",
      "12:31:42 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "12:31:42 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "12:31:42 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "12:31:42 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:31:42 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "12:31:42 DISPATCHER: Trying to submit another job.\n",
      "12:31:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:31:42 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:42 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:31:42 WORKER: start processing job (0, 0, 7)\n",
      "12:31:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:31:42 WORKER: args: ()\n",
      "12:31:42 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 7, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 100, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 15000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:32:09 WORKER: done with job (0, 0, 7), trying to register it.\n",
      "12:32:09 WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "12:32:09 DISPATCHER: job (0, 0, 7) finished\n",
      "12:32:09 DISPATCHER: register_result: lock acquired\n",
      "12:32:09 DISPATCHER: job (0, 0, 7) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:32:09 job_id: (0, 0, 7)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 7, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 100, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 742.2247248493842, 'info': {'L1': 742.2247248493842, 'L2': 1802.8799474037442, 'MAX': 7.713834590887711, 'TrainTime': 50.84375}}\n",
      "exception: None\n",
      "\n",
      "12:32:09 job_callback for (0, 0, 7) started\n",
      "12:32:09 DISPATCHER: Trying to submit another job.\n",
      "12:32:09 job_callback for (0, 0, 7) got condition\n",
      "12:32:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:32:09 HBMASTER: Trying to run another job!\n",
      "12:32:09 job_callback for (0, 0, 7) finished\n",
      "12:32:09 start sampling a new configuration.\n",
      "12:32:09 done sampling a new configuration.\n",
      "12:32:09 HBMASTER: schedule new run for iteration 0\n",
      "12:32:09 HBMASTER: trying submitting job (0, 0, 8) to dispatcher\n",
      "12:32:09 HBMASTER: submitting job (0, 0, 8) to dispatcher\n",
      "12:32:09 DISPATCHER: trying to submit job (0, 0, 8)\n",
      "12:32:09 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:32:09 HBMASTER: job (0, 0, 8) submitted to dispatcher\n",
      "12:32:09 DISPATCHER: Trying to submit another job.\n",
      "12:32:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:32:09 DISPATCHER: starting job (0, 0, 8) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:32:09 DISPATCHER: job (0, 0, 8) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:32:09 WORKER: start processing job (0, 0, 8)\n",
      "12:32:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:32:09 WORKER: args: ()\n",
      "12:32:09 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 29, 'numNeurons': 43, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "12:32:11 DISPATCHER: Starting worker discovery\n",
      "12:32:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:32:11 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:32:16 WORKER: done with job (0, 0, 8), trying to register it.\n",
      "12:32:16 WORKER: registered result for job (0, 0, 8) with dispatcher\n",
      "12:32:16 DISPATCHER: job (0, 0, 8) finished\n",
      "12:32:16 DISPATCHER: register_result: lock acquired\n",
      "12:32:16 DISPATCHER: job (0, 0, 8) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:32:16 job_id: (0, 0, 8)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 29, 'numNeurons': 43, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 724.4267731793948, 'info': {'L1': 724.4267731793948, 'L2': 1718.0990451078455, 'MAX': 7.570610099854095, 'TrainTime': 4.890625}}\n",
      "exception: None\n",
      "\n",
      "12:32:16 job_callback for (0, 0, 8) started\n",
      "12:32:16 DISPATCHER: Trying to submit another job.\n",
      "12:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:32:16 job_callback for (0, 0, 8) got condition\n",
      "12:32:16 HBMASTER: Trying to run another job!\n",
      "12:32:16 job_callback for (0, 0, 8) finished\n",
      "12:32:16 start sampling a new configuration.\n",
      "12:32:16 done sampling a new configuration.\n",
      "12:32:16 HBMASTER: schedule new run for iteration 0\n",
      "12:32:16 HBMASTER: trying submitting job (0, 0, 9) to dispatcher\n",
      "12:32:16 HBMASTER: submitting job (0, 0, 9) to dispatcher\n",
      "12:32:16 DISPATCHER: trying to submit job (0, 0, 9)\n",
      "12:32:16 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:32:16 HBMASTER: job (0, 0, 9) submitted to dispatcher\n",
      "12:32:16 DISPATCHER: Trying to submit another job.\n",
      "12:32:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:32:16 DISPATCHER: starting job (0, 0, 9) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:32:16 DISPATCHER: job (0, 0, 9) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:32:16 WORKER: start processing job (0, 0, 9)\n",
      "12:32:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:32:16 WORKER: args: ()\n",
      "12:32:16 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 3, 'numNeurons': 21, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:09 WORKER: done with job (0, 0, 9), trying to register it.\n",
      "12:33:09 WORKER: registered result for job (0, 0, 9) with dispatcher\n",
      "12:33:09 DISPATCHER: job (0, 0, 9) finished\n",
      "12:33:09 DISPATCHER: register_result: lock acquired\n",
      "12:33:09 DISPATCHER: job (0, 0, 9) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:33:09 job_id: (0, 0, 9)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 3, 'numNeurons': 21, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 543.2017971925244, 'info': {'L1': 543.2017971925244, 'L2': 999.8966504314742, 'MAX': 6.463461316799805, 'TrainTime': 72.78125}}\n",
      "exception: None\n",
      "\n",
      "12:33:09 job_callback for (0, 0, 9) started\n",
      "12:33:09 job_callback for (0, 0, 9) got condition\n",
      "12:33:09 HBMASTER: Trying to run another job!\n",
      "12:33:09 DISPATCHER: Trying to submit another job.\n",
      "12:33:09 job_callback for (0, 0, 9) finished\n",
      "12:33:09 start sampling a new configuration.\n",
      "12:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:33:09 done sampling a new configuration.\n",
      "12:33:09 HBMASTER: schedule new run for iteration 0\n",
      "12:33:09 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "12:33:09 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "12:33:09 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "12:33:09 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:33:09 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "12:33:09 DISPATCHER: Trying to submit another job.\n",
      "12:33:09 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:33:09 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:09 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:09 WORKER: start processing job (0, 0, 10)\n",
      "12:33:09 WORKER: args: ()\n",
      "12:33:09 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:33:09 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 44, 'numNeurons': 49, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "12:33:11 DISPATCHER: Starting worker discovery\n",
      "12:33:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:33:11 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 1000 \n",
      "Total batches: 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:16 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "12:33:16 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "12:33:16 DISPATCHER: job (0, 0, 10) finished\n",
      "12:33:16 DISPATCHER: register_result: lock acquired\n",
      "12:33:16 DISPATCHER: job (0, 0, 10) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:33:16 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 44, 'numNeurons': 49, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 128.49058423738205, 'info': {'L1': 128.49058423738205, 'L2': 76.88159779521018, 'MAX': 3.3286702029330812, 'TrainTime': 4.5625}}\n",
      "exception: None\n",
      "\n",
      "12:33:16 job_callback for (0, 0, 10) started\n",
      "12:33:16 DISPATCHER: Trying to submit another job.\n",
      "12:33:16 job_callback for (0, 0, 10) got condition\n",
      "12:33:16 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:33:16 HBMASTER: Trying to run another job!\n",
      "12:33:16 job_callback for (0, 0, 10) finished\n",
      "12:33:16 start sampling a new configuration.\n",
      "12:33:16 done sampling a new configuration.\n",
      "12:33:16 HBMASTER: schedule new run for iteration 0\n",
      "12:33:16 HBMASTER: trying submitting job (0, 0, 11) to dispatcher\n",
      "12:33:16 HBMASTER: submitting job (0, 0, 11) to dispatcher\n",
      "12:33:16 DISPATCHER: trying to submit job (0, 0, 11)\n",
      "12:33:16 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:33:16 HBMASTER: job (0, 0, 11) submitted to dispatcher\n",
      "12:33:16 DISPATCHER: Trying to submit another job.\n",
      "12:33:16 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:33:16 DISPATCHER: starting job (0, 0, 11) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:16 DISPATCHER: job (0, 0, 11) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:16 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:33:16 WORKER: start processing job (0, 0, 11)\n",
      "12:33:16 WORKER: args: ()\n",
      "12:33:16 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 4, 'loss': 'mae', 'numLayers': 33, 'numNeurons': 22, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10240 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:23 WORKER: done with job (0, 0, 11), trying to register it.\n",
      "12:33:23 WORKER: registered result for job (0, 0, 11) with dispatcher\n",
      "12:33:23 DISPATCHER: job (0, 0, 11) finished\n",
      "12:33:23 DISPATCHER: register_result: lock acquired\n",
      "12:33:23 DISPATCHER: job (0, 0, 11) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:33:23 job_id: (0, 0, 11)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 4, 'loss': 'mae', 'numLayers': 33, 'numNeurons': 22, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 762.540959401574, 'info': {'L1': 762.540959401574, 'L2': 1898.055599372096, 'MAX': 7.838198072886154, 'TrainTime': 5.140625}}\n",
      "exception: None\n",
      "\n",
      "12:33:23 job_callback for (0, 0, 11) started\n",
      "12:33:23 DISPATCHER: Trying to submit another job.\n",
      "12:33:23 job_callback for (0, 0, 11) got condition\n",
      "12:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:33:23 HBMASTER: Trying to run another job!\n",
      "12:33:23 job_callback for (0, 0, 11) finished\n",
      "12:33:23 start sampling a new configuration.\n",
      "12:33:23 done sampling a new configuration.\n",
      "12:33:23 HBMASTER: schedule new run for iteration 0\n",
      "12:33:23 HBMASTER: trying submitting job (0, 0, 12) to dispatcher\n",
      "12:33:23 HBMASTER: submitting job (0, 0, 12) to dispatcher\n",
      "12:33:23 DISPATCHER: trying to submit job (0, 0, 12)\n",
      "12:33:23 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:33:23 HBMASTER: job (0, 0, 12) submitted to dispatcher\n",
      "12:33:23 DISPATCHER: Trying to submit another job.\n",
      "12:33:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:33:23 DISPATCHER: starting job (0, 0, 12) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:23 DISPATCHER: job (0, 0, 12) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:33:23 WORKER: start processing job (0, 0, 12)\n",
      "12:33:23 WORKER: args: ()\n",
      "12:33:23 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 9, 'numNeurons': 86, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:37 WORKER: done with job (0, 0, 12), trying to register it.\n",
      "12:33:37 WORKER: registered result for job (0, 0, 12) with dispatcher\n",
      "12:33:37 DISPATCHER: job (0, 0, 12) finished\n",
      "12:33:37 DISPATCHER: register_result: lock acquired\n",
      "12:33:37 DISPATCHER: job (0, 0, 12) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:33:37 job_id: (0, 0, 12)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 9, 'numNeurons': 86, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 550.0471831757538, 'info': {'L1': 550.0471831757538, 'L2': 1021.6042612274939, 'MAX': 6.365841187214539, 'TrainTime': 16.5}}\n",
      "exception: None\n",
      "\n",
      "12:33:37 job_callback for (0, 0, 12) started\n",
      "12:33:37 job_callback for (0, 0, 12) got condition\n",
      "12:33:37 HBMASTER: Trying to run another job!\n",
      "12:33:37 job_callback for (0, 0, 12) finished\n",
      "12:33:37 DISPATCHER: Trying to submit another job.\n",
      "12:33:37 start sampling a new configuration.\n",
      "12:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:33:37 done sampling a new configuration.\n",
      "12:33:37 HBMASTER: schedule new run for iteration 0\n",
      "12:33:37 HBMASTER: trying submitting job (0, 0, 13) to dispatcher\n",
      "12:33:37 HBMASTER: submitting job (0, 0, 13) to dispatcher\n",
      "12:33:37 DISPATCHER: trying to submit job (0, 0, 13)\n",
      "12:33:37 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:33:37 HBMASTER: job (0, 0, 13) submitted to dispatcher\n",
      "12:33:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:33:37 DISPATCHER: Trying to submit another job.\n",
      "12:33:37 DISPATCHER: starting job (0, 0, 13) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:37 DISPATCHER: job (0, 0, 13) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:37 WORKER: start processing job (0, 0, 13)\n",
      "12:33:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:33:37 WORKER: args: ()\n",
      "12:33:37 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 3, 'loss': 'mae', 'numLayers': 42, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:33:53 WORKER: done with job (0, 0, 13), trying to register it.\n",
      "12:33:53 WORKER: registered result for job (0, 0, 13) with dispatcher\n",
      "12:33:53 DISPATCHER: job (0, 0, 13) finished\n",
      "12:33:53 DISPATCHER: register_result: lock acquired\n",
      "12:33:53 DISPATCHER: job (0, 0, 13) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:33:53 job_id: (0, 0, 13)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 3, 'loss': 'mae', 'numLayers': 42, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 798.5950529248827, 'info': {'L1': 798.5950529248827, 'L2': 2074.306562144303, 'MAX': 8.066149152493164, 'TrainTime': 14.09375}}\n",
      "exception: None\n",
      "\n",
      "12:33:53 job_callback for (0, 0, 13) started\n",
      "12:33:53 DISPATCHER: Trying to submit another job.\n",
      "12:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:33:53 job_callback for (0, 0, 13) got condition\n",
      "12:33:53 HBMASTER: Trying to run another job!\n",
      "12:33:53 job_callback for (0, 0, 13) finished\n",
      "12:33:53 start sampling a new configuration.\n",
      "12:33:53 done sampling a new configuration.\n",
      "12:33:53 HBMASTER: schedule new run for iteration 0\n",
      "12:33:53 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "12:33:53 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "12:33:53 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "12:33:53 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:33:53 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "12:33:53 DISPATCHER: Trying to submit another job.\n",
      "12:33:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:33:53 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:53 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:33:53 WORKER: start processing job (0, 0, 14)\n",
      "12:33:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:33:53 WORKER: args: ()\n",
      "12:33:53 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 25, 'numNeurons': 77, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:08 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "12:34:08 WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "12:34:08 DISPATCHER: job (0, 0, 14) finished\n",
      "12:34:08 DISPATCHER: register_result: lock acquired\n",
      "12:34:08 DISPATCHER: job (0, 0, 14) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:34:08 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 25, 'numNeurons': 77, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 445.0322157152167, 'info': {'L1': 445.0322157152167, 'L2': 689.7036046661976, 'MAX': 5.813991225933716, 'TrainTime': 16.6875}}\n",
      "exception: None\n",
      "\n",
      "12:34:08 job_callback for (0, 0, 14) started\n",
      "12:34:08 DISPATCHER: Trying to submit another job.\n",
      "12:34:08 job_callback for (0, 0, 14) got condition\n",
      "12:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:34:08 HBMASTER: Trying to run another job!\n",
      "12:34:08 job_callback for (0, 0, 14) finished\n",
      "12:34:08 start sampling a new configuration.\n",
      "12:34:08 done sampling a new configuration.\n",
      "12:34:08 HBMASTER: schedule new run for iteration 0\n",
      "12:34:08 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "12:34:08 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "12:34:08 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "12:34:08 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:34:08 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "12:34:08 DISPATCHER: Trying to submit another job.\n",
      "12:34:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:34:08 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:08 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:34:08 WORKER: start processing job (0, 0, 15)\n",
      "12:34:08 WORKER: args: ()\n",
      "12:34:08 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 30, 'numNeurons': 30, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:11 DISPATCHER: Starting worker discovery\n",
      "12:34:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:34:11 DISPATCHER: Finished worker discovery\n",
      "12:34:30 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "12:34:30 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "12:34:30 DISPATCHER: job (0, 0, 15) finished\n",
      "12:34:30 DISPATCHER: register_result: lock acquired\n",
      "12:34:30 DISPATCHER: job (0, 0, 15) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:34:30 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 30, 'numNeurons': 30, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 251.66364471925138, 'info': {'L1': 251.66364471925138, 'L2': 245.1680526344339, 'MAX': 4.5060257088896485, 'TrainTime': 26.140625}}\n",
      "exception: None\n",
      "\n",
      "12:34:30 job_callback for (0, 0, 15) started\n",
      "12:34:30 DISPATCHER: Trying to submit another job.\n",
      "12:34:30 job_callback for (0, 0, 15) got condition\n",
      "12:34:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:34:30 done building a new model for budget 12.345679 based on 8/13 split\n",
      "Best loss for this budget:128.490584\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:34:30 HBMASTER: Trying to run another job!\n",
      "12:34:30 job_callback for (0, 0, 15) finished\n",
      "12:34:30 start sampling a new configuration.\n",
      "C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\statsmodels\\nonparametric\\kernels.py:62: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  kernel_value = np.ones(Xi.size) * h / (num_levels - 1)\n",
      "C:\\Users\\Felix\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\_methods.py:48: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "12:34:30 sampled vector: [3, 4, 0.6462530527608995, 1, 0.4025264730804435, 0.9881121186968936, 1] has EI value inf\n",
      "12:34:30 data in the KDEs:\n",
      "[[1.         0.         0.08333194 0.         0.86734709 0.43406592\n",
      "  1.        ]\n",
      " [3.         0.         0.41666639 1.         0.58163269 0.22527466\n",
      "  0.        ]\n",
      " [0.         1.         0.41666639 0.         0.47959183 0.74175829\n",
      "  3.        ]\n",
      " [2.         0.         0.75000083 1.         0.03061205 0.12637354\n",
      "  3.        ]\n",
      " [0.         1.         0.41666639 0.         0.15306108 0.84065942\n",
      "  3.        ]\n",
      " [1.         0.         0.75000083 1.         0.9285716  0.89560448\n",
      "  3.        ]\n",
      " [1.         3.         0.41666639 1.         0.43877549 0.15934058\n",
      "  2.        ]\n",
      " [1.         4.         0.58333361 0.         0.33673463 0.89560448\n",
      "  0.        ]]\n",
      "[[1.         1.         0.24999917 0.         0.56122451 0.36813184\n",
      "  0.        ]\n",
      " [2.         1.         0.75000083 0.         0.3571428  0.56593408\n",
      "  0.        ]\n",
      " [2.         3.         0.75000083 0.         0.2142856  0.9945056\n",
      "  3.        ]\n",
      " [2.         1.         0.75000083 0.         0.37755097 0.80769238\n",
      "  3.        ]\n",
      " [1.         4.         0.24999917 0.         0.6428572  0.13736256\n",
      "  1.        ]\n",
      " [3.         1.         0.24999917 0.         0.41836731 0.73076928\n",
      "  4.        ]\n",
      " [1.         1.         0.58333361 0.         0.94897978 0.62087915\n",
      "  4.        ]\n",
      " [2.         3.         0.08333194 0.         0.82653075 0.36813184\n",
      "  2.        ]]\n",
      "12:34:30 bandwidth of the KDEs:\n",
      "[0.8133887  1.27433518 0.17816762 0.43870924 0.258164   0.27924005\n",
      " 1.11310312]\n",
      "[5.80357771e-01 1.02300184e+00 2.28312287e-01 1.00000000e-03\n",
      " 2.06009964e-01 2.26624602e-01 1.34773734e+00]\n",
      "12:34:30 l(x) = 0.0012703451423919992\n",
      "12:34:30 g(x) = inf\n",
      "12:34:30 best_vector: [3, 4, 0.6462530527608995, 1, 0.4025264730804435, 0.9881121186968936, 1], 5.621667552298953e-31, 0.0012703451423919992, inf\n",
      "12:34:30 done sampling a new configuration.\n",
      "12:34:30 HBMASTER: schedule new run for iteration 0\n",
      "12:34:30 HBMASTER: trying submitting job (0, 0, 16) to dispatcher\n",
      "12:34:30 HBMASTER: submitting job (0, 0, 16) to dispatcher\n",
      "12:34:30 DISPATCHER: trying to submit job (0, 0, 16)\n",
      "12:34:30 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:34:30 HBMASTER: job (0, 0, 16) submitted to dispatcher\n",
      "12:34:30 DISPATCHER: Trying to submit another job.\n",
      "12:34:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:34:30 DISPATCHER: starting job (0, 0, 16) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:30 DISPATCHER: job (0, 0, 16) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:30 WORKER: start processing job (0, 0, 16)\n",
      "12:34:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:34:30 WORKER: args: ()\n",
      "12:34:30 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 6, 'loss': 'mse', 'numLayers': 21, 'numNeurons': 99, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 25000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:48 WORKER: done with job (0, 0, 16), trying to register it.\n",
      "12:34:48 WORKER: registered result for job (0, 0, 16) with dispatcher\n",
      "12:34:48 DISPATCHER: job (0, 0, 16) finished\n",
      "12:34:48 DISPATCHER: register_result: lock acquired\n",
      "12:34:48 DISPATCHER: job (0, 0, 16) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:34:48 job_id: (0, 0, 16)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 6, 'loss': 'mse', 'numLayers': 21, 'numNeurons': 99, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 602.4471530984727, 'info': {'L1': 602.4471530984727, 'L2': 1213.986456989921, 'MAX': 6.837677634930298, 'TrainTime': 26.078125}}\n",
      "exception: None\n",
      "\n",
      "12:34:48 job_callback for (0, 0, 16) started\n",
      "12:34:48 DISPATCHER: Trying to submit another job.\n",
      "12:34:48 job_callback for (0, 0, 16) got condition\n",
      "12:34:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:34:48 done building a new model for budget 12.345679 based on 8/14 split\n",
      "Best loss for this budget:128.490584\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:34:48 HBMASTER: Trying to run another job!\n",
      "12:34:48 job_callback for (0, 0, 16) finished\n",
      "12:34:48 start sampling a new configuration.\n",
      "12:34:48 done sampling a new configuration.\n",
      "12:34:48 HBMASTER: schedule new run for iteration 0\n",
      "12:34:48 HBMASTER: trying submitting job (0, 0, 17) to dispatcher\n",
      "12:34:48 HBMASTER: submitting job (0, 0, 17) to dispatcher\n",
      "12:34:48 DISPATCHER: trying to submit job (0, 0, 17)\n",
      "12:34:48 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:34:48 HBMASTER: job (0, 0, 17) submitted to dispatcher\n",
      "12:34:48 DISPATCHER: Trying to submit another job.\n",
      "12:34:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:34:48 DISPATCHER: starting job (0, 0, 17) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:48 DISPATCHER: job (0, 0, 17) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:48 WORKER: start processing job (0, 0, 17)\n",
      "12:34:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:34:48 WORKER: args: ()\n",
      "12:34:48 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 5, 'loss': 'mse', 'numLayers': 14, 'numNeurons': 42, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 20000 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:34:56 WORKER: done with job (0, 0, 17), trying to register it.\n",
      "12:34:56 WORKER: registered result for job (0, 0, 17) with dispatcher\n",
      "12:34:56 DISPATCHER: job (0, 0, 17) finished\n",
      "12:34:56 DISPATCHER: register_result: lock acquired\n",
      "12:34:56 DISPATCHER: job (0, 0, 17) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:34:56 job_id: (0, 0, 17)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 5, 'loss': 'mse', 'numLayers': 14, 'numNeurons': 42, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 776.6710424413076, 'info': {'L1': 776.6710424413076, 'L2': 1966.9753164228998, 'MAX': 7.942287721348986, 'TrainTime': 6.375}}\n",
      "exception: None\n",
      "\n",
      "12:34:56 job_callback for (0, 0, 17) started\n",
      "12:34:56 DISPATCHER: Trying to submit another job.\n",
      "12:34:56 job_callback for (0, 0, 17) got condition\n",
      "12:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:34:56 done building a new model for budget 12.345679 based on 8/15 split\n",
      "Best loss for this budget:128.490584\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:34:56 HBMASTER: Trying to run another job!\n",
      "12:34:56 job_callback for (0, 0, 17) finished\n",
      "12:34:56 start sampling a new configuration.\n",
      "12:34:56 done sampling a new configuration.\n",
      "12:34:56 HBMASTER: schedule new run for iteration 0\n",
      "12:34:56 HBMASTER: trying submitting job (0, 0, 18) to dispatcher\n",
      "12:34:56 HBMASTER: submitting job (0, 0, 18) to dispatcher\n",
      "12:34:56 DISPATCHER: trying to submit job (0, 0, 18)\n",
      "12:34:56 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:34:56 HBMASTER: job (0, 0, 18) submitted to dispatcher\n",
      "12:34:56 DISPATCHER: Trying to submit another job.\n",
      "12:34:56 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:34:56 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:56 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:34:56 WORKER: start processing job (0, 0, 18)\n",
      "12:34:56 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:34:56 WORKER: args: ()\n",
      "12:34:56 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 75, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:11 DISPATCHER: Starting worker discovery\n",
      "12:35:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:35:11 DISPATCHER: Finished worker discovery\n",
      "12:35:18 WORKER: done with job (0, 0, 18), trying to register it.\n",
      "12:35:18 WORKER: registered result for job (0, 0, 18) with dispatcher\n",
      "12:35:18 DISPATCHER: job (0, 0, 18) finished\n",
      "12:35:18 DISPATCHER: register_result: lock acquired\n",
      "12:35:18 DISPATCHER: job (0, 0, 18) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:35:18 job_id: (0, 0, 18)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 75, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 107.8192946343077, 'info': {'L1': 107.8192946343077, 'L2': 77.55948926010208, 'MAX': 4.598476724945899, 'TrainTime': 25.578125}}\n",
      "exception: None\n",
      "\n",
      "12:35:18 job_callback for (0, 0, 18) started\n",
      "12:35:18 DISPATCHER: Trying to submit another job.\n",
      "12:35:18 job_callback for (0, 0, 18) got condition\n",
      "12:35:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:35:18 done building a new model for budget 12.345679 based on 8/16 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:35:18 HBMASTER: Trying to run another job!\n",
      "12:35:18 job_callback for (0, 0, 18) finished\n",
      "12:35:18 start sampling a new configuration.\n",
      "12:35:18 done sampling a new configuration.\n",
      "12:35:18 HBMASTER: schedule new run for iteration 0\n",
      "12:35:18 HBMASTER: trying submitting job (0, 0, 19) to dispatcher\n",
      "12:35:18 HBMASTER: submitting job (0, 0, 19) to dispatcher\n",
      "12:35:18 DISPATCHER: trying to submit job (0, 0, 19)\n",
      "12:35:18 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:35:18 HBMASTER: job (0, 0, 19) submitted to dispatcher\n",
      "12:35:18 DISPATCHER: Trying to submit another job.\n",
      "12:35:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:35:18 DISPATCHER: starting job (0, 0, 19) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:18 DISPATCHER: job (0, 0, 19) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:35:18 WORKER: start processing job (0, 0, 19)\n",
      "12:35:18 WORKER: args: ()\n",
      "12:35:18 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 25000, 'denspt': 4, 'loss': 'mae', 'numLayers': 40, 'numNeurons': 53, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10240 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:30 WORKER: done with job (0, 0, 19), trying to register it.\n",
      "12:35:30 WORKER: registered result for job (0, 0, 19) with dispatcher\n",
      "12:35:30 DISPATCHER: job (0, 0, 19) finished\n",
      "12:35:30 DISPATCHER: register_result: lock acquired\n",
      "12:35:30 DISPATCHER: job (0, 0, 19) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:35:30 job_id: (0, 0, 19)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 25000, 'denspt': 4, 'loss': 'mae', 'numLayers': 40, 'numNeurons': 53, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 782.4118592459671, 'info': {'L1': 782.4118592459671, 'L2': 1994.3511208354996, 'MAX': 7.965004188617751, 'TrainTime': 12.28125}}\n",
      "exception: None\n",
      "\n",
      "12:35:30 job_callback for (0, 0, 19) started\n",
      "12:35:30 DISPATCHER: Trying to submit another job.\n",
      "12:35:30 job_callback for (0, 0, 19) got condition\n",
      "12:35:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:35:30 done building a new model for budget 12.345679 based on 8/17 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:35:30 HBMASTER: Trying to run another job!\n",
      "12:35:30 job_callback for (0, 0, 19) finished\n",
      "12:35:30 start sampling a new configuration.\n",
      "12:35:30 done sampling a new configuration.\n",
      "12:35:30 HBMASTER: schedule new run for iteration 0\n",
      "12:35:30 HBMASTER: trying submitting job (0, 0, 20) to dispatcher\n",
      "12:35:30 HBMASTER: submitting job (0, 0, 20) to dispatcher\n",
      "12:35:30 DISPATCHER: trying to submit job (0, 0, 20)\n",
      "12:35:30 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:35:30 HBMASTER: job (0, 0, 20) submitted to dispatcher\n",
      "12:35:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:35:30 DISPATCHER: Trying to submit another job.\n",
      "12:35:30 DISPATCHER: starting job (0, 0, 20) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:30 DISPATCHER: job (0, 0, 20) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:35:30 WORKER: start processing job (0, 0, 20)\n",
      "12:35:30 WORKER: args: ()\n",
      "12:35:30 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 21, 'numNeurons': 67, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:35:44 WORKER: done with job (0, 0, 20), trying to register it.\n",
      "12:35:44 WORKER: registered result for job (0, 0, 20) with dispatcher\n",
      "12:35:44 DISPATCHER: job (0, 0, 20) finished\n",
      "12:35:44 DISPATCHER: register_result: lock acquired\n",
      "12:35:44 DISPATCHER: job (0, 0, 20) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:35:44 job_id: (0, 0, 20)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 21, 'numNeurons': 67, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 776.7551498729698, 'info': {'L1': 776.7551498729698, 'L2': 1966.7893876025266, 'MAX': 7.929649755036518, 'TrainTime': 12.359375}}\n",
      "exception: None\n",
      "\n",
      "12:35:44 job_callback for (0, 0, 20) started\n",
      "12:35:44 DISPATCHER: Trying to submit another job.\n",
      "12:35:44 job_callback for (0, 0, 20) got condition\n",
      "12:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:35:44 done building a new model for budget 12.345679 based on 8/17 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:35:44 HBMASTER: Trying to run another job!\n",
      "12:35:44 job_callback for (0, 0, 20) finished\n",
      "12:35:44 start sampling a new configuration.\n",
      "12:35:44 best_vector: [2, 4, 0.22105413809371977, 1, 0.8614024668707716, 0.48820359632281124, 2], 2.6698913807573055e-31, 0.037454707229188984, -0.006948127281074991\n",
      "12:35:44 done sampling a new configuration.\n",
      "12:35:44 HBMASTER: schedule new run for iteration 0\n",
      "12:35:44 HBMASTER: trying submitting job (0, 0, 21) to dispatcher\n",
      "12:35:44 HBMASTER: submitting job (0, 0, 21) to dispatcher\n",
      "12:35:44 DISPATCHER: trying to submit job (0, 0, 21)\n",
      "12:35:44 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:35:44 HBMASTER: job (0, 0, 21) submitted to dispatcher\n",
      "12:35:44 DISPATCHER: Trying to submit another job.\n",
      "12:35:44 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:35:44 DISPATCHER: starting job (0, 0, 21) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:44 DISPATCHER: job (0, 0, 21) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:35:44 WORKER: start processing job (0, 0, 21)\n",
      "12:35:44 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:35:44 WORKER: args: ()\n",
      "12:35:44 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 4, 'loss': 'mse', 'numLayers': 44, 'numNeurons': 54, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10240 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:03 WORKER: done with job (0, 0, 21), trying to register it.\n",
      "12:36:03 WORKER: registered result for job (0, 0, 21) with dispatcher\n",
      "12:36:03 DISPATCHER: job (0, 0, 21) finished\n",
      "12:36:03 DISPATCHER: register_result: lock acquired\n",
      "12:36:03 DISPATCHER: job (0, 0, 21) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:36:03 job_id: (0, 0, 21)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 4, 'loss': 'mse', 'numLayers': 44, 'numNeurons': 54, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 766.2081687767021, 'info': {'L1': 766.2081687767021, 'L2': 1915.9343721211756, 'MAX': 7.863731123184845, 'TrainTime': 20.125}}\n",
      "exception: None\n",
      "\n",
      "12:36:03 job_callback for (0, 0, 21) started\n",
      "12:36:03 DISPATCHER: Trying to submit another job.\n",
      "12:36:03 job_callback for (0, 0, 21) got condition\n",
      "12:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:36:03 done building a new model for budget 12.345679 based on 8/18 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:36:03 HBMASTER: Trying to run another job!\n",
      "12:36:03 job_callback for (0, 0, 21) finished\n",
      "12:36:03 start sampling a new configuration.\n",
      "12:36:03 best_vector: [1, 0, 0.5572177748917089, 1, 0.24219941306367865, 0.6830807877407671, 0], 1.8732218546912626e-31, 0.053383959700001274, -0.006811416374381986\n",
      "12:36:03 done sampling a new configuration.\n",
      "12:36:03 HBMASTER: schedule new run for iteration 0\n",
      "12:36:03 HBMASTER: trying submitting job (0, 0, 22) to dispatcher\n",
      "12:36:03 HBMASTER: submitting job (0, 0, 22) to dispatcher\n",
      "12:36:03 DISPATCHER: trying to submit job (0, 0, 22)\n",
      "12:36:03 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:36:03 HBMASTER: job (0, 0, 22) submitted to dispatcher\n",
      "12:36:03 DISPATCHER: Trying to submit another job.\n",
      "12:36:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:36:03 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:03 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:03 WORKER: start processing job (0, 0, 22)\n",
      "12:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:36:03 WORKER: args: ()\n",
      "12:36:03 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 6, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 72, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 1000 \n",
      "Total batches: 35 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:11 DISPATCHER: Starting worker discovery\n",
      "12:36:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:36:11 DISPATCHER: Finished worker discovery\n",
      "12:36:17 WORKER: done with job (0, 0, 22), trying to register it.\n",
      "12:36:17 WORKER: registered result for job (0, 0, 22) with dispatcher\n",
      "12:36:17 DISPATCHER: job (0, 0, 22) finished\n",
      "12:36:17 DISPATCHER: register_result: lock acquired\n",
      "12:36:17 DISPATCHER: job (0, 0, 22) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:36:17 job_id: (0, 0, 22)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 6, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 72, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 212.81017022020512, 'info': {'L1': 212.81017022020512, 'L2': 221.68145026770395, 'MAX': 5.934074401855469, 'TrainTime': 15.15625}}\n",
      "exception: None\n",
      "\n",
      "12:36:17 job_callback for (0, 0, 22) started\n",
      "12:36:17 DISPATCHER: Trying to submit another job.\n",
      "12:36:17 job_callback for (0, 0, 22) got condition\n",
      "12:36:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:36:17 done building a new model for budget 12.345679 based on 8/19 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:36:17 HBMASTER: Trying to run another job!\n",
      "12:36:17 job_callback for (0, 0, 22) finished\n",
      "12:36:17 start sampling a new configuration.\n",
      "12:36:17 best_vector: [2, 0, 0.21857165292548425, 0, 0.7639991901296571, 0.9393281895516202, 4], 6.388704643908932e-31, 0.015652625308847423, -0.002220347521281114\n",
      "12:36:17 done sampling a new configuration.\n",
      "12:36:17 HBMASTER: schedule new run for iteration 0\n",
      "12:36:17 HBMASTER: trying submitting job (0, 0, 23) to dispatcher\n",
      "12:36:17 HBMASTER: submitting job (0, 0, 23) to dispatcher\n",
      "12:36:17 DISPATCHER: trying to submit job (0, 0, 23)\n",
      "12:36:17 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:36:17 HBMASTER: job (0, 0, 23) submitted to dispatcher\n",
      "12:36:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:36:17 DISPATCHER: Trying to submit another job.\n",
      "12:36:17 DISPATCHER: starting job (0, 0, 23) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:17 DISPATCHER: job (0, 0, 23) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:17 WORKER: start processing job (0, 0, 23)\n",
      "12:36:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:36:17 WORKER: args: ()\n",
      "12:36:17 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 4, 'loss': 'mae', 'numLayers': 39, 'numNeurons': 95, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 1000 \n",
      "Total batches: 11 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:36:45 WORKER: done with job (0, 0, 23), trying to register it.\n",
      "12:36:45 WORKER: registered result for job (0, 0, 23) with dispatcher\n",
      "12:36:45 DISPATCHER: job (0, 0, 23) finished\n",
      "12:36:45 DISPATCHER: register_result: lock acquired\n",
      "12:36:45 DISPATCHER: job (0, 0, 23) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:36:45 job_id: (0, 0, 23)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 4, 'loss': 'mae', 'numLayers': 39, 'numNeurons': 95, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 778.3792345840446, 'info': {'L1': 778.3792345840446, 'L2': 1974.6821062821004, 'MAX': 7.939800284480736, 'TrainTime': 28.59375}}\n",
      "exception: None\n",
      "\n",
      "12:36:45 job_callback for (0, 0, 23) started\n",
      "12:36:45 DISPATCHER: Trying to submit another job.\n",
      "12:36:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:36:45 job_callback for (0, 0, 23) got condition\n",
      "12:36:45 done building a new model for budget 12.345679 based on 8/20 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:36:45 HBMASTER: Trying to run another job!\n",
      "12:36:45 job_callback for (0, 0, 23) finished\n",
      "12:36:45 start sampling a new configuration.\n",
      "12:36:45 best_vector: [3, 1, 0.4974760053261358, 0, 0.3645692866787448, 0.7885167924854263, 0], 1.9812278031953516e-31, 0.050473751599244984, -0.006117677232750243\n",
      "12:36:45 done sampling a new configuration.\n",
      "12:36:45 HBMASTER: schedule new run for iteration 0\n",
      "12:36:45 HBMASTER: trying submitting job (0, 0, 24) to dispatcher\n",
      "12:36:45 HBMASTER: submitting job (0, 0, 24) to dispatcher\n",
      "12:36:45 DISPATCHER: trying to submit job (0, 0, 24)\n",
      "12:36:45 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:36:45 HBMASTER: job (0, 0, 24) submitted to dispatcher\n",
      "12:36:45 DISPATCHER: Trying to submit another job.\n",
      "12:36:45 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:36:45 DISPATCHER: starting job (0, 0, 24) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:45 DISPATCHER: job (0, 0, 24) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:36:45 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:36:45 WORKER: start processing job (0, 0, 24)\n",
      "12:36:45 WORKER: args: ()\n",
      "12:36:45 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 81, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:06 WORKER: done with job (0, 0, 24), trying to register it.\n",
      "12:37:06 WORKER: registered result for job (0, 0, 24) with dispatcher\n",
      "12:37:06 DISPATCHER: job (0, 0, 24) finished\n",
      "12:37:06 DISPATCHER: register_result: lock acquired\n",
      "12:37:06 DISPATCHER: job (0, 0, 24) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:37:06 job_id: (0, 0, 24)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 81, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 777.6557258481346, 'info': {'L1': 777.6557258481346, 'L2': 1971.1639620797007, 'MAX': 7.935278279384658, 'TrainTime': 21.921875}}\n",
      "exception: None\n",
      "\n",
      "12:37:06 job_callback for (0, 0, 24) started\n",
      "12:37:06 DISPATCHER: Trying to submit another job.\n",
      "12:37:06 job_callback for (0, 0, 24) got condition\n",
      "12:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:37:06 done building a new model for budget 12.345679 based on 8/21 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:37:06 HBMASTER: Trying to run another job!\n",
      "12:37:06 job_callback for (0, 0, 24) finished\n",
      "12:37:06 start sampling a new configuration.\n",
      "12:37:06 best_vector: [0, 1, 0.3415972397541347, 0, 0.4985451748221308, 0.36704651628138507, 2], 3.3196975456781605e-31, 0.030123226174682015, -0.0035058695174402395\n",
      "12:37:06 done sampling a new configuration.\n",
      "12:37:06 HBMASTER: schedule new run for iteration 0\n",
      "12:37:06 HBMASTER: trying submitting job (0, 0, 25) to dispatcher\n",
      "12:37:06 HBMASTER: submitting job (0, 0, 25) to dispatcher\n",
      "12:37:06 DISPATCHER: trying to submit job (0, 0, 25)\n",
      "12:37:06 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:37:06 HBMASTER: job (0, 0, 25) submitted to dispatcher\n",
      "12:37:06 DISPATCHER: Trying to submit another job.\n",
      "12:37:06 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:37:06 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:37:06 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:37:06 WORKER: start processing job (0, 0, 25)\n",
      "12:37:06 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:37:06 WORKER: args: ()\n",
      "12:37:06 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:37:11 DISPATCHER: Starting worker discovery\n",
      "12:37:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:37:11 DISPATCHER: Finished worker discovery\n",
      "12:37:25 WORKER: done with job (0, 0, 25), trying to register it.\n",
      "12:37:25 WORKER: registered result for job (0, 0, 25) with dispatcher\n",
      "12:37:25 DISPATCHER: job (0, 0, 25) finished\n",
      "12:37:25 DISPATCHER: register_result: lock acquired\n",
      "12:37:25 DISPATCHER: job (0, 0, 25) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:37:25 job_id: (0, 0, 25)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 531.4931341816314, 'info': {'L1': 531.4931341816314, 'L2': 949.6861319242778, 'MAX': 6.327034391140625, 'TrainTime': 19.546875}}\n",
      "exception: None\n",
      "\n",
      "12:37:25 job_callback for (0, 0, 25) started\n",
      "12:37:25 DISPATCHER: Trying to submit another job.\n",
      "12:37:25 job_callback for (0, 0, 25) got condition\n",
      "12:37:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:37:25 done building a new model for budget 12.345679 based on 8/22 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:37:25 HBMASTER: Trying to run another job!\n",
      "12:37:25 job_callback for (0, 0, 25) finished\n",
      "12:37:25 start sampling a new configuration.\n",
      "12:37:25 best_vector: [3, 0, 0.692146732123749, 0, 0.12956091158183672, 0.33542732208506454, 0], 6.246754407807254e-31, 0.016008313032927796, -0.0029626924194052873\n",
      "12:37:25 done sampling a new configuration.\n",
      "12:37:25 HBMASTER: schedule new run for iteration 0\n",
      "12:37:25 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "12:37:25 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "12:37:25 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "12:37:25 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:37:25 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "12:37:25 DISPATCHER: Trying to submit another job.\n",
      "12:37:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:37:25 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:37:25 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:37:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:37:25 WORKER: start processing job (0, 0, 26)\n",
      "12:37:25 WORKER: args: ()\n",
      "12:37:25 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 8, 'numNeurons': 40, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:11 DISPATCHER: Starting worker discovery\n",
      "12:38:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:38:11 DISPATCHER: Finished worker discovery\n",
      "12:38:29 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "12:38:29 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "12:38:29 DISPATCHER: job (0, 0, 26) finished\n",
      "12:38:29 DISPATCHER: register_result: lock acquired\n",
      "12:38:29 DISPATCHER: job (0, 0, 26) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:38:29 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 8, 'numNeurons': 40, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 139.08374135696653, 'info': {'L1': 139.08374135696653, 'L2': 98.96930634192839, 'MAX': 4.162531214081641, 'TrainTime': 77.015625}}\n",
      "exception: None\n",
      "\n",
      "12:38:29 job_callback for (0, 0, 26) started\n",
      "12:38:29 DISPATCHER: Trying to submit another job.\n",
      "12:38:29 job_callback for (0, 0, 26) got condition\n",
      "12:38:29 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:38:29 done building a new model for budget 12.345679 based on 8/22 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:38:29 HBMASTER: Trying to run another job!\n",
      "12:38:29 job_callback for (0, 0, 26) finished\n",
      "12:38:29 start sampling a new configuration.\n",
      "12:38:29 best_vector: [3, 1, 0.6475094668071056, 0, 0.26173652113792906, 0.6352090653109638, 1], 2.213089096559597e-31, 0.04518570904147377, -0.0029210295870638683\n",
      "12:38:29 done sampling a new configuration.\n",
      "12:38:29 HBMASTER: schedule new run for iteration 0\n",
      "12:38:29 HBMASTER: trying submitting job (0, 0, 27) to dispatcher\n",
      "12:38:29 HBMASTER: submitting job (0, 0, 27) to dispatcher\n",
      "12:38:29 DISPATCHER: trying to submit job (0, 0, 27)\n",
      "12:38:29 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:38:29 HBMASTER: job (0, 0, 27) submitted to dispatcher\n",
      "12:38:29 DISPATCHER: Trying to submit another job.\n",
      "12:38:29 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:38:29 DISPATCHER: starting job (0, 0, 27) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:38:29 DISPATCHER: job (0, 0, 27) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:38:29 WORKER: start processing job (0, 0, 27)\n",
      "12:38:29 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:38:29 WORKER: args: ()\n",
      "12:38:29 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:38:54 WORKER: done with job (0, 0, 27), trying to register it.\n",
      "12:38:54 WORKER: registered result for job (0, 0, 27) with dispatcher\n",
      "12:38:54 DISPATCHER: job (0, 0, 27) finished\n",
      "12:38:54 DISPATCHER: register_result: lock acquired\n",
      "12:38:54 DISPATCHER: job (0, 0, 27) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:38:54 job_id: (0, 0, 27)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 438.04824479552974, 'info': {'L1': 438.04824479552974, 'L2': 670.404161058542, 'MAX': 5.788504279827759, 'TrainTime': 29.34375}}\n",
      "exception: None\n",
      "\n",
      "12:38:54 job_callback for (0, 0, 27) started\n",
      "12:38:54 DISPATCHER: Trying to submit another job.\n",
      "12:38:54 job_callback for (0, 0, 27) got condition\n",
      "12:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:38:54 done building a new model for budget 12.345679 based on 8/23 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:38:54 HBMASTER: Trying to run another job!\n",
      "12:38:54 job_callback for (0, 0, 27) finished\n",
      "12:38:54 start sampling a new configuration.\n",
      "12:38:54 best_vector: [3, 1, 0.6014071446823616, 0, 0.5820797841510497, 0.7933391284303578, 1], 1.4883447967387032e-31, 0.06718873222059996, -0.0018227567025515194\n",
      "12:38:54 done sampling a new configuration.\n",
      "12:38:54 HBMASTER: schedule new run for iteration 0\n",
      "12:38:54 HBMASTER: trying submitting job (0, 0, 28) to dispatcher\n",
      "12:38:54 HBMASTER: submitting job (0, 0, 28) to dispatcher\n",
      "12:38:54 DISPATCHER: trying to submit job (0, 0, 28)\n",
      "12:38:54 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:38:54 HBMASTER: job (0, 0, 28) submitted to dispatcher\n",
      "12:38:54 DISPATCHER: Trying to submit another job.\n",
      "12:38:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:38:54 DISPATCHER: starting job (0, 0, 28) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:38:54 DISPATCHER: job (0, 0, 28) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:38:54 WORKER: start processing job (0, 0, 28)\n",
      "12:38:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:38:54 WORKER: args: ()\n",
      "12:38:54 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 30, 'numNeurons': 82, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:11 DISPATCHER: Starting worker discovery\n",
      "12:39:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:39:11 DISPATCHER: Finished worker discovery\n",
      "12:39:20 WORKER: done with job (0, 0, 28), trying to register it.\n",
      "12:39:20 WORKER: registered result for job (0, 0, 28) with dispatcher\n",
      "12:39:20 DISPATCHER: job (0, 0, 28) finished\n",
      "12:39:20 DISPATCHER: register_result: lock acquired\n",
      "12:39:20 DISPATCHER: job (0, 0, 28) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:39:20 job_id: (0, 0, 28)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 30, 'numNeurons': 82, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 515.5467756687082, 'info': {'L1': 515.5467756687082, 'L2': 907.0262078058862, 'MAX': 6.287602223133728, 'TrainTime': 29.875}}\n",
      "exception: None\n",
      "\n",
      "12:39:20 job_callback for (0, 0, 28) started\n",
      "12:39:20 DISPATCHER: Trying to submit another job.\n",
      "12:39:20 job_callback for (0, 0, 28) got condition\n",
      "12:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:39:20 done building a new model for budget 12.345679 based on 8/24 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:39:20 HBMASTER: Trying to run another job!\n",
      "12:39:20 job_callback for (0, 0, 28) finished\n",
      "12:39:20 start sampling a new configuration.\n",
      "12:39:20 best_vector: [3, 1, 0.48374874029070813, 0, 0.4128677567121535, 0.5417250061703496, 4], 9.988190696107558e-32, 0.10011823266346973, -0.00042624033846323214\n",
      "12:39:20 done sampling a new configuration.\n",
      "12:39:20 HBMASTER: schedule new run for iteration 0\n",
      "12:39:20 HBMASTER: trying submitting job (0, 0, 29) to dispatcher\n",
      "12:39:20 HBMASTER: submitting job (0, 0, 29) to dispatcher\n",
      "12:39:20 DISPATCHER: trying to submit job (0, 0, 29)\n",
      "12:39:20 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:39:20 HBMASTER: job (0, 0, 29) submitted to dispatcher\n",
      "12:39:20 DISPATCHER: Trying to submit another job.\n",
      "12:39:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:39:20 DISPATCHER: starting job (0, 0, 29) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:20 DISPATCHER: job (0, 0, 29) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:39:20 WORKER: start processing job (0, 0, 29)\n",
      "12:39:20 WORKER: args: ()\n",
      "12:39:20 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 59, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:39 WORKER: done with job (0, 0, 29), trying to register it.\n",
      "12:39:39 WORKER: registered result for job (0, 0, 29) with dispatcher\n",
      "12:39:39 DISPATCHER: job (0, 0, 29) finished\n",
      "12:39:39 DISPATCHER: register_result: lock acquired\n",
      "12:39:39 DISPATCHER: job (0, 0, 29) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:39:39 job_id: (0, 0, 29)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 22, 'numNeurons': 59, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 679.5009100121223, 'info': {'L1': 679.5009100121223, 'L2': 1523.8321070253555, 'MAX': 7.321262277340576, 'TrainTime': 20.875}}\n",
      "exception: None\n",
      "\n",
      "12:39:39 job_callback for (0, 0, 29) started\n",
      "12:39:39 DISPATCHER: Trying to submit another job.\n",
      "12:39:39 job_callback for (0, 0, 29) got condition\n",
      "12:39:39 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:39:39 done building a new model for budget 12.345679 based on 8/25 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:39:39 HBMASTER: Trying to run another job!\n",
      "12:39:39 job_callback for (0, 0, 29) finished\n",
      "12:39:39 start sampling a new configuration.\n",
      "12:39:39 done sampling a new configuration.\n",
      "12:39:39 HBMASTER: schedule new run for iteration 0\n",
      "12:39:39 HBMASTER: trying submitting job (0, 0, 30) to dispatcher\n",
      "12:39:39 HBMASTER: submitting job (0, 0, 30) to dispatcher\n",
      "12:39:39 DISPATCHER: trying to submit job (0, 0, 30)\n",
      "12:39:39 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:39:39 HBMASTER: job (0, 0, 30) submitted to dispatcher\n",
      "12:39:39 DISPATCHER: Trying to submit another job.\n",
      "12:39:39 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:39:39 DISPATCHER: starting job (0, 0, 30) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:39 DISPATCHER: job (0, 0, 30) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:39 WORKER: start processing job (0, 0, 30)\n",
      "12:39:39 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:39:39 WORKER: args: ()\n",
      "12:39:39 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 6, 'numNeurons': 58, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:39:53 WORKER: done with job (0, 0, 30), trying to register it.\n",
      "12:39:53 WORKER: registered result for job (0, 0, 30) with dispatcher\n",
      "12:39:53 DISPATCHER: job (0, 0, 30) finished\n",
      "12:39:53 DISPATCHER: register_result: lock acquired\n",
      "12:39:53 DISPATCHER: job (0, 0, 30) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:39:53 job_id: (0, 0, 30)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 6, 'numNeurons': 58, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 144.9273386663056, 'info': {'L1': 144.9273386663056, 'L2': 102.76359065978204, 'MAX': 3.9242029190063477, 'TrainTime': 12.09375}}\n",
      "exception: None\n",
      "\n",
      "12:39:53 job_callback for (0, 0, 30) started\n",
      "12:39:53 job_callback for (0, 0, 30) got condition\n",
      "12:39:53 DISPATCHER: Trying to submit another job.\n",
      "12:39:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:39:53 done building a new model for budget 12.345679 based on 8/26 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:39:53 HBMASTER: Trying to run another job!\n",
      "12:39:53 job_callback for (0, 0, 30) finished\n",
      "12:39:53 start sampling a new configuration.\n",
      "12:39:53 best_vector: [2, 4, 0.28667279697273146, 1, 0.488557448142936, 0.608583593943164, 4], 1.7831865744310087e-31, 0.05607938139165762, -0.00031233640117804757\n",
      "12:39:53 done sampling a new configuration.\n",
      "12:39:53 HBMASTER: schedule new run for iteration 0\n",
      "12:39:53 HBMASTER: trying submitting job (0, 0, 31) to dispatcher\n",
      "12:39:53 HBMASTER: submitting job (0, 0, 31) to dispatcher\n",
      "12:39:53 DISPATCHER: trying to submit job (0, 0, 31)\n",
      "12:39:53 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:39:53 HBMASTER: job (0, 0, 31) submitted to dispatcher\n",
      "12:39:53 DISPATCHER: Trying to submit another job.\n",
      "12:39:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:39:53 DISPATCHER: starting job (0, 0, 31) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:53 DISPATCHER: job (0, 0, 31) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:39:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:39:53 WORKER: start processing job (0, 0, 31)\n",
      "12:39:53 WORKER: args: ()\n",
      "12:39:53 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 4, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 65, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10240 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:11 DISPATCHER: Starting worker discovery\n",
      "12:40:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:40:11 DISPATCHER: Finished worker discovery\n",
      "12:40:14 WORKER: done with job (0, 0, 31), trying to register it.\n",
      "12:40:14 WORKER: registered result for job (0, 0, 31) with dispatcher\n",
      "12:40:14 DISPATCHER: job (0, 0, 31) finished\n",
      "12:40:14 DISPATCHER: register_result: lock acquired\n",
      "12:40:14 DISPATCHER: job (0, 0, 31) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:40:14 job_id: (0, 0, 31)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 4, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 65, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 786.0903029758446, 'info': {'L1': 786.0903029758446, 'L2': 2012.3812675352622, 'MAX': 7.987994461929485, 'TrainTime': 21.578125}}\n",
      "exception: None\n",
      "\n",
      "12:40:14 job_callback for (0, 0, 31) started\n",
      "12:40:14 DISPATCHER: Trying to submit another job.\n",
      "12:40:14 job_callback for (0, 0, 31) got condition\n",
      "12:40:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:40:14 done building a new model for budget 12.345679 based on 8/27 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:40:14 HBMASTER: Trying to run another job!\n",
      "12:40:14 job_callback for (0, 0, 31) finished\n",
      "12:40:14 start sampling a new configuration.\n",
      "12:40:14 best_vector: [1, 1, 0.35957399597821466, 0, 0.25543547183640336, 0.7072945651438478, 4], 8.556952429447532e-32, 0.11686403637802667, -0.000769829569035089\n",
      "12:40:14 done sampling a new configuration.\n",
      "12:40:14 HBMASTER: schedule new run for iteration 0\n",
      "12:40:14 HBMASTER: trying submitting job (0, 0, 32) to dispatcher\n",
      "12:40:14 HBMASTER: submitting job (0, 0, 32) to dispatcher\n",
      "12:40:14 DISPATCHER: trying to submit job (0, 0, 32)\n",
      "12:40:14 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:40:14 HBMASTER: job (0, 0, 32) submitted to dispatcher\n",
      "12:40:14 DISPATCHER: Trying to submit another job.\n",
      "12:40:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:40:14 DISPATCHER: starting job (0, 0, 32) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:40:14 DISPATCHER: job (0, 0, 32) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:40:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:40:14 WORKER: start processing job (0, 0, 32)\n",
      "12:40:14 WORKER: args: ()\n",
      "12:40:14 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 74, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:40:24 WORKER: done with job (0, 0, 32), trying to register it.\n",
      "12:40:24 WORKER: registered result for job (0, 0, 32) with dispatcher\n",
      "12:40:24 DISPATCHER: job (0, 0, 32) finished\n",
      "12:40:24 DISPATCHER: register_result: lock acquired\n",
      "12:40:24 DISPATCHER: job (0, 0, 32) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:40:24 job_id: (0, 0, 32)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 74, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 776.8866141755096, 'info': {'L1': 776.8866141755096, 'L2': 1967.427663949113, 'MAX': 7.930471406927392, 'TrainTime': 8.78125}}\n",
      "exception: None\n",
      "\n",
      "12:40:24 job_callback for (0, 0, 32) started\n",
      "12:40:24 DISPATCHER: Trying to submit another job.\n",
      "12:40:24 job_callback for (0, 0, 32) got condition\n",
      "12:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:40:24 done building a new model for budget 12.345679 based on 8/28 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:40:24 HBMASTER: Trying to run another job!\n",
      "12:40:24 job_callback for (0, 0, 32) finished\n",
      "12:40:24 start sampling a new configuration.\n",
      "12:40:24 best_vector: [2, 1, 0.6076369382873289, 0, 0.5101063439122666, 0.722010848013319, 3], 1.1732676678939458e-31, 0.0852320427268769, -0.0015061898055623033\n",
      "12:40:24 done sampling a new configuration.\n",
      "12:40:24 HBMASTER: schedule new run for iteration 0\n",
      "12:40:24 HBMASTER: trying submitting job (0, 0, 33) to dispatcher\n",
      "12:40:24 HBMASTER: submitting job (0, 0, 33) to dispatcher\n",
      "12:40:24 DISPATCHER: trying to submit job (0, 0, 33)\n",
      "12:40:24 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:40:24 HBMASTER: job (0, 0, 33) submitted to dispatcher\n",
      "12:40:24 DISPATCHER: Trying to submit another job.\n",
      "12:40:24 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:40:24 DISPATCHER: starting job (0, 0, 33) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:40:24 DISPATCHER: job (0, 0, 33) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:40:24 WORKER: start processing job (0, 0, 33)\n",
      "12:40:24 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:40:24 WORKER: args: ()\n",
      "12:40:24 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 75, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:04 WORKER: done with job (0, 0, 33), trying to register it.\n",
      "12:41:04 WORKER: registered result for job (0, 0, 33) with dispatcher\n",
      "12:41:04 DISPATCHER: job (0, 0, 33) finished\n",
      "12:41:04 DISPATCHER: register_result: lock acquired\n",
      "12:41:04 DISPATCHER: job (0, 0, 33) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:41:04 job_id: (0, 0, 33)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 75, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 732.9381910137259, 'info': {'L1': 732.9381910137259, 'L2': 1760.0563428635992, 'MAX': 7.655774987911865, 'TrainTime': 45.859375}}\n",
      "exception: None\n",
      "\n",
      "12:41:04 job_callback for (0, 0, 33) started\n",
      "12:41:04 DISPATCHER: Trying to submit another job.\n",
      "12:41:04 job_callback for (0, 0, 33) got condition\n",
      "12:41:04 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:41:04 done building a new model for budget 12.345679 based on 8/28 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:41:04 HBMASTER: Trying to run another job!\n",
      "12:41:04 job_callback for (0, 0, 33) finished\n",
      "12:41:04 start sampling a new configuration.\n",
      "12:41:04 best_vector: [3, 1, 0.4202610331328295, 0, 0.5474429512350836, 0.7166313995863376, 3], 1.5537521398722007e-31, 0.06436032970369727, -0.0012461427117195904\n",
      "12:41:04 done sampling a new configuration.\n",
      "12:41:04 HBMASTER: schedule new run for iteration 0\n",
      "12:41:04 HBMASTER: trying submitting job (0, 0, 34) to dispatcher\n",
      "12:41:04 HBMASTER: submitting job (0, 0, 34) to dispatcher\n",
      "12:41:04 DISPATCHER: trying to submit job (0, 0, 34)\n",
      "12:41:04 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:41:04 HBMASTER: job (0, 0, 34) submitted to dispatcher\n",
      "12:41:04 DISPATCHER: Trying to submit another job.\n",
      "12:41:04 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:41:04 DISPATCHER: starting job (0, 0, 34) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:41:04 DISPATCHER: job (0, 0, 34) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:41:04 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:41:04 WORKER: start processing job (0, 0, 34)\n",
      "12:41:04 WORKER: args: ()\n",
      "12:41:04 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 28, 'numNeurons': 75, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:41:11 DISPATCHER: Starting worker discovery\n",
      "12:41:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:41:11 DISPATCHER: Finished worker discovery\n",
      "12:41:26 WORKER: done with job (0, 0, 34), trying to register it.\n",
      "12:41:26 WORKER: registered result for job (0, 0, 34) with dispatcher\n",
      "12:41:26 DISPATCHER: job (0, 0, 34) finished\n",
      "12:41:26 DISPATCHER: register_result: lock acquired\n",
      "12:41:26 DISPATCHER: job (0, 0, 34) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:41:26 job_id: (0, 0, 34)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 28, 'numNeurons': 75, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 917.959630875241, 'info': {'L1': 917.959630875241, 'L2': 2714.606018626784, 'MAX': 8.81217781422107, 'TrainTime': 23.4375}}\n",
      "exception: None\n",
      "\n",
      "12:41:26 job_callback for (0, 0, 34) started\n",
      "12:41:26 DISPATCHER: Trying to submit another job.\n",
      "12:41:26 job_callback for (0, 0, 34) got condition\n",
      "12:41:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:41:26 done building a new model for budget 12.345679 based on 8/29 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:41:26 HBMASTER: Trying to run another job!\n",
      "12:41:26 job_callback for (0, 0, 34) finished\n",
      "12:41:26 start sampling a new configuration.\n",
      "12:41:26 best_vector: [2, 1, 0.6091759522399194, 0, 0.22696191129885693, 0.6267477315751308, 1], 8.990931962530349e-32, 0.11122317510214666, -0.002427647044848999\n",
      "12:41:26 done sampling a new configuration.\n",
      "12:41:26 HBMASTER: schedule new run for iteration 0\n",
      "12:41:26 HBMASTER: trying submitting job (0, 0, 35) to dispatcher\n",
      "12:41:26 HBMASTER: submitting job (0, 0, 35) to dispatcher\n",
      "12:41:26 DISPATCHER: trying to submit job (0, 0, 35)\n",
      "12:41:26 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:41:26 HBMASTER: job (0, 0, 35) submitted to dispatcher\n",
      "12:41:26 DISPATCHER: Trying to submit another job.\n",
      "12:41:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:41:26 DISPATCHER: starting job (0, 0, 35) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:41:26 DISPATCHER: job (0, 0, 35) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:41:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:41:26 WORKER: start processing job (0, 0, 35)\n",
      "12:41:26 WORKER: args: ()\n",
      "12:41:26 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 13, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:42:11 DISPATCHER: Starting worker discovery\n",
      "12:42:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:42:11 DISPATCHER: Finished worker discovery\n",
      "12:42:14 WORKER: done with job (0, 0, 35), trying to register it.\n",
      "12:42:14 WORKER: registered result for job (0, 0, 35) with dispatcher\n",
      "12:42:14 DISPATCHER: job (0, 0, 35) finished\n",
      "12:42:14 DISPATCHER: register_result: lock acquired\n",
      "12:42:14 DISPATCHER: job (0, 0, 35) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:42:14 job_id: (0, 0, 35)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 13, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 694.2862304290904, 'info': {'L1': 694.2862304290904, 'L2': 1587.4346870329, 'MAX': 7.413866556858704, 'TrainTime': 54.0625}}\n",
      "exception: None\n",
      "\n",
      "12:42:14 job_callback for (0, 0, 35) started\n",
      "12:42:14 DISPATCHER: Trying to submit another job.\n",
      "12:42:14 job_callback for (0, 0, 35) got condition\n",
      "12:42:14 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:42:14 done building a new model for budget 12.345679 based on 8/30 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:42:14 HBMASTER: Trying to run another job!\n",
      "12:42:14 job_callback for (0, 0, 35) finished\n",
      "12:42:14 start sampling a new configuration.\n",
      "12:42:14 best_vector: [0, 0, 0.899022152434333, 0, 0.08234653084048033, 0.2634629567459862, 1], 1.98468789076719e-31, 0.05038575610059502, -0.00012802989421902472\n",
      "12:42:14 done sampling a new configuration.\n",
      "12:42:14 HBMASTER: schedule new run for iteration 0\n",
      "12:42:14 HBMASTER: trying submitting job (0, 0, 36) to dispatcher\n",
      "12:42:14 HBMASTER: submitting job (0, 0, 36) to dispatcher\n",
      "12:42:14 DISPATCHER: trying to submit job (0, 0, 36)\n",
      "12:42:14 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:42:14 HBMASTER: job (0, 0, 36) submitted to dispatcher\n",
      "12:42:14 DISPATCHER: Trying to submit another job.\n",
      "12:42:14 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:42:14 DISPATCHER: starting job (0, 0, 36) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:42:14 DISPATCHER: job (0, 0, 36) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:42:14 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:42:14 WORKER: start processing job (0, 0, 36)\n",
      "12:42:14 WORKER: args: ()\n",
      "12:42:14 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 6, 'numNeurons': 33, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:43:11 DISPATCHER: Starting worker discovery\n",
      "12:43:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:43:11 DISPATCHER: Finished worker discovery\n",
      "12:44:11 DISPATCHER: Starting worker discovery\n",
      "12:44:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:44:11 DISPATCHER: Finished worker discovery\n",
      "12:44:34 WORKER: done with job (0, 0, 36), trying to register it.\n",
      "12:44:34 WORKER: registered result for job (0, 0, 36) with dispatcher\n",
      "12:44:34 DISPATCHER: job (0, 0, 36) finished\n",
      "12:44:34 DISPATCHER: register_result: lock acquired\n",
      "12:44:34 DISPATCHER: job (0, 0, 36) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:44:34 job_id: (0, 0, 36)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 6, 'numNeurons': 33, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 183.71070357008745, 'info': {'L1': 183.71070357008745, 'L2': 157.342835773509, 'MAX': 3.8178639325771484, 'TrainTime': 160.75}}\n",
      "exception: None\n",
      "\n",
      "12:44:34 job_callback for (0, 0, 36) started\n",
      "12:44:34 DISPATCHER: Trying to submit another job.\n",
      "12:44:34 job_callback for (0, 0, 36) got condition\n",
      "12:44:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:44:34 done building a new model for budget 12.345679 based on 8/31 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:44:34 HBMASTER: Trying to run another job!\n",
      "12:44:34 job_callback for (0, 0, 36) finished\n",
      "12:44:34 start sampling a new configuration.\n",
      "12:44:34 best_vector: [3, 1, 0.48212728443532427, 0, 0.14660753071742955, 0.5781482256277886, 1], 2.762643936472345e-31, 0.03619720901409078, -0.0010404421057066628\n",
      "12:44:34 done sampling a new configuration.\n",
      "12:44:34 HBMASTER: schedule new run for iteration 0\n",
      "12:44:34 HBMASTER: trying submitting job (0, 0, 37) to dispatcher\n",
      "12:44:34 HBMASTER: submitting job (0, 0, 37) to dispatcher\n",
      "12:44:34 DISPATCHER: trying to submit job (0, 0, 37)\n",
      "12:44:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:44:34 HBMASTER: job (0, 0, 37) submitted to dispatcher\n",
      "12:44:34 DISPATCHER: Trying to submit another job.\n",
      "12:44:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:44:34 DISPATCHER: starting job (0, 0, 37) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:44:34 DISPATCHER: job (0, 0, 37) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:44:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:44:34 WORKER: start processing job (0, 0, 37)\n",
      "12:44:34 WORKER: args: ()\n",
      "12:44:34 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 9, 'numNeurons': 62, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:44:58 WORKER: done with job (0, 0, 37), trying to register it.\n",
      "12:44:58 WORKER: registered result for job (0, 0, 37) with dispatcher\n",
      "12:44:58 DISPATCHER: job (0, 0, 37) finished\n",
      "12:44:58 DISPATCHER: register_result: lock acquired\n",
      "12:44:58 DISPATCHER: job (0, 0, 37) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:44:58 job_id: (0, 0, 37)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 9, 'numNeurons': 62, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 659.6654750694763, 'info': {'L1': 659.6654750694763, 'L2': 1440.6114957276063, 'MAX': 7.1969537508246155, 'TrainTime': 25.171875}}\n",
      "exception: None\n",
      "\n",
      "12:44:58 job_callback for (0, 0, 37) started\n",
      "12:44:58 DISPATCHER: Trying to submit another job.\n",
      "12:44:58 job_callback for (0, 0, 37) got condition\n",
      "12:44:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:44:58 done building a new model for budget 12.345679 based on 8/32 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:44:58 HBMASTER: Trying to run another job!\n",
      "12:44:58 job_callback for (0, 0, 37) finished\n",
      "12:44:58 start sampling a new configuration.\n",
      "12:44:58 done sampling a new configuration.\n",
      "12:44:58 HBMASTER: schedule new run for iteration 0\n",
      "12:44:58 HBMASTER: trying submitting job (0, 0, 38) to dispatcher\n",
      "12:44:58 HBMASTER: submitting job (0, 0, 38) to dispatcher\n",
      "12:44:58 DISPATCHER: trying to submit job (0, 0, 38)\n",
      "12:44:58 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:44:58 HBMASTER: job (0, 0, 38) submitted to dispatcher\n",
      "12:44:58 DISPATCHER: Trying to submit another job.\n",
      "12:44:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:44:58 DISPATCHER: starting job (0, 0, 38) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:44:58 DISPATCHER: job (0, 0, 38) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:44:58 WORKER: start processing job (0, 0, 38)\n",
      "12:44:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:44:58 WORKER: args: ()\n",
      "12:44:58 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 7, 'loss': 'mse', 'numLayers': 18, 'numNeurons': 84, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 5000 \n",
      "Total batches: 11 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:45:11 DISPATCHER: Starting worker discovery\n",
      "12:45:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:45:11 DISPATCHER: Finished worker discovery\n",
      "12:45:20 WORKER: done with job (0, 0, 38), trying to register it.\n",
      "12:45:20 WORKER: registered result for job (0, 0, 38) with dispatcher\n",
      "12:45:20 DISPATCHER: job (0, 0, 38) finished\n",
      "12:45:20 DISPATCHER: register_result: lock acquired\n",
      "12:45:20 DISPATCHER: job (0, 0, 38) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:45:20 job_id: (0, 0, 38)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 7, 'loss': 'mse', 'numLayers': 18, 'numNeurons': 84, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 168.69903663320682, 'info': {'L1': 168.69903663320682, 'L2': 132.65962918799417, 'MAX': 4.239982604980469, 'TrainTime': 23.265625}}\n",
      "exception: None\n",
      "\n",
      "12:45:20 job_callback for (0, 0, 38) started\n",
      "12:45:20 DISPATCHER: Trying to submit another job.\n",
      "12:45:20 job_callback for (0, 0, 38) got condition\n",
      "12:45:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:45:20 done building a new model for budget 12.345679 based on 8/33 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:45:20 HBMASTER: Trying to run another job!\n",
      "12:45:20 job_callback for (0, 0, 38) finished\n",
      "12:45:20 start sampling a new configuration.\n",
      "12:45:20 best_vector: [1, 0, 0.9386439915636977, 1, 0.1975239135732055, 0.07582827623548893, 0], 4.0097526361198955e-31, 0.02493919427827016, -0.0004264932243739005\n",
      "12:45:20 done sampling a new configuration.\n",
      "12:45:20 HBMASTER: schedule new run for iteration 0\n",
      "12:45:20 HBMASTER: trying submitting job (0, 0, 39) to dispatcher\n",
      "12:45:20 HBMASTER: submitting job (0, 0, 39) to dispatcher\n",
      "12:45:20 DISPATCHER: trying to submit job (0, 0, 39)\n",
      "12:45:20 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:45:20 HBMASTER: job (0, 0, 39) submitted to dispatcher\n",
      "12:45:20 DISPATCHER: Trying to submit another job.\n",
      "12:45:20 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:45:20 DISPATCHER: starting job (0, 0, 39) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:45:20 DISPATCHER: job (0, 0, 39) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:45:20 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:45:20 WORKER: start processing job (0, 0, 39)\n",
      "12:45:20 WORKER: args: ()\n",
      "12:45:20 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 11, 'numNeurons': 16, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:46:11 DISPATCHER: Starting worker discovery\n",
      "12:46:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:46:11 DISPATCHER: Finished worker discovery\n",
      "12:46:11 WORKER: done with job (0, 0, 39), trying to register it.\n",
      "12:46:11 WORKER: registered result for job (0, 0, 39) with dispatcher\n",
      "12:46:11 DISPATCHER: job (0, 0, 39) finished\n",
      "12:46:11 DISPATCHER: register_result: lock acquired\n",
      "12:46:11 DISPATCHER: job (0, 0, 39) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:46:11 job_id: (0, 0, 39)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 11, 'numNeurons': 16, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 551.8677298839821, 'info': {'L1': 551.8677298839821, 'L2': 2144.836398617387, 'MAX': 27.55389829549219, 'TrainTime': 57.546875}}\n",
      "exception: None\n",
      "\n",
      "12:46:11 job_callback for (0, 0, 39) started\n",
      "12:46:11 DISPATCHER: Trying to submit another job.\n",
      "12:46:11 job_callback for (0, 0, 39) got condition\n",
      "12:46:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:46:11 done building a new model for budget 12.345679 based on 8/34 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:46:11 HBMASTER: Trying to run another job!\n",
      "12:46:11 job_callback for (0, 0, 39) finished\n",
      "12:46:11 start sampling a new configuration.\n",
      "12:46:11 best_vector: [3, 0, 0.8798602000255941, 0, 0.04533895820623664, 0.17984288136504756, 4], 2.002685659188539e-31, 0.04993294855894591, -0.0007016495451528922\n",
      "12:46:11 done sampling a new configuration.\n",
      "12:46:11 HBMASTER: schedule new run for iteration 0\n",
      "12:46:11 HBMASTER: trying submitting job (0, 0, 40) to dispatcher\n",
      "12:46:11 HBMASTER: submitting job (0, 0, 40) to dispatcher\n",
      "12:46:11 DISPATCHER: trying to submit job (0, 0, 40)\n",
      "12:46:11 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:46:11 HBMASTER: job (0, 0, 40) submitted to dispatcher\n",
      "12:46:11 DISPATCHER: Trying to submit another job.\n",
      "12:46:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:46:11 DISPATCHER: starting job (0, 0, 40) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:46:11 DISPATCHER: job (0, 0, 40) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:46:11 WORKER: start processing job (0, 0, 40)\n",
      "12:46:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:46:11 WORKER: args: ()\n",
      "12:46:11 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 26, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:47:11 DISPATCHER: Starting worker discovery\n",
      "12:47:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:47:11 DISPATCHER: Finished worker discovery\n",
      "12:48:11 DISPATCHER: Starting worker discovery\n",
      "12:48:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:48:11 DISPATCHER: Finished worker discovery\n",
      "12:48:36 WORKER: done with job (0, 0, 40), trying to register it.\n",
      "12:48:36 WORKER: registered result for job (0, 0, 40) with dispatcher\n",
      "12:48:36 DISPATCHER: job (0, 0, 40) finished\n",
      "12:48:36 DISPATCHER: register_result: lock acquired\n",
      "12:48:36 DISPATCHER: job (0, 0, 40) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:48:36 job_id: (0, 0, 40)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 26, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: None\n",
      "exception: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 83, in compute\n",
      "    pred = functional.eval(m,[self.test_gridObj.grid[:,i] for i in range(self.test_gridObj.grid.shape[1])])\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\sciann\\functionals\\mlp_functional.py\", line 157, in eval\n",
      "    y_pred = to_list(model(xs_vals))\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3822, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3759, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1504, in _make_callable_from_options\n",
      "    self._extend_graph()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1388, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InternalError: Constraining by assigned device should not cause an error. Original root's assigned device name: /job:localhost/replica:0/task:0/device::* node's assigned device name \"/job:localhost/replica:0/task:0/device:CPU:0. Error: Cannot merge devices with incompatible types: '/job:localhost/replica:0/task:0/device::*' and '/job:localhost/replica:0/task:0/device:CPU:0'\n",
      "\n",
      "\n",
      "12:48:36 job_callback for (0, 0, 40) started\n",
      "12:48:36 DISPATCHER: Trying to submit another job.\n",
      "12:48:36 job_callback for (0, 0, 40) got condition\n",
      "12:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:48:36 job (0, 0, 40) failed with exception\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\hpbandster\\core\\worker.py\", line 206, in start_computation\n",
      "    result = {'result': self.compute(*args, config_id=id, **kwargs),\n",
      "  File \"..\\Pinn_Worker.py\", line 83, in compute\n",
      "    pred = functional.eval(m,[self.test_gridObj.grid[:,i] for i in range(self.test_gridObj.grid.shape[1])])\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\sciann\\functionals\\mlp_functional.py\", line 157, in eval\n",
      "    y_pred = to_list(model(xs_vals))\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3822, in __call__\n",
      "    self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3759, in _make_callable\n",
      "    callable_fn = session._make_callable_from_options(callable_opts)\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1504, in _make_callable_from_options\n",
      "    self._extend_graph()\n",
      "  File \"C:\\Users\\Felix\\anaconda3\\envs\\MENDERS\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1388, in _extend_graph\n",
      "    tf_session.ExtendSession(self._session)\n",
      "tensorflow.python.framework.errors_impl.InternalError: Constraining by assigned device should not cause an error. Original root's assigned device name: /job:localhost/replica:0/task:0/device::* node's assigned device name \"/job:localhost/replica:0/task:0/device:CPU:0. Error: Cannot merge devices with incompatible types: '/job:localhost/replica:0/task:0/device::*' and '/job:localhost/replica:0/task:0/device:CPU:0'\n",
      "\n",
      "12:48:36 done building a new model for budget 12.345679 based on 8/34 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:48:36 HBMASTER: Trying to run another job!\n",
      "12:48:36 job_callback for (0, 0, 40) finished\n",
      "12:48:36 start sampling a new configuration.\n",
      "12:48:36 best_vector: [1, 0, 0.9891397196423881, 1, 0.014365604267880944, 0.3805119303323775, 4], 2.060961377717695e-31, 0.0485210451205737, -1.1654097530385666e-05\n",
      "12:48:36 done sampling a new configuration.\n",
      "12:48:36 HBMASTER: schedule new run for iteration 0\n",
      "12:48:36 HBMASTER: trying submitting job (0, 0, 41) to dispatcher\n",
      "12:48:36 HBMASTER: submitting job (0, 0, 41) to dispatcher\n",
      "12:48:36 DISPATCHER: trying to submit job (0, 0, 41)\n",
      "12:48:36 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:48:36 HBMASTER: job (0, 0, 41) submitted to dispatcher\n",
      "12:48:36 DISPATCHER: Trying to submit another job.\n",
      "12:48:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:48:36 DISPATCHER: starting job (0, 0, 41) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:48:36 DISPATCHER: job (0, 0, 41) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:48:36 WORKER: start processing job (0, 0, 41)\n",
      "12:48:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:48:36 WORKER: args: ()\n",
      "12:48:36 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 2, 'numNeurons': 44, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:49:11 DISPATCHER: Starting worker discovery\n",
      "12:49:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:49:11 DISPATCHER: Finished worker discovery\n",
      "12:49:23 WORKER: done with job (0, 0, 41), trying to register it.\n",
      "12:49:23 WORKER: registered result for job (0, 0, 41) with dispatcher\n",
      "12:49:23 DISPATCHER: job (0, 0, 41) finished\n",
      "12:49:23 DISPATCHER: register_result: lock acquired\n",
      "12:49:23 DISPATCHER: job (0, 0, 41) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:49:23 job_id: (0, 0, 41)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 2, 'numNeurons': 44, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 772.6368575412743, 'info': {'L1': 772.6368575412743, 'L2': 1946.8492337808882, 'MAX': 7.903910427963421, 'TrainTime': 54.375}}\n",
      "exception: None\n",
      "\n",
      "12:49:23 job_callback for (0, 0, 41) started\n",
      "12:49:23 DISPATCHER: Trying to submit another job.\n",
      "12:49:23 job_callback for (0, 0, 41) got condition\n",
      "12:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:49:23 done building a new model for budget 12.345679 based on 8/35 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:49:23 HBMASTER: Trying to run another job!\n",
      "12:49:23 job_callback for (0, 0, 41) finished\n",
      "12:49:23 start sampling a new configuration.\n",
      "12:49:23 best_vector: [3, 0, 0.9525016363595192, 0, 0.2967885404665979, 0.1541568871437117, 2], 3.2589545458986365e-31, 0.030684686942273883, -0.0008502551015320571\n",
      "12:49:23 done sampling a new configuration.\n",
      "12:49:23 HBMASTER: schedule new run for iteration 0\n",
      "12:49:23 HBMASTER: trying submitting job (0, 0, 42) to dispatcher\n",
      "12:49:23 HBMASTER: submitting job (0, 0, 42) to dispatcher\n",
      "12:49:23 DISPATCHER: trying to submit job (0, 0, 42)\n",
      "12:49:23 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:49:23 HBMASTER: job (0, 0, 42) submitted to dispatcher\n",
      "12:49:23 DISPATCHER: Trying to submit another job.\n",
      "12:49:23 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:49:23 DISPATCHER: starting job (0, 0, 42) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:49:23 DISPATCHER: job (0, 0, 42) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:49:23 WORKER: start processing job (0, 0, 42)\n",
      "12:49:23 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:49:23 WORKER: args: ()\n",
      "12:49:23 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 16, 'numNeurons': 24, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:50:11 DISPATCHER: Starting worker discovery\n",
      "12:50:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:50:11 DISPATCHER: Finished worker discovery\n",
      "12:51:11 DISPATCHER: Starting worker discovery\n",
      "12:51:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:51:11 DISPATCHER: Finished worker discovery\n",
      "12:51:55 WORKER: done with job (0, 0, 42), trying to register it.\n",
      "12:51:55 WORKER: registered result for job (0, 0, 42) with dispatcher\n",
      "12:51:55 DISPATCHER: job (0, 0, 42) finished\n",
      "12:51:55 DISPATCHER: register_result: lock acquired\n",
      "12:51:55 DISPATCHER: job (0, 0, 42) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:51:55 job_id: (0, 0, 42)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 16, 'numNeurons': 24, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 130.30767206998598, 'info': {'L1': 130.30767206998598, 'L2': 92.29096056299628, 'MAX': 4.261926966034766, 'TrainTime': 172.078125}}\n",
      "exception: None\n",
      "\n",
      "12:51:55 job_callback for (0, 0, 42) started\n",
      "12:51:55 DISPATCHER: Trying to submit another job.\n",
      "12:51:55 job_callback for (0, 0, 42) got condition\n",
      "12:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:51:55 done building a new model for budget 12.345679 based on 8/36 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:51:55 HBMASTER: Trying to run another job!\n",
      "12:51:55 job_callback for (0, 0, 42) finished\n",
      "12:51:55 start sampling a new configuration.\n",
      "12:51:55 done sampling a new configuration.\n",
      "12:51:55 HBMASTER: schedule new run for iteration 0\n",
      "12:51:55 HBMASTER: trying submitting job (0, 0, 43) to dispatcher\n",
      "12:51:55 HBMASTER: submitting job (0, 0, 43) to dispatcher\n",
      "12:51:55 DISPATCHER: trying to submit job (0, 0, 43)\n",
      "12:51:55 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:51:55 HBMASTER: job (0, 0, 43) submitted to dispatcher\n",
      "12:51:55 DISPATCHER: Trying to submit another job.\n",
      "12:51:55 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:51:55 DISPATCHER: starting job (0, 0, 43) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:51:55 DISPATCHER: job (0, 0, 43) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:51:55 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:51:55 WORKER: start processing job (0, 0, 43)\n",
      "12:51:55 WORKER: args: ()\n",
      "12:51:55 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 15, 'numNeurons': 87, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:11 DISPATCHER: Starting worker discovery\n",
      "12:52:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:52:11 DISPATCHER: Finished worker discovery\n",
      "12:52:12 WORKER: done with job (0, 0, 43), trying to register it.\n",
      "12:52:12 WORKER: registered result for job (0, 0, 43) with dispatcher\n",
      "12:52:12 DISPATCHER: job (0, 0, 43) finished\n",
      "12:52:12 DISPATCHER: register_result: lock acquired\n",
      "12:52:12 DISPATCHER: job (0, 0, 43) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:52:12 job_id: (0, 0, 43)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 15, 'numNeurons': 87, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 137.4098002509437, 'info': {'L1': 137.4098002509437, 'L2': 89.27376487875733, 'MAX': 3.8051815032958984, 'TrainTime': 16.90625}}\n",
      "exception: None\n",
      "\n",
      "12:52:12 job_callback for (0, 0, 43) started\n",
      "12:52:12 DISPATCHER: Trying to submit another job.\n",
      "12:52:12 job_callback for (0, 0, 43) got condition\n",
      "12:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:52:12 done building a new model for budget 12.345679 based on 8/37 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:52:12 HBMASTER: Trying to run another job!\n",
      "12:52:12 job_callback for (0, 0, 43) finished\n",
      "12:52:12 start sampling a new configuration.\n",
      "12:52:12 best_vector: [1, 0, 0.6955165281096964, 0, 0.056652537452367056, 0.4992106825590947, 1], 2.4888641443793187e-31, 0.04017897088751638, -0.0002953489283120744\n",
      "12:52:12 done sampling a new configuration.\n",
      "12:52:12 HBMASTER: schedule new run for iteration 0\n",
      "12:52:12 HBMASTER: trying submitting job (0, 0, 44) to dispatcher\n",
      "12:52:12 HBMASTER: submitting job (0, 0, 44) to dispatcher\n",
      "12:52:12 DISPATCHER: trying to submit job (0, 0, 44)\n",
      "12:52:12 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:52:12 HBMASTER: job (0, 0, 44) submitted to dispatcher\n",
      "12:52:12 DISPATCHER: Trying to submit another job.\n",
      "12:52:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:52:12 DISPATCHER: starting job (0, 0, 44) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:52:12 DISPATCHER: job (0, 0, 44) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:52:12 WORKER: start processing job (0, 0, 44)\n",
      "12:52:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:52:12 WORKER: args: ()\n",
      "12:52:12 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 55, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:52:50 WORKER: done with job (0, 0, 44), trying to register it.\n",
      "12:52:50 WORKER: registered result for job (0, 0, 44) with dispatcher\n",
      "12:52:50 DISPATCHER: job (0, 0, 44) finished\n",
      "12:52:50 DISPATCHER: register_result: lock acquired\n",
      "12:52:50 DISPATCHER: job (0, 0, 44) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:52:50 job_id: (0, 0, 44)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 55, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 222.6518905778036, 'info': {'L1': 222.6518905778036, 'L2': 203.84887294897337, 'MAX': 3.144941207789551, 'TrainTime': 41.109375}}\n",
      "exception: None\n",
      "\n",
      "12:52:50 job_callback for (0, 0, 44) started\n",
      "12:52:50 DISPATCHER: Trying to submit another job.\n",
      "12:52:50 job_callback for (0, 0, 44) got condition\n",
      "12:52:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:52:50 done building a new model for budget 12.345679 based on 8/38 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:52:50 HBMASTER: Trying to run another job!\n",
      "12:52:50 job_callback for (0, 0, 44) finished\n",
      "12:52:50 start sampling a new configuration.\n",
      "12:52:50 done sampling a new configuration.\n",
      "12:52:50 HBMASTER: schedule new run for iteration 0\n",
      "12:52:50 HBMASTER: trying submitting job (0, 0, 45) to dispatcher\n",
      "12:52:50 HBMASTER: submitting job (0, 0, 45) to dispatcher\n",
      "12:52:50 DISPATCHER: trying to submit job (0, 0, 45)\n",
      "12:52:50 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:52:50 HBMASTER: job (0, 0, 45) submitted to dispatcher\n",
      "12:52:50 DISPATCHER: Trying to submit another job.\n",
      "12:52:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:52:50 DISPATCHER: starting job (0, 0, 45) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:52:50 DISPATCHER: job (0, 0, 45) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:52:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:52:50 WORKER: start processing job (0, 0, 45)\n",
      "12:52:50 WORKER: args: ()\n",
      "12:52:50 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 7, 'loss': 'mse', 'numLayers': 50, 'numNeurons': 88, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 10000 \n",
      "Total batches: 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:53:11 DISPATCHER: Starting worker discovery\n",
      "12:53:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:53:11 DISPATCHER: Finished worker discovery\n",
      "12:53:38 WORKER: done with job (0, 0, 45), trying to register it.\n",
      "12:53:38 WORKER: registered result for job (0, 0, 45) with dispatcher\n",
      "12:53:38 DISPATCHER: job (0, 0, 45) finished\n",
      "12:53:38 DISPATCHER: register_result: lock acquired\n",
      "12:53:38 DISPATCHER: job (0, 0, 45) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:53:38 job_id: (0, 0, 45)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 7, 'loss': 'mse', 'numLayers': 50, 'numNeurons': 88, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 251.0481265644342, 'info': {'L1': 251.0481265644342, 'L2': 243.8813290828013, 'MAX': 4.498307861065552, 'TrainTime': 57.59375}}\n",
      "exception: None\n",
      "\n",
      "12:53:38 job_callback for (0, 0, 45) started\n",
      "12:53:38 DISPATCHER: Trying to submit another job.\n",
      "12:53:38 job_callback for (0, 0, 45) got condition\n",
      "12:53:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:53:38 done building a new model for budget 12.345679 based on 8/39 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:53:38 HBMASTER: Trying to run another job!\n",
      "12:53:38 job_callback for (0, 0, 45) finished\n",
      "12:53:38 start sampling a new configuration.\n",
      "12:53:38 done sampling a new configuration.\n",
      "12:53:38 HBMASTER: schedule new run for iteration 0\n",
      "12:53:38 HBMASTER: trying submitting job (0, 0, 46) to dispatcher\n",
      "12:53:38 HBMASTER: submitting job (0, 0, 46) to dispatcher\n",
      "12:53:38 DISPATCHER: trying to submit job (0, 0, 46)\n",
      "12:53:38 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:53:38 HBMASTER: job (0, 0, 46) submitted to dispatcher\n",
      "12:53:38 DISPATCHER: Trying to submit another job.\n",
      "12:53:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:53:38 DISPATCHER: starting job (0, 0, 46) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:53:38 DISPATCHER: job (0, 0, 46) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:53:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:53:38 WORKER: start processing job (0, 0, 46)\n",
      "12:53:38 WORKER: args: ()\n",
      "12:53:38 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 3, 'loss': 'mse', 'numLayers': 12, 'numNeurons': 78, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:02 WORKER: done with job (0, 0, 46), trying to register it.\n",
      "12:54:02 WORKER: registered result for job (0, 0, 46) with dispatcher\n",
      "12:54:02 DISPATCHER: job (0, 0, 46) finished\n",
      "12:54:02 DISPATCHER: register_result: lock acquired\n",
      "12:54:02 DISPATCHER: job (0, 0, 46) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:54:02 job_id: (0, 0, 46)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 3, 'loss': 'mse', 'numLayers': 12, 'numNeurons': 78, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 772.9893534454368, 'info': {'L1': 772.9893534454368, 'L2': 1948.5518178706582, 'MAX': 7.906113527393028, 'TrainTime': 18.734375}}\n",
      "exception: None\n",
      "\n",
      "12:54:02 job_callback for (0, 0, 46) started\n",
      "12:54:02 DISPATCHER: Trying to submit another job.\n",
      "12:54:02 job_callback for (0, 0, 46) got condition\n",
      "12:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:54:02 done building a new model for budget 12.345679 based on 8/39 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:54:02 HBMASTER: Trying to run another job!\n",
      "12:54:02 job_callback for (0, 0, 46) finished\n",
      "12:54:02 start sampling a new configuration.\n",
      "12:54:02 done sampling a new configuration.\n",
      "12:54:02 HBMASTER: schedule new run for iteration 0\n",
      "12:54:02 HBMASTER: trying submitting job (0, 0, 47) to dispatcher\n",
      "12:54:02 HBMASTER: submitting job (0, 0, 47) to dispatcher\n",
      "12:54:02 DISPATCHER: trying to submit job (0, 0, 47)\n",
      "12:54:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:54:02 HBMASTER: job (0, 0, 47) submitted to dispatcher\n",
      "12:54:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:54:02 DISPATCHER: Trying to submit another job.\n",
      "12:54:02 DISPATCHER: starting job (0, 0, 47) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:54:02 DISPATCHER: job (0, 0, 47) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:54:02 WORKER: start processing job (0, 0, 47)\n",
      "12:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:54:02 WORKER: args: ()\n",
      "12:54:02 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 7, 'loss': 'mae', 'numLayers': 7, 'numNeurons': 15, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 10000 \n",
      "Total batches: 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:54:11 DISPATCHER: Starting worker discovery\n",
      "12:54:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:54:11 DISPATCHER: Finished worker discovery\n",
      "12:55:08 WORKER: done with job (0, 0, 47), trying to register it.\n",
      "12:55:08 WORKER: registered result for job (0, 0, 47) with dispatcher\n",
      "12:55:08 DISPATCHER: job (0, 0, 47) finished\n",
      "12:55:08 DISPATCHER: register_result: lock acquired\n",
      "12:55:08 DISPATCHER: job (0, 0, 47) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:55:08 job_id: (0, 0, 47)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 10000, 'denspt': 7, 'loss': 'mae', 'numLayers': 7, 'numNeurons': 15, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 732.0859073683762, 'info': {'L1': 732.0859073683762, 'L2': 1756.151510225884, 'MAX': 7.650444216704056, 'TrainTime': 85.171875}}\n",
      "exception: None\n",
      "\n",
      "12:55:08 job_callback for (0, 0, 47) started\n",
      "12:55:08 DISPATCHER: Trying to submit another job.\n",
      "12:55:08 job_callback for (0, 0, 47) got condition\n",
      "12:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:55:08 done building a new model for budget 12.345679 based on 8/40 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:55:08 HBMASTER: Trying to run another job!\n",
      "12:55:08 job_callback for (0, 0, 47) finished\n",
      "12:55:08 start sampling a new configuration.\n",
      "12:55:08 best_vector: [3, 0, 0.8234824468255117, 1, 0.15112121070781687, 0.20220224294552558, 3], 3.3547275917942394e-31, 0.029808679621142083, -0.0007691956605461228\n",
      "12:55:08 done sampling a new configuration.\n",
      "12:55:08 HBMASTER: schedule new run for iteration 0\n",
      "12:55:08 HBMASTER: trying submitting job (0, 0, 48) to dispatcher\n",
      "12:55:08 HBMASTER: submitting job (0, 0, 48) to dispatcher\n",
      "12:55:08 DISPATCHER: trying to submit job (0, 0, 48)\n",
      "12:55:08 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:55:08 HBMASTER: job (0, 0, 48) submitted to dispatcher\n",
      "12:55:08 DISPATCHER: Trying to submit another job.\n",
      "12:55:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:55:08 DISPATCHER: starting job (0, 0, 48) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:55:08 DISPATCHER: job (0, 0, 48) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:55:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:55:08 WORKER: start processing job (0, 0, 48)\n",
      "12:55:08 WORKER: args: ()\n",
      "12:55:08 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 9, 'numNeurons': 28, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:55:11 DISPATCHER: Starting worker discovery\n",
      "12:55:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:55:11 DISPATCHER: Finished worker discovery\n",
      "12:56:11 DISPATCHER: Starting worker discovery\n",
      "12:56:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:56:11 DISPATCHER: Finished worker discovery\n",
      "12:57:11 DISPATCHER: Starting worker discovery\n",
      "12:57:11 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:57:11 DISPATCHER: Finished worker discovery\n",
      "12:57:29 WORKER: done with job (0, 0, 48), trying to register it.\n",
      "12:57:29 WORKER: registered result for job (0, 0, 48) with dispatcher\n",
      "12:57:29 DISPATCHER: job (0, 0, 48) finished\n",
      "12:57:30 DISPATCHER: register_result: lock acquired\n",
      "12:57:30 DISPATCHER: job (0, 0, 48) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:57:30 job_id: (0, 0, 48)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 9, 'numNeurons': 28, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 269.18335576731033, 'info': {'L1': 269.18335576731033, 'L2': 276.13831552262747, 'MAX': 4.635431684231445, 'TrainTime': 152.46875}}\n",
      "exception: None\n",
      "\n",
      "12:57:30 job_callback for (0, 0, 48) started\n",
      "12:57:30 DISPATCHER: Trying to submit another job.\n",
      "12:57:30 job_callback for (0, 0, 48) got condition\n",
      "12:57:30 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:57:30 done building a new model for budget 12.345679 based on 8/41 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:57:30 HBMASTER: Trying to run another job!\n",
      "12:57:30 job_callback for (0, 0, 48) finished\n",
      "12:57:30 start sampling a new configuration.\n",
      "12:57:30 best_vector: [0, 3, 0.22428065071395953, 0, 0.9975132148166562, 0.7475674412868658, 4], 1.8746217051227565e-30, 0.005334409589237721, -6.874080253305647e-05\n",
      "12:57:30 done sampling a new configuration.\n",
      "12:57:30 HBMASTER: schedule new run for iteration 0\n",
      "12:57:30 HBMASTER: trying submitting job (0, 0, 49) to dispatcher\n",
      "12:57:30 HBMASTER: submitting job (0, 0, 49) to dispatcher\n",
      "12:57:30 DISPATCHER: trying to submit job (0, 0, 49)\n",
      "12:57:30 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:57:30 HBMASTER: job (0, 0, 49) submitted to dispatcher\n",
      "12:57:30 DISPATCHER: Trying to submit another job.\n",
      "12:57:30 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:57:30 DISPATCHER: starting job (0, 0, 49) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:57:30 DISPATCHER: job (0, 0, 49) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:57:30 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:57:30 WORKER: start processing job (0, 0, 49)\n",
      "12:57:30 WORKER: args: ()\n",
      "12:57:30 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 15000, 'denspt': 4, 'loss': 'mae', 'numLayers': 50, 'numNeurons': 78, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10240 \n",
      "Total batches: 1 \n",
      "\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57:48 WORKER: done with job (0, 0, 49), trying to register it.\n",
      "12:57:48 WORKER: registered result for job (0, 0, 49) with dispatcher\n",
      "12:57:48 DISPATCHER: job (0, 0, 49) finished\n",
      "12:57:48 DISPATCHER: register_result: lock acquired\n",
      "12:57:48 DISPATCHER: job (0, 0, 49) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:57:48 job_id: (0, 0, 49)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 15000, 'denspt': 4, 'loss': 'mae', 'numLayers': 50, 'numNeurons': 78, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 777.7564414460174, 'info': {'L1': 777.7564414460174, 'L2': 1971.6535105918788, 'MAX': 7.935907827368066, 'TrainTime': 18.5}}\n",
      "exception: None\n",
      "\n",
      "12:57:48 job_callback for (0, 0, 49) started\n",
      "12:57:48 DISPATCHER: Trying to submit another job.\n",
      "12:57:48 job_callback for (0, 0, 49) got condition\n",
      "12:57:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:57:48 done building a new model for budget 12.345679 based on 8/42 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:57:48 HBMASTER: Trying to run another job!\n",
      "12:57:48 job_callback for (0, 0, 49) finished\n",
      "12:57:48 start sampling a new configuration.\n",
      "12:57:48 done sampling a new configuration.\n",
      "12:57:48 HBMASTER: schedule new run for iteration 0\n",
      "12:57:48 HBMASTER: trying submitting job (0, 0, 50) to dispatcher\n",
      "12:57:48 HBMASTER: submitting job (0, 0, 50) to dispatcher\n",
      "12:57:48 DISPATCHER: trying to submit job (0, 0, 50)\n",
      "12:57:48 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:57:49 HBMASTER: job (0, 0, 50) submitted to dispatcher\n",
      "12:57:49 DISPATCHER: Trying to submit another job.\n",
      "12:57:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:57:49 DISPATCHER: starting job (0, 0, 50) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:57:49 DISPATCHER: job (0, 0, 50) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:57:49 WORKER: start processing job (0, 0, 50)\n",
      "12:57:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:57:49 WORKER: args: ()\n",
      "12:57:49 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 34, 'numNeurons': 11, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:58:11 DISPATCHER: Starting worker discovery\n",
      "12:58:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:58:12 DISPATCHER: Finished worker discovery\n",
      "12:58:34 WORKER: done with job (0, 0, 50), trying to register it.\n",
      "12:58:34 WORKER: registered result for job (0, 0, 50) with dispatcher\n",
      "12:58:34 DISPATCHER: job (0, 0, 50) finished\n",
      "12:58:34 DISPATCHER: register_result: lock acquired\n",
      "12:58:34 DISPATCHER: job (0, 0, 50) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:58:34 job_id: (0, 0, 50)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 34, 'numNeurons': 11, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 768.8546483344546, 'info': {'L1': 768.8546483344546, 'L2': 1928.6297232742531, 'MAX': 7.880271620726273, 'TrainTime': 47.515625}}\n",
      "exception: None\n",
      "\n",
      "12:58:34 job_callback for (0, 0, 50) started\n",
      "12:58:34 DISPATCHER: Trying to submit another job.\n",
      "12:58:34 job_callback for (0, 0, 50) got condition\n",
      "12:58:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:58:34 done building a new model for budget 12.345679 based on 8/43 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:58:34 HBMASTER: Trying to run another job!\n",
      "12:58:34 job_callback for (0, 0, 50) finished\n",
      "12:58:34 start sampling a new configuration.\n",
      "12:58:34 done sampling a new configuration.\n",
      "12:58:34 HBMASTER: schedule new run for iteration 0\n",
      "12:58:34 HBMASTER: trying submitting job (0, 0, 51) to dispatcher\n",
      "12:58:34 HBMASTER: submitting job (0, 0, 51) to dispatcher\n",
      "12:58:34 DISPATCHER: trying to submit job (0, 0, 51)\n",
      "12:58:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:58:34 HBMASTER: job (0, 0, 51) submitted to dispatcher\n",
      "12:58:34 DISPATCHER: Trying to submit another job.\n",
      "12:58:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:58:34 DISPATCHER: starting job (0, 0, 51) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:58:34 DISPATCHER: job (0, 0, 51) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:58:34 WORKER: start processing job (0, 0, 51)\n",
      "12:58:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:58:34 WORKER: args: ()\n",
      "12:58:34 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 45, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:59:12 DISPATCHER: Starting worker discovery\n",
      "12:59:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "12:59:12 DISPATCHER: Finished worker discovery\n",
      "12:59:21 WORKER: done with job (0, 0, 51), trying to register it.\n",
      "12:59:21 WORKER: registered result for job (0, 0, 51) with dispatcher\n",
      "12:59:21 DISPATCHER: job (0, 0, 51) finished\n",
      "12:59:21 DISPATCHER: register_result: lock acquired\n",
      "12:59:21 DISPATCHER: job (0, 0, 51) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "12:59:21 job_id: (0, 0, 51)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 25, 'numNeurons': 45, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 769.7721187837534, 'info': {'L1': 769.7721187837534, 'L2': 1933.0411029743616, 'MAX': 7.886005691861794, 'TrainTime': 49.59375}}\n",
      "exception: None\n",
      "\n",
      "12:59:21 job_callback for (0, 0, 51) started\n",
      "12:59:21 DISPATCHER: Trying to submit another job.\n",
      "12:59:21 job_callback for (0, 0, 51) got condition\n",
      "12:59:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "12:59:21 done building a new model for budget 12.345679 based on 8/44 split\n",
      "Best loss for this budget:107.819295\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12:59:21 HBMASTER: Trying to run another job!\n",
      "12:59:21 job_callback for (0, 0, 51) finished\n",
      "12:59:21 start sampling a new configuration.\n",
      "12:59:21 best_vector: [0, 0, 0.9747375720779585, 0, 0.185779741086266, 0.05055592599717114, 3], 2.599868455277731e-31, 0.03846348448784018, -0.0006054904066305809\n",
      "12:59:21 done sampling a new configuration.\n",
      "12:59:21 HBMASTER: schedule new run for iteration 0\n",
      "12:59:21 HBMASTER: trying submitting job (0, 0, 52) to dispatcher\n",
      "12:59:21 HBMASTER: submitting job (0, 0, 52) to dispatcher\n",
      "12:59:21 DISPATCHER: trying to submit job (0, 0, 52)\n",
      "12:59:21 DISPATCHER: trying to notify the job_runner thread.\n",
      "12:59:21 HBMASTER: job (0, 0, 52) submitted to dispatcher\n",
      "12:59:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "12:59:21 DISPATCHER: Trying to submit another job.\n",
      "12:59:21 DISPATCHER: starting job (0, 0, 52) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:59:21 DISPATCHER: job (0, 0, 52) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "12:59:21 WORKER: start processing job (0, 0, 52)\n",
      "12:59:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "12:59:21 WORKER: args: ()\n",
      "12:59:21 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 11, 'numNeurons': 14, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:00:12 DISPATCHER: Starting worker discovery\n",
      "13:00:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:00:12 DISPATCHER: Finished worker discovery\n",
      "13:01:12 DISPATCHER: Starting worker discovery\n",
      "13:01:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:01:12 DISPATCHER: Finished worker discovery\n",
      "13:02:12 DISPATCHER: Starting worker discovery\n",
      "13:02:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:02:12 DISPATCHER: Finished worker discovery\n",
      "13:03:12 DISPATCHER: Starting worker discovery\n",
      "13:03:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:03:12 DISPATCHER: Finished worker discovery\n",
      "13:03:22 WORKER: done with job (0, 0, 52), trying to register it.\n",
      "13:03:22 WORKER: registered result for job (0, 0, 52) with dispatcher\n",
      "13:03:22 DISPATCHER: job (0, 0, 52) finished\n",
      "13:03:22 DISPATCHER: register_result: lock acquired\n",
      "13:03:22 DISPATCHER: job (0, 0, 52) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:03:22 job_id: (0, 0, 52)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 11, 'numNeurons': 14, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 100.33817159068232, 'info': {'L1': 100.33817159068232, 'L2': 65.35807842669104, 'MAX': 3.227610496301514, 'TrainTime': 255.453125}}\n",
      "exception: None\n",
      "\n",
      "13:03:22 job_callback for (0, 0, 52) started\n",
      "13:03:22 DISPATCHER: Trying to submit another job.\n",
      "13:03:22 job_callback for (0, 0, 52) got condition\n",
      "13:03:22 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:03:22 done building a new model for budget 12.345679 based on 8/45 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:03:22 HBMASTER: Trying to run another job!\n",
      "13:03:22 job_callback for (0, 0, 52) finished\n",
      "13:03:22 start sampling a new configuration.\n",
      "13:03:22 best_vector: [0, 1, 0.3773332376592322, 0, 0.17492755541715788, 0.8809357615867073, 0], 3.496494028660042e-31, 0.028600077443382024, -0.00017699564943850687\n",
      "13:03:22 done sampling a new configuration.\n",
      "13:03:22 HBMASTER: schedule new run for iteration 0\n",
      "13:03:22 HBMASTER: trying submitting job (0, 0, 53) to dispatcher\n",
      "13:03:22 HBMASTER: submitting job (0, 0, 53) to dispatcher\n",
      "13:03:22 DISPATCHER: trying to submit job (0, 0, 53)\n",
      "13:03:22 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:03:22 HBMASTER: job (0, 0, 53) submitted to dispatcher\n",
      "13:03:22 DISPATCHER: Trying to submit another job.\n",
      "13:03:22 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:03:22 DISPATCHER: starting job (0, 0, 53) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:03:22 DISPATCHER: job (0, 0, 53) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:03:22 WORKER: start processing job (0, 0, 53)\n",
      "13:03:22 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:03:22 WORKER: args: ()\n",
      "13:03:22 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 10, 'numNeurons': 90, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:03:53 WORKER: done with job (0, 0, 53), trying to register it.\n",
      "13:03:53 WORKER: registered result for job (0, 0, 53) with dispatcher\n",
      "13:03:53 DISPATCHER: job (0, 0, 53) finished\n",
      "13:03:53 DISPATCHER: register_result: lock acquired\n",
      "13:03:53 DISPATCHER: job (0, 0, 53) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:03:53 job_id: (0, 0, 53)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 10, 'numNeurons': 90, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 278.0966145770491, 'info': {'L1': 278.0966145770491, 'L2': 291.9020654057206, 'MAX': 4.687256253933594, 'TrainTime': 32.609375}}\n",
      "exception: None\n",
      "\n",
      "13:03:53 job_callback for (0, 0, 53) started\n",
      "13:03:53 DISPATCHER: Trying to submit another job.\n",
      "13:03:53 job_callback for (0, 0, 53) got condition\n",
      "13:03:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:03:53 done building a new model for budget 12.345679 based on 8/45 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:03:53 HBMASTER: Trying to run another job!\n",
      "13:03:53 job_callback for (0, 0, 53) finished\n",
      "13:03:53 start sampling a new configuration.\n",
      "13:03:54 best_vector: [3, 1, 0.641679831117243, 1, 0.4619275116221506, 0.8923956597829553, 0], 0.02450072398693504, 0.052297768095966764, 0.001281333181252019\n",
      "13:03:54 done sampling a new configuration.\n",
      "13:03:54 HBMASTER: schedule new run for iteration 0\n",
      "13:03:54 HBMASTER: trying submitting job (0, 0, 54) to dispatcher\n",
      "13:03:54 HBMASTER: submitting job (0, 0, 54) to dispatcher\n",
      "13:03:54 DISPATCHER: trying to submit job (0, 0, 54)\n",
      "13:03:54 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:03:54 HBMASTER: job (0, 0, 54) submitted to dispatcher\n",
      "13:03:54 DISPATCHER: Trying to submit another job.\n",
      "13:03:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:03:54 DISPATCHER: starting job (0, 0, 54) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:03:54 DISPATCHER: job (0, 0, 54) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:03:54 WORKER: start processing job (0, 0, 54)\n",
      "13:03:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:03:54 WORKER: args: ()\n",
      "13:03:54 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 24, 'numNeurons': 91, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:04:12 DISPATCHER: Starting worker discovery\n",
      "13:04:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:04:12 DISPATCHER: Finished worker discovery\n",
      "13:04:48 WORKER: done with job (0, 0, 54), trying to register it.\n",
      "13:04:48 WORKER: registered result for job (0, 0, 54) with dispatcher\n",
      "13:04:48 DISPATCHER: job (0, 0, 54) finished\n",
      "13:04:48 DISPATCHER: register_result: lock acquired\n",
      "13:04:48 DISPATCHER: job (0, 0, 54) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:04:48 job_id: (0, 0, 54)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 24, 'numNeurons': 91, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 565.0526835897743, 'info': {'L1': 565.0526835897743, 'L2': 1076.4640578683698, 'MAX': 6.601859725689575, 'TrainTime': 58.0}}\n",
      "exception: None\n",
      "\n",
      "13:04:48 job_callback for (0, 0, 54) started\n",
      "13:04:48 job_callback for (0, 0, 54) got condition\n",
      "13:04:48 DISPATCHER: Trying to submit another job.\n",
      "13:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:04:48 done building a new model for budget 12.345679 based on 8/46 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:04:48 HBMASTER: Trying to run another job!\n",
      "13:04:48 job_callback for (0, 0, 54) finished\n",
      "13:04:48 start sampling a new configuration.\n",
      "13:04:48 done sampling a new configuration.\n",
      "13:04:48 HBMASTER: schedule new run for iteration 0\n",
      "13:04:48 HBMASTER: trying submitting job (0, 0, 55) to dispatcher\n",
      "13:04:48 HBMASTER: submitting job (0, 0, 55) to dispatcher\n",
      "13:04:48 DISPATCHER: trying to submit job (0, 0, 55)\n",
      "13:04:48 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:04:48 HBMASTER: job (0, 0, 55) submitted to dispatcher\n",
      "13:04:48 DISPATCHER: Trying to submit another job.\n",
      "13:04:48 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:04:48 DISPATCHER: starting job (0, 0, 55) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:04:48 DISPATCHER: job (0, 0, 55) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:04:48 WORKER: start processing job (0, 0, 55)\n",
      "13:04:48 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:04:48 WORKER: args: ()\n",
      "13:04:48 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 5, 'numNeurons': 30, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:05:12 DISPATCHER: Starting worker discovery\n",
      "13:05:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:05:12 DISPATCHER: Finished worker discovery\n",
      "13:06:12 DISPATCHER: Starting worker discovery\n",
      "13:06:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:06:12 DISPATCHER: Finished worker discovery\n",
      "13:07:12 DISPATCHER: Starting worker discovery\n",
      "13:07:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:07:12 DISPATCHER: Finished worker discovery\n",
      "13:08:12 DISPATCHER: Starting worker discovery\n",
      "13:08:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:08:12 DISPATCHER: Finished worker discovery\n",
      "13:09:12 DISPATCHER: Starting worker discovery\n",
      "13:09:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:09:12 DISPATCHER: Finished worker discovery\n",
      "13:09:18 WORKER: done with job (0, 0, 55), trying to register it.\n",
      "13:09:18 WORKER: registered result for job (0, 0, 55) with dispatcher\n",
      "13:09:18 DISPATCHER: job (0, 0, 55) finished\n",
      "13:09:18 DISPATCHER: register_result: lock acquired\n",
      "13:09:18 DISPATCHER: job (0, 0, 55) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:09:18 job_id: (0, 0, 55)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 7, 'loss': 'mse', 'numLayers': 5, 'numNeurons': 30, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 513.2629858823913, 'info': {'L1': 513.2629858823913, 'L2': 899.5532215284094, 'MAX': 6.273031271671936, 'TrainTime': 287.265625}}\n",
      "exception: None\n",
      "\n",
      "13:09:18 job_callback for (0, 0, 55) started\n",
      "13:09:18 DISPATCHER: Trying to submit another job.\n",
      "13:09:18 job_callback for (0, 0, 55) got condition\n",
      "13:09:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:09:18 done building a new model for budget 12.345679 based on 8/47 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:09:18 HBMASTER: Trying to run another job!\n",
      "13:09:18 job_callback for (0, 0, 55) finished\n",
      "13:09:18 start sampling a new configuration.\n",
      "13:09:18 best_vector: [1, 0, 0.8935558110285114, 1, 0.08965944554849094, 0.1104484212637794, 3], 3.034394702416164e-31, 0.03295550177449694, -0.0002915795964277757\n",
      "13:09:18 done sampling a new configuration.\n",
      "13:09:18 HBMASTER: schedule new run for iteration 0\n",
      "13:09:18 HBMASTER: trying submitting job (0, 0, 56) to dispatcher\n",
      "13:09:18 HBMASTER: submitting job (0, 0, 56) to dispatcher\n",
      "13:09:18 DISPATCHER: trying to submit job (0, 0, 56)\n",
      "13:09:18 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:09:18 HBMASTER: job (0, 0, 56) submitted to dispatcher\n",
      "13:09:18 DISPATCHER: Trying to submit another job.\n",
      "13:09:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:09:18 DISPATCHER: starting job (0, 0, 56) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:09:18 DISPATCHER: job (0, 0, 56) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:09:18 WORKER: start processing job (0, 0, 56)\n",
      "13:09:18 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:09:18 WORKER: args: ()\n",
      "13:09:18 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 6, 'numNeurons': 20, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:10:12 DISPATCHER: Starting worker discovery\n",
      "13:10:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:10:12 DISPATCHER: Finished worker discovery\n",
      "13:10:52 WORKER: done with job (0, 0, 56), trying to register it.\n",
      "13:10:52 WORKER: registered result for job (0, 0, 56) with dispatcher\n",
      "13:10:52 DISPATCHER: job (0, 0, 56) finished\n",
      "13:10:52 DISPATCHER: register_result: lock acquired\n",
      "13:10:52 DISPATCHER: job (0, 0, 56) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:10:52 job_id: (0, 0, 56)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 6, 'numNeurons': 20, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 673.4158329596537, 'info': {'L1': 673.4158329596537, 'L2': 4938.613834960019, 'MAX': 36.604259723371094, 'TrainTime': 100.4375}}\n",
      "exception: None\n",
      "\n",
      "13:10:52 job_callback for (0, 0, 56) started\n",
      "13:10:52 DISPATCHER: Trying to submit another job.\n",
      "13:10:52 job_callback for (0, 0, 56) got condition\n",
      "13:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:10:52 done building a new model for budget 12.345679 based on 8/48 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:10:52 HBMASTER: Trying to run another job!\n",
      "13:10:52 job_callback for (0, 0, 56) finished\n",
      "13:10:52 start sampling a new configuration.\n",
      "13:10:52 best_vector: [2, 4, 0.030423967616728498, 1, 0.9339647264863247, 0.35836670232961176, 2], 6.500839737262239e-31, 0.015382628097537746, -0.00012178811342061259\n",
      "13:10:52 done sampling a new configuration.\n",
      "13:10:52 HBMASTER: schedule new run for iteration 0\n",
      "13:10:52 HBMASTER: trying submitting job (0, 0, 57) to dispatcher\n",
      "13:10:52 HBMASTER: submitting job (0, 0, 57) to dispatcher\n",
      "13:10:52 DISPATCHER: trying to submit job (0, 0, 57)\n",
      "13:10:52 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:10:52 HBMASTER: job (0, 0, 57) submitted to dispatcher\n",
      "13:10:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:10:52 DISPATCHER: Trying to submit another job.\n",
      "13:10:52 DISPATCHER: starting job (0, 0, 57) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:10:52 DISPATCHER: job (0, 0, 57) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:10:52 WORKER: start processing job (0, 0, 57)\n",
      "13:10:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:10:52 WORKER: args: ()\n",
      "13:10:52 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 3, 'loss': 'mse', 'numLayers': 47, 'numNeurons': 42, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:11:12 DISPATCHER: Starting worker discovery\n",
      "13:11:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:11:12 DISPATCHER: Finished worker discovery\n",
      "13:11:15 WORKER: done with job (0, 0, 57), trying to register it.\n",
      "13:11:15 WORKER: registered result for job (0, 0, 57) with dispatcher\n",
      "13:11:15 DISPATCHER: job (0, 0, 57) finished\n",
      "13:11:15 DISPATCHER: register_result: lock acquired\n",
      "13:11:15 DISPATCHER: job (0, 0, 57) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:11:15 job_id: (0, 0, 57)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 25000, 'denspt': 3, 'loss': 'mse', 'numLayers': 47, 'numNeurons': 42, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 734.1804501153483, 'info': {'L1': 734.1804501153483, 'L2': 1765.7556866419989, 'MAX': 7.6635444533583374, 'TrainTime': 20.0}}\n",
      "exception: None\n",
      "\n",
      "13:11:15 job_callback for (0, 0, 57) started\n",
      "13:11:15 DISPATCHER: Trying to submit another job.\n",
      "13:11:15 job_callback for (0, 0, 57) got condition\n",
      "13:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:11:15 done building a new model for budget 12.345679 based on 8/49 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:11:15 HBMASTER: Trying to run another job!\n",
      "13:11:15 job_callback for (0, 0, 57) finished\n",
      "13:11:15 start sampling a new configuration.\n",
      "13:11:15 done sampling a new configuration.\n",
      "13:11:15 HBMASTER: schedule new run for iteration 0\n",
      "13:11:15 HBMASTER: trying submitting job (0, 0, 58) to dispatcher\n",
      "13:11:15 HBMASTER: submitting job (0, 0, 58) to dispatcher\n",
      "13:11:15 DISPATCHER: trying to submit job (0, 0, 58)\n",
      "13:11:15 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:11:15 HBMASTER: job (0, 0, 58) submitted to dispatcher\n",
      "13:11:15 DISPATCHER: Trying to submit another job.\n",
      "13:11:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:11:15 DISPATCHER: starting job (0, 0, 58) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:11:15 DISPATCHER: job (0, 0, 58) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:11:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:11:15 WORKER: start processing job (0, 0, 58)\n",
      "13:11:15 WORKER: args: ()\n",
      "13:11:15 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 80, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:12:12 DISPATCHER: Starting worker discovery\n",
      "13:12:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:12:12 DISPATCHER: Finished worker discovery\n",
      "13:12:21 WORKER: done with job (0, 0, 58), trying to register it.\n",
      "13:12:21 WORKER: registered result for job (0, 0, 58) with dispatcher\n",
      "13:12:21 DISPATCHER: job (0, 0, 58) finished\n",
      "13:12:21 DISPATCHER: register_result: lock acquired\n",
      "13:12:21 DISPATCHER: job (0, 0, 58) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:12:21 job_id: (0, 0, 58)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 80, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 541.6527104388476, 'info': {'L1': 541.6527104388476, 'L2': 994.5143498531041, 'MAX': 6.453295625424072, 'TrainTime': 69.296875}}\n",
      "exception: None\n",
      "\n",
      "13:12:21 job_callback for (0, 0, 58) started\n",
      "13:12:21 DISPATCHER: Trying to submit another job.\n",
      "13:12:21 job_callback for (0, 0, 58) got condition\n",
      "13:12:21 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:12:21 done building a new model for budget 12.345679 based on 8/50 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:12:21 HBMASTER: Trying to run another job!\n",
      "13:12:21 job_callback for (0, 0, 58) finished\n",
      "13:12:21 start sampling a new configuration.\n",
      "13:12:21 best_vector: [3, 1, 0.10436265936875655, 1, 0.6630155705055643, 0.8828526427015309, 4], 2.1344857346173678e-30, 0.004684969235361332, -8.574270957831427e-05\n",
      "13:12:21 done sampling a new configuration.\n",
      "13:12:21 HBMASTER: schedule new run for iteration 0\n",
      "13:12:21 HBMASTER: trying submitting job (0, 0, 59) to dispatcher\n",
      "13:12:21 HBMASTER: submitting job (0, 0, 59) to dispatcher\n",
      "13:12:21 DISPATCHER: trying to submit job (0, 0, 59)\n",
      "13:12:21 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:12:21 HBMASTER: job (0, 0, 59) submitted to dispatcher\n",
      "13:12:21 DISPATCHER: Trying to submit another job.\n",
      "13:12:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:12:21 DISPATCHER: starting job (0, 0, 59) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:12:21 DISPATCHER: job (0, 0, 59) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:12:21 WORKER: start processing job (0, 0, 59)\n",
      "13:12:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:12:21 WORKER: args: ()\n",
      "13:12:21 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 3, 'loss': 'mse', 'numLayers': 34, 'numNeurons': 90, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:12:37 WORKER: done with job (0, 0, 59), trying to register it.\n",
      "13:12:37 WORKER: registered result for job (0, 0, 59) with dispatcher\n",
      "13:12:37 DISPATCHER: job (0, 0, 59) finished\n",
      "13:12:37 DISPATCHER: register_result: lock acquired\n",
      "13:12:37 DISPATCHER: job (0, 0, 59) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:12:37 job_id: (0, 0, 59)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 3, 'loss': 'mse', 'numLayers': 34, 'numNeurons': 90, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 984.6786372978203, 'info': {'L1': 984.6786372978203, 'L2': 3111.3001872791283, 'MAX': 9.229171551441834, 'TrainTime': 14.21875}}\n",
      "exception: None\n",
      "\n",
      "13:12:37 job_callback for (0, 0, 59) started\n",
      "13:12:37 DISPATCHER: Trying to submit another job.\n",
      "13:12:37 job_callback for (0, 0, 59) got condition\n",
      "13:12:37 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:12:37 done building a new model for budget 12.345679 based on 9/51 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:12:37 HBMASTER: Trying to run another job!\n",
      "13:12:37 job_callback for (0, 0, 59) finished\n",
      "13:12:37 start sampling a new configuration.\n",
      "13:12:37 best_vector: [3, 1, 0.3019994529098024, 1, 0.00789850101670525, 0.6381106764243832, 0], 0.01716648622293546, 0.02129972003996953, 0.00036564135061851924\n",
      "13:12:37 done sampling a new configuration.\n",
      "13:12:37 HBMASTER: schedule new run for iteration 0\n",
      "13:12:37 HBMASTER: trying submitting job (0, 0, 60) to dispatcher\n",
      "13:12:37 HBMASTER: submitting job (0, 0, 60) to dispatcher\n",
      "13:12:37 DISPATCHER: trying to submit job (0, 0, 60)\n",
      "13:12:37 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:12:37 HBMASTER: job (0, 0, 60) submitted to dispatcher\n",
      "13:12:37 DISPATCHER: Trying to submit another job.\n",
      "13:12:37 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:12:37 DISPATCHER: starting job (0, 0, 60) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:12:37 DISPATCHER: job (0, 0, 60) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:12:37 WORKER: start processing job (0, 0, 60)\n",
      "13:12:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:12:37 WORKER: args: ()\n",
      "13:12:37 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'loss': 'mse', 'numLayers': 2, 'numNeurons': 68, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:13:01 WORKER: done with job (0, 0, 60), trying to register it.\n",
      "13:13:01 WORKER: registered result for job (0, 0, 60) with dispatcher\n",
      "13:13:01 DISPATCHER: job (0, 0, 60) finished\n",
      "13:13:01 DISPATCHER: register_result: lock acquired\n",
      "13:13:01 DISPATCHER: job (0, 0, 60) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:13:01 job_id: (0, 0, 60)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 4, 'loss': 'mse', 'numLayers': 2, 'numNeurons': 68, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 616.6230309061026, 'info': {'L1': 616.6230309061026, 'L2': 1268.3221832393285, 'MAX': 6.926872528767273, 'TrainTime': 23.828125}}\n",
      "exception: None\n",
      "\n",
      "13:13:01 job_callback for (0, 0, 60) started\n",
      "13:13:01 DISPATCHER: Trying to submit another job.\n",
      "13:13:01 job_callback for (0, 0, 60) got condition\n",
      "13:13:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:13:01 done building a new model for budget 12.345679 based on 9/51 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:13:01 HBMASTER: Trying to run another job!\n",
      "13:13:01 job_callback for (0, 0, 60) finished\n",
      "13:13:01 start sampling a new configuration.\n",
      "13:13:01 best_vector: [1, 4, 0.9466027820243015, 0, 0.05465233100167066, 0.08611576099733098, 3], 2.814645682393287e-31, 0.03552845057036459, -0.00010527422146640202\n",
      "13:13:01 done sampling a new configuration.\n",
      "13:13:01 HBMASTER: schedule new run for iteration 0\n",
      "13:13:01 HBMASTER: trying submitting job (0, 0, 61) to dispatcher\n",
      "13:13:01 HBMASTER: submitting job (0, 0, 61) to dispatcher\n",
      "13:13:01 DISPATCHER: trying to submit job (0, 0, 61)\n",
      "13:13:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:13:01 HBMASTER: job (0, 0, 61) submitted to dispatcher\n",
      "13:13:01 DISPATCHER: Trying to submit another job.\n",
      "13:13:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:13:02 DISPATCHER: starting job (0, 0, 61) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:13:02 DISPATCHER: job (0, 0, 61) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:13:02 WORKER: start processing job (0, 0, 61)\n",
      "13:13:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:13:02 WORKER: args: ()\n",
      "13:13:02 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 8, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 17, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 25000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:13:12 DISPATCHER: Starting worker discovery\n",
      "13:13:12 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:13:12 DISPATCHER: Finished worker discovery\n",
      "13:13:35 WORKER: done with job (0, 0, 61), trying to register it.\n",
      "13:13:35 WORKER: registered result for job (0, 0, 61) with dispatcher\n",
      "13:13:35 DISPATCHER: job (0, 0, 61) finished\n",
      "13:13:35 DISPATCHER: register_result: lock acquired\n",
      "13:13:35 DISPATCHER: job (0, 0, 61) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:13:35 job_id: (0, 0, 61)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 8, 'loss': 'mae', 'numLayers': 4, 'numNeurons': 17, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 720.3295857142075, 'info': {'L1': 720.3295857142075, 'L2': 1693.5068054755734, 'MAX': 7.456044197220474, 'TrainTime': 37.78125}}\n",
      "exception: None\n",
      "\n",
      "13:13:35 job_callback for (0, 0, 61) started\n",
      "13:13:35 DISPATCHER: Trying to submit another job.\n",
      "13:13:35 job_callback for (0, 0, 61) got condition\n",
      "13:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:13:35 done building a new model for budget 12.345679 based on 9/52 split\n",
      "Best loss for this budget:100.338172\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:13:35 HBMASTER: Trying to run another job!\n",
      "13:13:35 job_callback for (0, 0, 61) finished\n",
      "13:13:35 start sampling a new configuration.\n",
      "13:13:35 best_vector: [0, 0, 0.8561423469733349, 0, 0.2449141966617765, 0.093519548379008, 3], 1.920473167060168e-31, 0.05207050101776664, -0.0006602750171710476\n",
      "13:13:35 done sampling a new configuration.\n",
      "13:13:35 HBMASTER: schedule new run for iteration 0\n",
      "13:13:35 HBMASTER: trying submitting job (0, 0, 62) to dispatcher\n",
      "13:13:35 HBMASTER: submitting job (0, 0, 62) to dispatcher\n",
      "13:13:35 DISPATCHER: trying to submit job (0, 0, 62)\n",
      "13:13:35 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:13:35 HBMASTER: job (0, 0, 62) submitted to dispatcher\n",
      "13:13:35 DISPATCHER: Trying to submit another job.\n",
      "13:13:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:13:35 DISPATCHER: starting job (0, 0, 62) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:13:35 DISPATCHER: job (0, 0, 62) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:13:35 WORKER: start processing job (0, 0, 62)\n",
      "13:13:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:13:35 WORKER: args: ()\n",
      "13:13:35 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 18, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:14:13 DISPATCHER: Starting worker discovery\n",
      "13:14:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:14:13 DISPATCHER: Finished worker discovery\n",
      "13:15:13 DISPATCHER: Starting worker discovery\n",
      "13:15:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:15:13 DISPATCHER: Finished worker discovery\n",
      "13:16:13 DISPATCHER: Starting worker discovery\n",
      "13:16:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:16:13 DISPATCHER: Finished worker discovery\n",
      "13:17:13 DISPATCHER: Starting worker discovery\n",
      "13:17:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:17:13 DISPATCHER: Finished worker discovery\n",
      "13:18:13 DISPATCHER: Starting worker discovery\n",
      "13:18:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:18:13 DISPATCHER: Finished worker discovery\n",
      "13:18:45 WORKER: done with job (0, 0, 62), trying to register it.\n",
      "13:18:45 WORKER: registered result for job (0, 0, 62) with dispatcher\n",
      "13:18:45 DISPATCHER: job (0, 0, 62) finished\n",
      "13:18:45 DISPATCHER: register_result: lock acquired\n",
      "13:18:45 DISPATCHER: job (0, 0, 62) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:18:45 job_id: (0, 0, 62)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 18, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 98.7672131034462, 'info': {'L1': 98.7672131034462, 'L2': 61.84869059420487, 'MAX': 2.9554270875212403, 'TrainTime': 324.015625}}\n",
      "exception: None\n",
      "\n",
      "13:18:45 job_callback for (0, 0, 62) started\n",
      "13:18:45 DISPATCHER: Trying to submit another job.\n",
      "13:18:45 job_callback for (0, 0, 62) got condition\n",
      "13:18:45 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:18:45 done building a new model for budget 12.345679 based on 9/53 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:18:45 HBMASTER: Trying to run another job!\n",
      "13:18:45 job_callback for (0, 0, 62) finished\n",
      "13:18:45 start sampling a new configuration.\n",
      "13:18:45 done sampling a new configuration.\n",
      "13:18:45 HBMASTER: schedule new run for iteration 0\n",
      "13:18:45 HBMASTER: trying submitting job (0, 0, 63) to dispatcher\n",
      "13:18:45 HBMASTER: submitting job (0, 0, 63) to dispatcher\n",
      "13:18:45 DISPATCHER: trying to submit job (0, 0, 63)\n",
      "13:18:45 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:18:45 HBMASTER: job (0, 0, 63) submitted to dispatcher\n",
      "13:18:45 DISPATCHER: Trying to submit another job.\n",
      "13:18:46 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:18:46 DISPATCHER: starting job (0, 0, 63) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:18:46 DISPATCHER: job (0, 0, 63) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:18:46 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:18:46 WORKER: start processing job (0, 0, 63)\n",
      "13:18:46 WORKER: args: ()\n",
      "13:18:46 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 8, 'loss': 'mae', 'numLayers': 21, 'numNeurons': 49, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 25000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:19:13 DISPATCHER: Starting worker discovery\n",
      "13:19:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:19:13 DISPATCHER: Finished worker discovery\n",
      "13:19:58 WORKER: done with job (0, 0, 63), trying to register it.\n",
      "13:19:58 WORKER: registered result for job (0, 0, 63) with dispatcher\n",
      "13:19:58 DISPATCHER: job (0, 0, 63) finished\n",
      "13:19:58 DISPATCHER: register_result: lock acquired\n",
      "13:19:58 DISPATCHER: job (0, 0, 63) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:19:58 job_id: (0, 0, 63)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 8, 'loss': 'mae', 'numLayers': 21, 'numNeurons': 49, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 537.3109521746344, 'info': {'L1': 537.3109521746344, 'L2': 979.7443012631385, 'MAX': 6.42608527061908, 'TrainTime': 91.515625}}\n",
      "exception: None\n",
      "\n",
      "13:19:58 job_callback for (0, 0, 63) started\n",
      "13:19:58 DISPATCHER: Trying to submit another job.\n",
      "13:19:58 job_callback for (0, 0, 63) got condition\n",
      "13:19:58 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:19:58 done building a new model for budget 12.345679 based on 9/54 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:19:58 HBMASTER: Trying to run another job!\n",
      "13:19:58 job_callback for (0, 0, 63) finished\n",
      "13:19:58 start sampling a new configuration.\n",
      "13:19:58 done sampling a new configuration.\n",
      "13:19:58 HBMASTER: schedule new run for iteration 0\n",
      "13:19:58 HBMASTER: trying submitting job (0, 0, 64) to dispatcher\n",
      "13:19:58 HBMASTER: submitting job (0, 0, 64) to dispatcher\n",
      "13:19:58 DISPATCHER: trying to submit job (0, 0, 64)\n",
      "13:19:58 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:19:58 HBMASTER: job (0, 0, 64) submitted to dispatcher\n",
      "13:19:58 DISPATCHER: Trying to submit another job.\n",
      "13:19:58 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:19:58 DISPATCHER: starting job (0, 0, 64) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:19:58 DISPATCHER: job (0, 0, 64) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:19:58 WORKER: start processing job (0, 0, 64)\n",
      "13:19:58 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:19:58 WORKER: args: ()\n",
      "13:19:58 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 25000, 'denspt': 3, 'loss': 'mae', 'numLayers': 28, 'numNeurons': 99, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:20:13 DISPATCHER: Starting worker discovery\n",
      "13:20:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:20:13 DISPATCHER: Finished worker discovery\n",
      "13:20:14 WORKER: done with job (0, 0, 64), trying to register it.\n",
      "13:20:14 WORKER: registered result for job (0, 0, 64) with dispatcher\n",
      "13:20:14 DISPATCHER: job (0, 0, 64) finished\n",
      "13:20:15 DISPATCHER: register_result: lock acquired\n",
      "13:20:15 DISPATCHER: job (0, 0, 64) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:20:15 job_id: (0, 0, 64)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 25000, 'denspt': 3, 'loss': 'mae', 'numLayers': 28, 'numNeurons': 99, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 703.2405326952087, 'info': {'L1': 703.2405326952087, 'L2': 1623.9737775619549, 'MAX': 7.445889103719208, 'TrainTime': 14.125}}\n",
      "exception: None\n",
      "\n",
      "13:20:15 job_callback for (0, 0, 64) started\n",
      "13:20:15 DISPATCHER: Trying to submit another job.\n",
      "13:20:15 job_callback for (0, 0, 64) got condition\n",
      "13:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:20:15 done building a new model for budget 12.345679 based on 9/55 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:20:15 HBMASTER: Trying to run another job!\n",
      "13:20:15 job_callback for (0, 0, 64) finished\n",
      "13:20:15 start sampling a new configuration.\n",
      "13:20:15 done sampling a new configuration.\n",
      "13:20:15 HBMASTER: schedule new run for iteration 0\n",
      "13:20:15 HBMASTER: trying submitting job (0, 0, 65) to dispatcher\n",
      "13:20:15 HBMASTER: submitting job (0, 0, 65) to dispatcher\n",
      "13:20:15 DISPATCHER: trying to submit job (0, 0, 65)\n",
      "13:20:15 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:20:15 HBMASTER: job (0, 0, 65) submitted to dispatcher\n",
      "13:20:15 DISPATCHER: Trying to submit another job.\n",
      "13:20:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:20:15 DISPATCHER: starting job (0, 0, 65) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:20:15 DISPATCHER: job (0, 0, 65) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:20:15 WORKER: start processing job (0, 0, 65)\n",
      "13:20:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:20:15 WORKER: args: ()\n",
      "13:20:15 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 6, 'loss': 'mse', 'numLayers': 10, 'numNeurons': 99, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 15000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:21:13 DISPATCHER: Starting worker discovery\n",
      "13:21:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:21:13 DISPATCHER: Finished worker discovery\n",
      "13:21:18 WORKER: done with job (0, 0, 65), trying to register it.\n",
      "13:21:18 WORKER: registered result for job (0, 0, 65) with dispatcher\n",
      "13:21:18 DISPATCHER: job (0, 0, 65) finished\n",
      "13:21:18 DISPATCHER: register_result: lock acquired\n",
      "13:21:18 DISPATCHER: job (0, 0, 65) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:21:18 job_id: (0, 0, 65)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 15000, 'denspt': 6, 'loss': 'mse', 'numLayers': 10, 'numNeurons': 99, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 754.9201243240349, 'info': {'L1': 754.9201243240349, 'L2': 1862.276360275141, 'MAX': 7.793180845355675, 'TrainTime': 73.140625}}\n",
      "exception: None\n",
      "\n",
      "13:21:18 job_callback for (0, 0, 65) started\n",
      "13:21:18 DISPATCHER: Trying to submit another job.\n",
      "13:21:18 job_callback for (0, 0, 65) got condition\n",
      "13:21:18 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:21:18 done building a new model for budget 12.345679 based on 9/56 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:21:18 HBMASTER: Trying to run another job!\n",
      "13:21:18 job_callback for (0, 0, 65) finished\n",
      "13:21:18 start sampling a new configuration.\n",
      "13:21:18 best_vector: [0, 0, 0.9568816116351854, 0, 0.01049290736223163, 0.5543456091297394, 3], 0.006566682327562545, 0.020427537646469544, 0.00013414115045869013\n",
      "13:21:18 done sampling a new configuration.\n",
      "13:21:18 HBMASTER: schedule new run for iteration 0\n",
      "13:21:18 HBMASTER: trying submitting job (0, 0, 66) to dispatcher\n",
      "13:21:18 HBMASTER: submitting job (0, 0, 66) to dispatcher\n",
      "13:21:18 DISPATCHER: trying to submit job (0, 0, 66)\n",
      "13:21:18 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:21:18 HBMASTER: job (0, 0, 66) submitted to dispatcher\n",
      "13:21:18 DISPATCHER: Trying to submit another job.\n",
      "13:21:18 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:21:18 DISPATCHER: starting job (0, 0, 66) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:21:18 DISPATCHER: job (0, 0, 66) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:21:19 WORKER: start processing job (0, 0, 66)\n",
      "13:21:19 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:21:19 WORKER: args: ()\n",
      "13:21:19 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 2, 'numNeurons': 60, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:22:13 DISPATCHER: Starting worker discovery\n",
      "13:22:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:22:13 DISPATCHER: Finished worker discovery\n",
      "13:23:13 DISPATCHER: Starting worker discovery\n",
      "13:23:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:23:13 DISPATCHER: Finished worker discovery\n",
      "13:24:13 DISPATCHER: Starting worker discovery\n",
      "13:24:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:24:13 DISPATCHER: Finished worker discovery\n",
      "13:25:13 DISPATCHER: Starting worker discovery\n",
      "13:25:13 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:25:14 DISPATCHER: Finished worker discovery\n",
      "13:26:14 DISPATCHER: Starting worker discovery\n",
      "13:26:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:26:14 DISPATCHER: Finished worker discovery\n",
      "13:27:14 DISPATCHER: Starting worker discovery\n",
      "13:27:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:27:14 DISPATCHER: Finished worker discovery\n",
      "13:27:15 WORKER: done with job (0, 0, 66), trying to register it.\n",
      "13:27:15 WORKER: registered result for job (0, 0, 66) with dispatcher\n",
      "13:27:15 DISPATCHER: job (0, 0, 66) finished\n",
      "13:27:15 DISPATCHER: register_result: lock acquired\n",
      "13:27:15 DISPATCHER: job (0, 0, 66) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:27:15 job_id: (0, 0, 66)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 2, 'numNeurons': 60, 'optimizer': 'Nadam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 119.37356347834937, 'info': {'L1': 119.37356347834937, 'L2': 75.67648448878138, 'MAX': 3.773169763565674, 'TrainTime': 369.578125}}\n",
      "exception: None\n",
      "\n",
      "13:27:15 job_callback for (0, 0, 66) started\n",
      "13:27:15 DISPATCHER: Trying to submit another job.\n",
      "13:27:15 job_callback for (0, 0, 66) got condition\n",
      "13:27:15 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:27:15 done building a new model for budget 12.345679 based on 10/56 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:27:15 HBMASTER: Trying to run another job!\n",
      "13:27:15 job_callback for (0, 0, 66) finished\n",
      "13:27:15 start sampling a new configuration.\n",
      "13:27:15 best_vector: [1, 0, 0.8568302549431461, 1, 0.23468034798096538, 0.24939277442854002, 0], 1.62984692216629e-31, 0.06135545531299731, -0.00011957946357527272\n",
      "13:27:15 done sampling a new configuration.\n",
      "13:27:15 HBMASTER: schedule new run for iteration 0\n",
      "13:27:15 HBMASTER: trying submitting job (0, 0, 67) to dispatcher\n",
      "13:27:15 HBMASTER: submitting job (0, 0, 67) to dispatcher\n",
      "13:27:15 DISPATCHER: trying to submit job (0, 0, 67)\n",
      "13:27:15 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:27:15 HBMASTER: job (0, 0, 67) submitted to dispatcher\n",
      "13:27:15 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:27:15 DISPATCHER: Trying to submit another job.\n",
      "13:27:15 DISPATCHER: starting job (0, 0, 67) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:27:15 DISPATCHER: job (0, 0, 67) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:27:15 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:27:15 WORKER: start processing job (0, 0, 67)\n",
      "13:27:15 WORKER: args: ()\n",
      "13:27:15 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 32, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:28:14 DISPATCHER: Starting worker discovery\n",
      "13:28:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:28:14 DISPATCHER: Finished worker discovery\n",
      "13:29:12 WORKER: done with job (0, 0, 67), trying to register it.\n",
      "13:29:12 WORKER: registered result for job (0, 0, 67) with dispatcher\n",
      "13:29:12 DISPATCHER: job (0, 0, 67) finished\n",
      "13:29:12 DISPATCHER: register_result: lock acquired\n",
      "13:29:12 DISPATCHER: job (0, 0, 67) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:29:12 job_id: (0, 0, 67)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 32, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 721.9253239655798, 'info': {'L1': 721.9253239655798, 'L2': 6033.527795902943, 'MAX': 41.94431723854883, 'TrainTime': 122.234375}}\n",
      "exception: None\n",
      "\n",
      "13:29:12 job_callback for (0, 0, 67) started\n",
      "13:29:12 DISPATCHER: Trying to submit another job.\n",
      "13:29:12 job_callback for (0, 0, 67) got condition\n",
      "13:29:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:29:12 done building a new model for budget 12.345679 based on 10/57 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:29:12 HBMASTER: Trying to run another job!\n",
      "13:29:12 job_callback for (0, 0, 67) finished\n",
      "13:29:12 start sampling a new configuration.\n",
      "13:29:12 best_vector: [2, 1, 0.3193324756805665, 0, 0.4367817756522217, 0.5446185652402048, 2], 4.960060919552903e-31, 0.020161042701268665, -0.00014829473260286375\n",
      "13:29:12 done sampling a new configuration.\n",
      "13:29:12 HBMASTER: schedule new run for iteration 0\n",
      "13:29:12 HBMASTER: trying submitting job (0, 0, 68) to dispatcher\n",
      "13:29:12 HBMASTER: submitting job (0, 0, 68) to dispatcher\n",
      "13:29:12 DISPATCHER: trying to submit job (0, 0, 68)\n",
      "13:29:12 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:29:12 HBMASTER: job (0, 0, 68) submitted to dispatcher\n",
      "13:29:12 DISPATCHER: Trying to submit another job.\n",
      "13:29:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:29:12 DISPATCHER: starting job (0, 0, 68) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:29:12 DISPATCHER: job (0, 0, 68) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:29:12 WORKER: start processing job (0, 0, 68)\n",
      "13:29:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:29:12 WORKER: args: ()\n",
      "13:29:12 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 23, 'numNeurons': 59, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "13:29:14 DISPATCHER: Starting worker discovery\n",
      "13:29:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:29:14 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 5000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:29:52 WORKER: done with job (0, 0, 68), trying to register it.\n",
      "13:29:52 WORKER: registered result for job (0, 0, 68) with dispatcher\n",
      "13:29:52 DISPATCHER: job (0, 0, 68) finished\n",
      "13:29:52 DISPATCHER: register_result: lock acquired\n",
      "13:29:52 DISPATCHER: job (0, 0, 68) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:29:52 job_id: (0, 0, 68)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 4, 'loss': 'mae', 'numLayers': 23, 'numNeurons': 59, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 806.101717265319, 'info': {'L1': 806.101717265319, 'L2': 2111.9500617397666, 'MAX': 8.113065801238701, 'TrainTime': 38.78125}}\n",
      "exception: None\n",
      "\n",
      "13:29:53 job_callback for (0, 0, 68) started\n",
      "13:29:53 DISPATCHER: Trying to submit another job.\n",
      "13:29:53 job_callback for (0, 0, 68) got condition\n",
      "13:29:53 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:29:53 done building a new model for budget 12.345679 based on 10/58 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:29:53 HBMASTER: Trying to run another job!\n",
      "13:29:53 job_callback for (0, 0, 68) finished\n",
      "13:29:53 start sampling a new configuration.\n",
      "13:29:53 best_vector: [0, 1, 0.48078099063356516, 0, 0.3875735618639838, 0.6808338630856011, 2], 3.5153617220820456e-31, 0.02844657474985901, -5.189910800019874e-06\n",
      "13:29:53 done sampling a new configuration.\n",
      "13:29:53 HBMASTER: schedule new run for iteration 0\n",
      "13:29:53 HBMASTER: trying submitting job (0, 0, 69) to dispatcher\n",
      "13:29:53 HBMASTER: submitting job (0, 0, 69) to dispatcher\n",
      "13:29:53 DISPATCHER: trying to submit job (0, 0, 69)\n",
      "13:29:53 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:29:53 HBMASTER: job (0, 0, 69) submitted to dispatcher\n",
      "13:29:53 DISPATCHER: Trying to submit another job.\n",
      "13:29:53 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:29:53 DISPATCHER: starting job (0, 0, 69) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:29:53 DISPATCHER: job (0, 0, 69) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:29:53 WORKER: start processing job (0, 0, 69)\n",
      "13:29:53 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:29:53 WORKER: args: ()\n",
      "13:29:53 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 71, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:30:14 DISPATCHER: Starting worker discovery\n",
      "13:30:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:30:14 DISPATCHER: Finished worker discovery\n",
      "13:30:36 WORKER: done with job (0, 0, 69), trying to register it.\n",
      "13:30:36 WORKER: registered result for job (0, 0, 69) with dispatcher\n",
      "13:30:36 DISPATCHER: job (0, 0, 69) finished\n",
      "13:30:36 DISPATCHER: register_result: lock acquired\n",
      "13:30:36 DISPATCHER: job (0, 0, 69) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:30:36 job_id: (0, 0, 69)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 20, 'numNeurons': 71, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 682.6976055476542, 'info': {'L1': 682.6976055476542, 'L2': 1536.7086378049362, 'MAX': 7.178604054757568, 'TrainTime': 44.34375}}\n",
      "exception: None\n",
      "\n",
      "13:30:36 job_callback for (0, 0, 69) started\n",
      "13:30:36 DISPATCHER: Trying to submit another job.\n",
      "13:30:36 job_callback for (0, 0, 69) got condition\n",
      "13:30:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:30:36 done building a new model for budget 12.345679 based on 10/59 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:30:36 HBMASTER: Trying to run another job!\n",
      "13:30:36 job_callback for (0, 0, 69) finished\n",
      "13:30:36 start sampling a new configuration.\n",
      "13:30:36 done sampling a new configuration.\n",
      "13:30:36 HBMASTER: schedule new run for iteration 0\n",
      "13:30:36 HBMASTER: trying submitting job (0, 0, 70) to dispatcher\n",
      "13:30:36 HBMASTER: submitting job (0, 0, 70) to dispatcher\n",
      "13:30:36 DISPATCHER: trying to submit job (0, 0, 70)\n",
      "13:30:36 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:30:36 HBMASTER: job (0, 0, 70) submitted to dispatcher\n",
      "13:30:36 DISPATCHER: Trying to submit another job.\n",
      "13:30:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:30:36 DISPATCHER: starting job (0, 0, 70) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:30:37 DISPATCHER: job (0, 0, 70) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:30:37 WORKER: start processing job (0, 0, 70)\n",
      "13:30:37 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:30:37 WORKER: args: ()\n",
      "13:30:37 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 4, 'loss': 'mse', 'numLayers': 17, 'numNeurons': 37, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 10000 \n",
      "Total batches: 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:02 WORKER: done with job (0, 0, 70), trying to register it.\n",
      "13:31:02 WORKER: registered result for job (0, 0, 70) with dispatcher\n",
      "13:31:02 DISPATCHER: job (0, 0, 70) finished\n",
      "13:31:02 DISPATCHER: register_result: lock acquired\n",
      "13:31:02 DISPATCHER: job (0, 0, 70) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:31:02 job_id: (0, 0, 70)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 10000, 'denspt': 4, 'loss': 'mse', 'numLayers': 17, 'numNeurons': 37, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 725.0339908211095, 'info': {'L1': 725.0339908211095, 'L2': 1724.0105058026602, 'MAX': 7.6063276898619385, 'TrainTime': 25.96875}}\n",
      "exception: None\n",
      "\n",
      "13:31:02 job_callback for (0, 0, 70) started\n",
      "13:31:02 DISPATCHER: Trying to submit another job.\n",
      "13:31:02 job_callback for (0, 0, 70) got condition\n",
      "13:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:31:02 done building a new model for budget 12.345679 based on 10/60 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:31:02 HBMASTER: Trying to run another job!\n",
      "13:31:02 job_callback for (0, 0, 70) finished\n",
      "13:31:02 start sampling a new configuration.\n",
      "13:31:02 done sampling a new configuration.\n",
      "13:31:02 HBMASTER: schedule new run for iteration 0\n",
      "13:31:02 HBMASTER: trying submitting job (0, 0, 71) to dispatcher\n",
      "13:31:02 HBMASTER: submitting job (0, 0, 71) to dispatcher\n",
      "13:31:02 DISPATCHER: trying to submit job (0, 0, 71)\n",
      "13:31:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:31:02 HBMASTER: job (0, 0, 71) submitted to dispatcher\n",
      "13:31:02 DISPATCHER: Trying to submit another job.\n",
      "13:31:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:31:02 DISPATCHER: starting job (0, 0, 71) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:31:02 DISPATCHER: job (0, 0, 71) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:31:02 WORKER: start processing job (0, 0, 71)\n",
      "13:31:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:31:02 WORKER: args: ()\n",
      "13:31:02 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 6, 'loss': 'mae', 'numLayers': 16, 'numNeurons': 12, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 1000 \n",
      "Total batches: 35 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:31:14 DISPATCHER: Starting worker discovery\n",
      "13:31:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:31:14 DISPATCHER: Finished worker discovery\n",
      "13:32:14 DISPATCHER: Starting worker discovery\n",
      "13:32:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:32:14 DISPATCHER: Finished worker discovery\n",
      "13:33:14 DISPATCHER: Starting worker discovery\n",
      "13:33:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:33:14 DISPATCHER: Finished worker discovery\n",
      "13:34:14 DISPATCHER: Starting worker discovery\n",
      "13:34:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:34:14 DISPATCHER: Finished worker discovery\n",
      "13:35:11 WORKER: done with job (0, 0, 71), trying to register it.\n",
      "13:35:11 WORKER: registered result for job (0, 0, 71) with dispatcher\n",
      "13:35:11 DISPATCHER: job (0, 0, 71) finished\n",
      "13:35:11 DISPATCHER: register_result: lock acquired\n",
      "13:35:11 DISPATCHER: job (0, 0, 71) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:35:11 job_id: (0, 0, 71)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 6, 'loss': 'mae', 'numLayers': 16, 'numNeurons': 12, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 622.4684790117387, 'info': {'L1': 622.4684790117387, 'L2': 1291.0800227439072, 'MAX': 6.963623441433594, 'TrainTime': 257.84375}}\n",
      "exception: None\n",
      "\n",
      "13:35:11 job_callback for (0, 0, 71) started\n",
      "13:35:11 DISPATCHER: Trying to submit another job.\n",
      "13:35:11 job_callback for (0, 0, 71) got condition\n",
      "13:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:35:11 done building a new model for budget 12.345679 based on 10/61 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:35:11 HBMASTER: Trying to run another job!\n",
      "13:35:11 job_callback for (0, 0, 71) finished\n",
      "13:35:11 start sampling a new configuration.\n",
      "13:35:11 done sampling a new configuration.\n",
      "13:35:11 HBMASTER: schedule new run for iteration 0\n",
      "13:35:11 HBMASTER: trying submitting job (0, 0, 72) to dispatcher\n",
      "13:35:11 HBMASTER: submitting job (0, 0, 72) to dispatcher\n",
      "13:35:11 DISPATCHER: trying to submit job (0, 0, 72)\n",
      "13:35:11 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:35:11 HBMASTER: job (0, 0, 72) submitted to dispatcher\n",
      "13:35:11 DISPATCHER: Trying to submit another job.\n",
      "13:35:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:35:11 DISPATCHER: starting job (0, 0, 72) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:35:11 DISPATCHER: job (0, 0, 72) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:35:11 WORKER: start processing job (0, 0, 72)\n",
      "13:35:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:35:11 WORKER: args: ()\n",
      "13:35:11 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 5, 'numNeurons': 15, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 1000 \n",
      "Total batches: 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:35:14 DISPATCHER: Starting worker discovery\n",
      "13:35:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:35:14 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:35:42 WORKER: done with job (0, 0, 72), trying to register it.\n",
      "13:35:42 WORKER: registered result for job (0, 0, 72) with dispatcher\n",
      "13:35:42 DISPATCHER: job (0, 0, 72) finished\n",
      "13:35:42 DISPATCHER: register_result: lock acquired\n",
      "13:35:42 DISPATCHER: job (0, 0, 72) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:35:42 job_id: (0, 0, 72)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 5, 'numNeurons': 15, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 779.4854638595097, 'info': {'L1': 779.4854638595097, 'L2': 1980.0675923340746, 'MAX': 7.946714217452392, 'TrainTime': 28.640625}}\n",
      "exception: None\n",
      "\n",
      "13:35:42 job_callback for (0, 0, 72) started\n",
      "13:35:42 DISPATCHER: Trying to submit another job.\n",
      "13:35:42 job_callback for (0, 0, 72) got condition\n",
      "13:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:35:42 done building a new model for budget 12.345679 based on 10/62 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:35:42 HBMASTER: Trying to run another job!\n",
      "13:35:42 job_callback for (0, 0, 72) finished\n",
      "13:35:42 start sampling a new configuration.\n",
      "13:35:42 done sampling a new configuration.\n",
      "13:35:42 HBMASTER: schedule new run for iteration 0\n",
      "13:35:42 HBMASTER: trying submitting job (0, 0, 73) to dispatcher\n",
      "13:35:42 HBMASTER: submitting job (0, 0, 73) to dispatcher\n",
      "13:35:42 DISPATCHER: trying to submit job (0, 0, 73)\n",
      "13:35:42 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:35:42 HBMASTER: job (0, 0, 73) submitted to dispatcher\n",
      "13:35:42 DISPATCHER: Trying to submit another job.\n",
      "13:35:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:35:42 DISPATCHER: starting job (0, 0, 73) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:35:42 DISPATCHER: job (0, 0, 73) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:35:42 WORKER: start processing job (0, 0, 73)\n",
      "13:35:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:35:42 WORKER: args: ()\n",
      "13:35:42 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 3, 'loss': 'mse', 'numLayers': 45, 'numNeurons': 34, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 4320 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:36:03 WORKER: done with job (0, 0, 73), trying to register it.\n",
      "13:36:03 WORKER: registered result for job (0, 0, 73) with dispatcher\n",
      "13:36:03 DISPATCHER: job (0, 0, 73) finished\n",
      "13:36:03 DISPATCHER: register_result: lock acquired\n",
      "13:36:03 DISPATCHER: job (0, 0, 73) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:36:03 job_id: (0, 0, 73)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 3, 'loss': 'mse', 'numLayers': 45, 'numNeurons': 34, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 776.5112654357068, 'info': {'L1': 776.5112654357068, 'L2': 1965.6222363671438, 'MAX': 7.928369950180933, 'TrainTime': 17.734375}}\n",
      "exception: None\n",
      "\n",
      "13:36:03 job_callback for (0, 0, 73) started\n",
      "13:36:03 DISPATCHER: Trying to submit another job.\n",
      "13:36:03 job_callback for (0, 0, 73) got condition\n",
      "13:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:36:03 done building a new model for budget 12.345679 based on 11/62 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:36:03 HBMASTER: Trying to run another job!\n",
      "13:36:03 job_callback for (0, 0, 73) finished\n",
      "13:36:03 start sampling a new configuration.\n",
      "13:36:03 best_vector: [2, 0, 0.8926644416081422, 0, 0.34067885875733583, 0.2528461534878285, 0], 0.004977716530675711, 0.09663094588386612, 0.00048100145670095044\n",
      "13:36:03 done sampling a new configuration.\n",
      "13:36:03 HBMASTER: schedule new run for iteration 0\n",
      "13:36:03 HBMASTER: trying submitting job (0, 0, 74) to dispatcher\n",
      "13:36:03 HBMASTER: submitting job (0, 0, 74) to dispatcher\n",
      "13:36:03 DISPATCHER: trying to submit job (0, 0, 74)\n",
      "13:36:03 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:36:03 HBMASTER: job (0, 0, 74) submitted to dispatcher\n",
      "13:36:03 DISPATCHER: Trying to submit another job.\n",
      "13:36:03 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:36:03 DISPATCHER: starting job (0, 0, 74) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:36:03 DISPATCHER: job (0, 0, 74) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:36:03 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:36:03 WORKER: start processing job (0, 0, 74)\n",
      "13:36:03 WORKER: args: ()\n",
      "13:36:03 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 18, 'numNeurons': 33, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:36:14 DISPATCHER: Starting worker discovery\n",
      "13:36:14 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:36:14 DISPATCHER: Finished worker discovery\n",
      "13:37:15 DISPATCHER: Starting worker discovery\n",
      "13:37:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:37:15 DISPATCHER: Finished worker discovery\n",
      "13:38:15 DISPATCHER: Starting worker discovery\n",
      "13:38:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:38:15 DISPATCHER: Finished worker discovery\n",
      "13:39:15 DISPATCHER: Starting worker discovery\n",
      "13:39:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:39:15 DISPATCHER: Finished worker discovery\n",
      "13:40:15 DISPATCHER: Starting worker discovery\n",
      "13:40:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:40:15 DISPATCHER: Finished worker discovery\n",
      "13:41:15 DISPATCHER: Starting worker discovery\n",
      "13:41:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:41:15 DISPATCHER: Finished worker discovery\n",
      "13:42:15 DISPATCHER: Starting worker discovery\n",
      "13:42:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:42:15 DISPATCHER: Finished worker discovery\n",
      "13:43:15 DISPATCHER: Starting worker discovery\n",
      "13:43:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:43:15 DISPATCHER: Finished worker discovery\n",
      "13:44:15 DISPATCHER: Starting worker discovery\n",
      "13:44:15 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:44:15 DISPATCHER: Finished worker discovery\n",
      "13:45:15 DISPATCHER: Starting worker discovery\n",
      "13:45:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:45:16 DISPATCHER: Finished worker discovery\n",
      "13:46:16 DISPATCHER: Starting worker discovery\n",
      "13:46:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:46:16 DISPATCHER: Finished worker discovery\n",
      "13:46:49 WORKER: done with job (0, 0, 74), trying to register it.\n",
      "13:46:49 WORKER: registered result for job (0, 0, 74) with dispatcher\n",
      "13:46:49 DISPATCHER: job (0, 0, 74) finished\n",
      "13:46:49 DISPATCHER: register_result: lock acquired\n",
      "13:46:49 DISPATCHER: job (0, 0, 74) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:46:49 job_id: (0, 0, 74)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 18, 'numNeurons': 33, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 392.0989559814296, 'info': {'L1': 392.0989559814296, 'L2': 546.5059048499699, 'MAX': 5.4863113534208985, 'TrainTime': 662.4375}}\n",
      "exception: None\n",
      "\n",
      "13:46:49 job_callback for (0, 0, 74) started\n",
      "13:46:49 DISPATCHER: Trying to submit another job.\n",
      "13:46:49 job_callback for (0, 0, 74) got condition\n",
      "13:46:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:46:49 done building a new model for budget 12.345679 based on 11/63 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:46:49 HBMASTER: Trying to run another job!\n",
      "13:46:49 job_callback for (0, 0, 74) finished\n",
      "13:46:49 start sampling a new configuration.\n",
      "13:46:49 done sampling a new configuration.\n",
      "13:46:49 HBMASTER: schedule new run for iteration 0\n",
      "13:46:49 HBMASTER: trying submitting job (0, 0, 75) to dispatcher\n",
      "13:46:49 HBMASTER: submitting job (0, 0, 75) to dispatcher\n",
      "13:46:49 DISPATCHER: trying to submit job (0, 0, 75)\n",
      "13:46:49 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:46:49 HBMASTER: job (0, 0, 75) submitted to dispatcher\n",
      "13:46:49 DISPATCHER: Trying to submit another job.\n",
      "13:46:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:46:49 DISPATCHER: starting job (0, 0, 75) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:46:49 DISPATCHER: job (0, 0, 75) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:46:49 WORKER: start processing job (0, 0, 75)\n",
      "13:46:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:46:49 WORKER: args: ()\n",
      "13:46:49 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 10000, 'denspt': 5, 'loss': 'mse', 'numLayers': 39, 'numNeurons': 82, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 10000 \n",
      "Total batches: 2 \n",
      "\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:47:12 WORKER: done with job (0, 0, 75), trying to register it.\n",
      "13:47:12 WORKER: registered result for job (0, 0, 75) with dispatcher\n",
      "13:47:12 DISPATCHER: job (0, 0, 75) finished\n",
      "13:47:12 DISPATCHER: register_result: lock acquired\n",
      "13:47:12 DISPATCHER: job (0, 0, 75) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:47:12 job_id: (0, 0, 75)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 10000, 'denspt': 5, 'loss': 'mse', 'numLayers': 39, 'numNeurons': 82, 'optimizer': 'Ftrl'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 776.7651424661875, 'info': {'L1': 776.7651424661875, 'L2': 1966.8376269459154, 'MAX': 7.929708487963364, 'TrainTime': 21.484375}}\n",
      "exception: None\n",
      "\n",
      "13:47:12 job_callback for (0, 0, 75) started\n",
      "13:47:12 DISPATCHER: Trying to submit another job.\n",
      "13:47:12 job_callback for (0, 0, 75) got condition\n",
      "13:47:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:47:12 done building a new model for budget 12.345679 based on 11/64 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:47:12 HBMASTER: Trying to run another job!\n",
      "13:47:12 job_callback for (0, 0, 75) finished\n",
      "13:47:12 start sampling a new configuration.\n",
      "13:47:12 best_vector: [1, 0, 0.9818620384296437, 0, 0.20907531766345352, 0.20327095267195197, 0], 0.008451503494945885, 0.12469272722367884, 0.0010538410199252557\n",
      "13:47:12 done sampling a new configuration.\n",
      "13:47:12 HBMASTER: schedule new run for iteration 0\n",
      "13:47:12 HBMASTER: trying submitting job (0, 0, 76) to dispatcher\n",
      "13:47:12 HBMASTER: submitting job (0, 0, 76) to dispatcher\n",
      "13:47:12 DISPATCHER: trying to submit job (0, 0, 76)\n",
      "13:47:12 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:47:12 HBMASTER: job (0, 0, 76) submitted to dispatcher\n",
      "13:47:12 DISPATCHER: Trying to submit another job.\n",
      "13:47:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:47:12 DISPATCHER: starting job (0, 0, 76) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:47:12 DISPATCHER: job (0, 0, 76) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:47:12 WORKER: start processing job (0, 0, 76)\n",
      "13:47:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:47:12 WORKER: args: ()\n",
      "13:47:12 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 28, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:47:16 DISPATCHER: Starting worker discovery\n",
      "13:47:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:47:16 DISPATCHER: Finished worker discovery\n",
      "13:48:16 DISPATCHER: Starting worker discovery\n",
      "13:48:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:48:16 DISPATCHER: Finished worker discovery\n",
      "13:49:16 DISPATCHER: Starting worker discovery\n",
      "13:49:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:49:16 DISPATCHER: Finished worker discovery\n",
      "13:49:34 WORKER: done with job (0, 0, 76), trying to register it.\n",
      "13:49:34 WORKER: registered result for job (0, 0, 76) with dispatcher\n",
      "13:49:34 DISPATCHER: job (0, 0, 76) finished\n",
      "13:49:34 DISPATCHER: register_result: lock acquired\n",
      "13:49:34 DISPATCHER: job (0, 0, 76) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:49:34 job_id: (0, 0, 76)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 28, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 226.85999428054754, 'info': {'L1': 226.85999428054754, 'L2': 226.21138462545412, 'MAX': 3.3086830704580077, 'TrainTime': 147.484375}}\n",
      "exception: None\n",
      "\n",
      "13:49:34 job_callback for (0, 0, 76) started\n",
      "13:49:34 DISPATCHER: Trying to submit another job.\n",
      "13:49:34 job_callback for (0, 0, 76) got condition\n",
      "13:49:34 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:49:34 done building a new model for budget 12.345679 based on 11/65 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:49:34 HBMASTER: Trying to run another job!\n",
      "13:49:34 job_callback for (0, 0, 76) finished\n",
      "13:49:34 start sampling a new configuration.\n",
      "13:49:34 done sampling a new configuration.\n",
      "13:49:34 HBMASTER: schedule new run for iteration 0\n",
      "13:49:34 HBMASTER: trying submitting job (0, 0, 77) to dispatcher\n",
      "13:49:34 HBMASTER: submitting job (0, 0, 77) to dispatcher\n",
      "13:49:34 DISPATCHER: trying to submit job (0, 0, 77)\n",
      "13:49:34 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:49:34 HBMASTER: job (0, 0, 77) submitted to dispatcher\n",
      "13:49:34 DISPATCHER: Trying to submit another job.\n",
      "13:49:34 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:49:34 DISPATCHER: starting job (0, 0, 77) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:49:34 DISPATCHER: job (0, 0, 77) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:49:34 WORKER: start processing job (0, 0, 77)\n",
      "13:49:34 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:49:34 WORKER: args: ()\n",
      "13:49:34 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 44, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:50:16 DISPATCHER: Starting worker discovery\n",
      "13:50:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:50:16 DISPATCHER: Finished worker discovery\n",
      "13:51:16 DISPATCHER: Starting worker discovery\n",
      "13:51:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:51:16 DISPATCHER: Finished worker discovery\n",
      "13:52:16 DISPATCHER: Starting worker discovery\n",
      "13:52:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:52:16 DISPATCHER: Finished worker discovery\n",
      "13:52:26 WORKER: done with job (0, 0, 77), trying to register it.\n",
      "13:52:26 WORKER: registered result for job (0, 0, 77) with dispatcher\n",
      "13:52:26 DISPATCHER: job (0, 0, 77) finished\n",
      "13:52:26 DISPATCHER: register_result: lock acquired\n",
      "13:52:26 DISPATCHER: job (0, 0, 77) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:52:26 job_id: (0, 0, 77)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 44, 'optimizer': 'SGD'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 721.1855635573205, 'info': {'L1': 721.1855635573205, 'L2': 1706.600307764746, 'MAX': 7.582250751232788, 'TrainTime': 175.09375}}\n",
      "exception: None\n",
      "\n",
      "13:52:26 job_callback for (0, 0, 77) started\n",
      "13:52:26 DISPATCHER: Trying to submit another job.\n",
      "13:52:26 job_callback for (0, 0, 77) got condition\n",
      "13:52:26 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:52:26 done building a new model for budget 12.345679 based on 11/66 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:52:26 HBMASTER: Trying to run another job!\n",
      "13:52:26 job_callback for (0, 0, 77) finished\n",
      "13:52:26 start sampling a new configuration.\n",
      "13:52:26 done sampling a new configuration.\n",
      "13:52:26 HBMASTER: schedule new run for iteration 0\n",
      "13:52:26 HBMASTER: trying submitting job (0, 0, 78) to dispatcher\n",
      "13:52:26 HBMASTER: submitting job (0, 0, 78) to dispatcher\n",
      "13:52:26 DISPATCHER: trying to submit job (0, 0, 78)\n",
      "13:52:26 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:52:26 HBMASTER: job (0, 0, 78) submitted to dispatcher\n",
      "13:52:26 DISPATCHER: Trying to submit another job.\n",
      "13:52:26 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:52:26 DISPATCHER: starting job (0, 0, 78) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:52:26 DISPATCHER: job (0, 0, 78) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:52:26 WORKER: start processing job (0, 0, 78)\n",
      "13:52:26 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:52:26 WORKER: args: ()\n",
      "13:52:26 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 4, 'loss': 'mse', 'numLayers': 32, 'numNeurons': 34, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 10240 \n",
      "Batch size: 1000 \n",
      "Total batches: 11 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:52:49 WORKER: done with job (0, 0, 78), trying to register it.\n",
      "13:52:49 WORKER: registered result for job (0, 0, 78) with dispatcher\n",
      "13:52:49 DISPATCHER: job (0, 0, 78) finished\n",
      "13:52:49 DISPATCHER: register_result: lock acquired\n",
      "13:52:49 DISPATCHER: job (0, 0, 78) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:52:49 job_id: (0, 0, 78)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 4, 'loss': 'mse', 'numLayers': 32, 'numNeurons': 34, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 520.2811488623006, 'info': {'L1': 520.2811488623006, 'L2': 887.3696207838261, 'MAX': 5.642481868764038, 'TrainTime': 21.640625}}\n",
      "exception: None\n",
      "\n",
      "13:52:49 job_callback for (0, 0, 78) started\n",
      "13:52:49 DISPATCHER: Trying to submit another job.\n",
      "13:52:49 job_callback for (0, 0, 78) got condition\n",
      "13:52:49 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:52:49 done building a new model for budget 12.345679 based on 11/67 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:52:49 HBMASTER: Trying to run another job!\n",
      "13:52:49 job_callback for (0, 0, 78) finished\n",
      "13:52:49 start sampling a new configuration.\n",
      "13:52:49 done sampling a new configuration.\n",
      "13:52:49 HBMASTER: schedule new run for iteration 0\n",
      "13:52:49 HBMASTER: trying submitting job (0, 0, 79) to dispatcher\n",
      "13:52:49 HBMASTER: submitting job (0, 0, 79) to dispatcher\n",
      "13:52:49 DISPATCHER: trying to submit job (0, 0, 79)\n",
      "13:52:49 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:52:49 HBMASTER: job (0, 0, 79) submitted to dispatcher\n",
      "13:52:49 DISPATCHER: Trying to submit another job.\n",
      "13:52:49 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:52:49 DISPATCHER: starting job (0, 0, 79) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:52:49 DISPATCHER: job (0, 0, 79) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:52:49 WORKER: start processing job (0, 0, 79)\n",
      "13:52:49 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:52:49 WORKER: args: ()\n",
      "13:52:49 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'loss': 'mae', 'numLayers': 39, 'numNeurons': 46, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 15000 \n",
      "Total batches: 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:53:16 DISPATCHER: Starting worker discovery\n",
      "13:53:16 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:53:17 DISPATCHER: Finished worker discovery\n",
      "13:54:01 WORKER: done with job (0, 0, 79), trying to register it.\n",
      "13:54:01 WORKER: registered result for job (0, 0, 79) with dispatcher\n",
      "13:54:01 DISPATCHER: job (0, 0, 79) finished\n",
      "13:54:01 DISPATCHER: register_result: lock acquired\n",
      "13:54:01 DISPATCHER: job (0, 0, 79) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:54:01 job_id: (0, 0, 79)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 15000, 'denspt': 6, 'loss': 'mae', 'numLayers': 39, 'numNeurons': 46, 'optimizer': 'RMSprop'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 627.848208970299, 'info': {'L1': 627.848208970299, 'L2': 1312.20092066133, 'MAX': 6.997422314858124, 'TrainTime': 78.921875}}\n",
      "exception: None\n",
      "\n",
      "13:54:01 job_callback for (0, 0, 79) started\n",
      "13:54:01 DISPATCHER: Trying to submit another job.\n",
      "13:54:01 job_callback for (0, 0, 79) got condition\n",
      "13:54:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:54:01 done building a new model for budget 12.345679 based on 12/68 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:54:01 HBMASTER: Trying to run another job!\n",
      "13:54:01 job_callback for (0, 0, 79) finished\n",
      "13:54:01 start sampling a new configuration.\n",
      "13:54:02 best_vector: [1, 0, 0.9949155172468207, 0, 0.21889607726223742, 0.36502264133925194, 0], 0.0031160946024454688, 0.08555035822524946, 0.0002665830095029762\n",
      "13:54:02 done sampling a new configuration.\n",
      "13:54:02 HBMASTER: schedule new run for iteration 0\n",
      "13:54:02 HBMASTER: trying submitting job (0, 0, 80) to dispatcher\n",
      "13:54:02 HBMASTER: submitting job (0, 0, 80) to dispatcher\n",
      "13:54:02 DISPATCHER: trying to submit job (0, 0, 80)\n",
      "13:54:02 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:54:02 HBMASTER: job (0, 0, 80) submitted to dispatcher\n",
      "13:54:02 DISPATCHER: Trying to submit another job.\n",
      "13:54:02 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:54:02 DISPATCHER: starting job (0, 0, 80) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:54:02 DISPATCHER: job (0, 0, 80) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:54:02 WORKER: start processing job (0, 0, 80)\n",
      "13:54:02 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:54:02 WORKER: args: ()\n",
      "13:54:02 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 43, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 81920 \n",
      "Batch size: 1000 \n",
      "Total batches: 82 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:54:17 DISPATCHER: Starting worker discovery\n",
      "13:54:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:54:17 DISPATCHER: Finished worker discovery\n",
      "13:55:17 DISPATCHER: Starting worker discovery\n",
      "13:55:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:55:17 DISPATCHER: Finished worker discovery\n",
      "13:56:17 DISPATCHER: Starting worker discovery\n",
      "13:56:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:56:17 DISPATCHER: Finished worker discovery\n",
      "13:56:38 WORKER: done with job (0, 0, 80), trying to register it.\n",
      "13:56:38 WORKER: registered result for job (0, 0, 80) with dispatcher\n",
      "13:56:38 DISPATCHER: job (0, 0, 80) finished\n",
      "13:56:38 DISPATCHER: register_result: lock acquired\n",
      "13:56:38 DISPATCHER: job (0, 0, 80) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:56:38 job_id: (0, 0, 80)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 8, 'loss': 'mae', 'numLayers': 12, 'numNeurons': 43, 'optimizer': 'Adam'}, 'budget': 12.345679012345679, 'working_directory': '.'}\n",
      "result: {'loss': 186.64522937847406, 'info': {'L1': 186.64522937847406, 'L2': 163.1958269234849, 'MAX': 3.1531042052154543, 'TrainTime': 162.421875}}\n",
      "exception: None\n",
      "\n",
      "13:56:38 job_callback for (0, 0, 80) started\n",
      "13:56:38 DISPATCHER: Trying to submit another job.\n",
      "13:56:38 job_callback for (0, 0, 80) got condition\n",
      "13:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:56:38 done building a new model for budget 12.345679 based on 12/68 split\n",
      "Best loss for this budget:98.767213\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "13:56:38 HBMASTER: Trying to run another job!\n",
      "13:56:38 job_callback for (0, 0, 80) finished\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 10) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 14) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 15) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 18) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 22) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 25) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 26) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 27) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 28) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 30) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 36) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 38) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 42) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 43) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 44) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 45) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 48) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 52) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 53) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 55) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 62) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 63) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 66) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 74) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 76) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 78) to next budget 37.037037\n",
      "13:56:38 ITERATION: Advancing config (0, 0, 80) to next budget 37.037037\n",
      "13:56:38 HBMASTER: schedule new run for iteration 0\n",
      "13:56:38 HBMASTER: trying submitting job (0, 0, 10) to dispatcher\n",
      "13:56:38 HBMASTER: submitting job (0, 0, 10) to dispatcher\n",
      "13:56:38 DISPATCHER: trying to submit job (0, 0, 10)\n",
      "13:56:38 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:56:38 HBMASTER: job (0, 0, 10) submitted to dispatcher\n",
      "13:56:38 DISPATCHER: Trying to submit another job.\n",
      "13:56:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:56:38 DISPATCHER: starting job (0, 0, 10) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:56:38 DISPATCHER: job (0, 0, 10) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:56:38 WORKER: start processing job (0, 0, 10)\n",
      "13:56:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:56:38 WORKER: args: ()\n",
      "13:56:38 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 44, 'numNeurons': 49, 'optimizer': 'RMSprop'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 4320 \n",
      "Batch size: 1000 \n",
      "Total batches: 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:57:08 WORKER: done with job (0, 0, 10), trying to register it.\n",
      "13:57:08 WORKER: registered result for job (0, 0, 10) with dispatcher\n",
      "13:57:08 DISPATCHER: job (0, 0, 10) finished\n",
      "13:57:08 DISPATCHER: register_result: lock acquired\n",
      "13:57:08 DISPATCHER: job (0, 0, 10) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:57:08 job_id: (0, 0, 10)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 3, 'loss': 'mae', 'numLayers': 44, 'numNeurons': 49, 'optimizer': 'RMSprop'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 174.31193716531823, 'info': {'L1': 174.31193716531823, 'L2': 132.5590514202664, 'MAX': 3.2932456298234865, 'TrainTime': 29.015625}}\n",
      "exception: None\n",
      "\n",
      "13:57:08 job_callback for (0, 0, 10) started\n",
      "13:57:08 DISPATCHER: Trying to submit another job.\n",
      "13:57:08 job_callback for (0, 0, 10) got condition\n",
      "13:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:57:08 Only 1 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "13:57:08 HBMASTER: Trying to run another job!\n",
      "13:57:08 job_callback for (0, 0, 10) finished\n",
      "13:57:08 HBMASTER: schedule new run for iteration 0\n",
      "13:57:08 HBMASTER: trying submitting job (0, 0, 14) to dispatcher\n",
      "13:57:08 HBMASTER: submitting job (0, 0, 14) to dispatcher\n",
      "13:57:08 DISPATCHER: trying to submit job (0, 0, 14)\n",
      "13:57:08 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:57:08 HBMASTER: job (0, 0, 14) submitted to dispatcher\n",
      "13:57:08 DISPATCHER: Trying to submit another job.\n",
      "13:57:08 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:57:08 DISPATCHER: starting job (0, 0, 14) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:57:08 DISPATCHER: job (0, 0, 14) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:57:08 WORKER: start processing job (0, 0, 14)\n",
      "13:57:08 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:57:08 WORKER: args: ()\n",
      "13:57:08 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 25, 'numNeurons': 77, 'optimizer': 'Nadam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:57:17 DISPATCHER: Starting worker discovery\n",
      "13:57:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:57:17 DISPATCHER: Finished worker discovery\n",
      "13:58:17 DISPATCHER: Starting worker discovery\n",
      "13:58:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:58:17 DISPATCHER: Finished worker discovery\n",
      "13:59:17 DISPATCHER: Starting worker discovery\n",
      "13:59:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "13:59:17 DISPATCHER: Finished worker discovery\n",
      "13:59:50 WORKER: done with job (0, 0, 14), trying to register it.\n",
      "13:59:50 WORKER: registered result for job (0, 0, 14) with dispatcher\n",
      "13:59:50 DISPATCHER: job (0, 0, 14) finished\n",
      "13:59:50 DISPATCHER: register_result: lock acquired\n",
      "13:59:50 DISPATCHER: job (0, 0, 14) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "13:59:50 job_id: (0, 0, 14)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 25, 'numNeurons': 77, 'optimizer': 'Nadam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 114.95707167861178, 'info': {'L1': 114.95707167861178, 'L2': 77.79445157297383, 'MAX': 4.340563612305518, 'TrainTime': 170.515625}}\n",
      "exception: None\n",
      "\n",
      "13:59:50 job_callback for (0, 0, 14) started\n",
      "13:59:50 DISPATCHER: Trying to submit another job.\n",
      "13:59:50 job_callback for (0, 0, 14) got condition\n",
      "13:59:50 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "13:59:50 Only 2 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "13:59:50 HBMASTER: Trying to run another job!\n",
      "13:59:50 job_callback for (0, 0, 14) finished\n",
      "13:59:50 HBMASTER: schedule new run for iteration 0\n",
      "13:59:50 HBMASTER: trying submitting job (0, 0, 15) to dispatcher\n",
      "13:59:50 HBMASTER: submitting job (0, 0, 15) to dispatcher\n",
      "13:59:50 DISPATCHER: trying to submit job (0, 0, 15)\n",
      "13:59:50 DISPATCHER: trying to notify the job_runner thread.\n",
      "13:59:50 HBMASTER: job (0, 0, 15) submitted to dispatcher\n",
      "13:59:50 DISPATCHER: Trying to submit another job.\n",
      "13:59:50 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "13:59:50 DISPATCHER: starting job (0, 0, 15) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:59:50 DISPATCHER: job (0, 0, 15) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "13:59:50 WORKER: start processing job (0, 0, 15)\n",
      "13:59:50 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "13:59:50 WORKER: args: ()\n",
      "13:59:50 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 30, 'numNeurons': 30, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:00:17 DISPATCHER: Starting worker discovery\n",
      "14:00:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:00:17 DISPATCHER: Finished worker discovery\n",
      "14:01:17 DISPATCHER: Starting worker discovery\n",
      "14:01:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:01:17 DISPATCHER: Finished worker discovery\n",
      "14:02:17 DISPATCHER: Starting worker discovery\n",
      "14:02:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:02:17 DISPATCHER: Finished worker discovery\n",
      "14:03:17 DISPATCHER: Starting worker discovery\n",
      "14:03:17 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:03:18 DISPATCHER: Finished worker discovery\n",
      "14:04:18 DISPATCHER: Starting worker discovery\n",
      "14:04:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:04:18 DISPATCHER: Finished worker discovery\n",
      "14:05:18 DISPATCHER: Starting worker discovery\n",
      "14:05:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:05:18 DISPATCHER: Finished worker discovery\n",
      "14:06:11 WORKER: done with job (0, 0, 15), trying to register it.\n",
      "14:06:11 WORKER: registered result for job (0, 0, 15) with dispatcher\n",
      "14:06:11 DISPATCHER: job (0, 0, 15) finished\n",
      "14:06:11 DISPATCHER: register_result: lock acquired\n",
      "14:06:11 DISPATCHER: job (0, 0, 15) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:06:12 job_id: (0, 0, 15)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 5, 'loss': 'mse', 'numLayers': 30, 'numNeurons': 30, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 211.07726059501064, 'info': {'L1': 211.07726059501064, 'L2': 181.3255625568101, 'MAX': 4.192966140484497, 'TrainTime': 390.515625}}\n",
      "exception: None\n",
      "\n",
      "14:06:12 job_callback for (0, 0, 15) started\n",
      "14:06:12 DISPATCHER: Trying to submit another job.\n",
      "14:06:12 job_callback for (0, 0, 15) got condition\n",
      "14:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:06:12 Only 3 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "14:06:12 HBMASTER: Trying to run another job!\n",
      "14:06:12 job_callback for (0, 0, 15) finished\n",
      "14:06:12 HBMASTER: schedule new run for iteration 0\n",
      "14:06:12 HBMASTER: trying submitting job (0, 0, 18) to dispatcher\n",
      "14:06:12 HBMASTER: submitting job (0, 0, 18) to dispatcher\n",
      "14:06:12 DISPATCHER: trying to submit job (0, 0, 18)\n",
      "14:06:12 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:06:12 HBMASTER: job (0, 0, 18) submitted to dispatcher\n",
      "14:06:12 DISPATCHER: Trying to submit another job.\n",
      "14:06:12 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:06:12 DISPATCHER: starting job (0, 0, 18) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:06:12 DISPATCHER: job (0, 0, 18) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:06:12 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:06:12 WORKER: start processing job (0, 0, 18)\n",
      "14:06:12 WORKER: args: ()\n",
      "14:06:12 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 75, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 1000 \n",
      "Total batches: 20 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:06:18 DISPATCHER: Starting worker discovery\n",
      "14:06:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:06:18 DISPATCHER: Finished worker discovery\n",
      "14:07:18 DISPATCHER: Starting worker discovery\n",
      "14:07:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:07:18 DISPATCHER: Finished worker discovery\n",
      "14:08:18 DISPATCHER: Starting worker discovery\n",
      "14:08:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:08:18 DISPATCHER: Finished worker discovery\n",
      "14:09:18 DISPATCHER: Starting worker discovery\n",
      "14:09:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:09:18 DISPATCHER: Finished worker discovery\n",
      "14:10:18 DISPATCHER: Starting worker discovery\n",
      "14:10:18 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:10:19 DISPATCHER: Finished worker discovery\n",
      "14:11:19 DISPATCHER: Starting worker discovery\n",
      "14:11:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:11:19 DISPATCHER: Finished worker discovery\n",
      "14:12:19 DISPATCHER: Starting worker discovery\n",
      "14:12:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:12:19 DISPATCHER: Finished worker discovery\n",
      "14:12:20 WORKER: done with job (0, 0, 18), trying to register it.\n",
      "14:12:20 WORKER: registered result for job (0, 0, 18) with dispatcher\n",
      "14:12:20 DISPATCHER: job (0, 0, 18) finished\n",
      "14:12:20 DISPATCHER: register_result: lock acquired\n",
      "14:12:20 DISPATCHER: job (0, 0, 18) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:12:20 job_id: (0, 0, 18)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 1000, 'denspt': 5, 'loss': 'mae', 'numLayers': 19, 'numNeurons': 75, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 97.63025326712638, 'info': {'L1': 97.63025326712638, 'L2': 60.66541016497935, 'MAX': 2.9620546471831055, 'TrainTime': 376.859375}}\n",
      "exception: None\n",
      "\n",
      "14:12:20 job_callback for (0, 0, 18) started\n",
      "14:12:20 DISPATCHER: Trying to submit another job.\n",
      "14:12:20 job_callback for (0, 0, 18) got condition\n",
      "14:12:20 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:12:20 Only 4 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "14:12:20 HBMASTER: Trying to run another job!\n",
      "14:12:20 job_callback for (0, 0, 18) finished\n",
      "14:12:20 HBMASTER: schedule new run for iteration 0\n",
      "14:12:20 HBMASTER: trying submitting job (0, 0, 22) to dispatcher\n",
      "14:12:20 HBMASTER: submitting job (0, 0, 22) to dispatcher\n",
      "14:12:20 DISPATCHER: trying to submit job (0, 0, 22)\n",
      "14:12:21 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:12:21 HBMASTER: job (0, 0, 22) submitted to dispatcher\n",
      "14:12:21 DISPATCHER: Trying to submit another job.\n",
      "14:12:21 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:12:21 DISPATCHER: starting job (0, 0, 22) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:12:21 DISPATCHER: job (0, 0, 22) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:12:21 WORKER: start processing job (0, 0, 22)\n",
      "14:12:21 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:12:21 WORKER: args: ()\n",
      "14:12:21 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 6, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 72, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 1000 \n",
      "Total batches: 35 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:13:19 DISPATCHER: Starting worker discovery\n",
      "14:13:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:13:19 DISPATCHER: Finished worker discovery\n",
      "14:14:19 DISPATCHER: Starting worker discovery\n",
      "14:14:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:14:19 DISPATCHER: Finished worker discovery\n",
      "14:15:19 DISPATCHER: Starting worker discovery\n",
      "14:15:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:15:19 DISPATCHER: Finished worker discovery\n",
      "14:15:36 WORKER: done with job (0, 0, 22), trying to register it.\n",
      "14:15:36 WORKER: registered result for job (0, 0, 22) with dispatcher\n",
      "14:15:36 DISPATCHER: job (0, 0, 22) finished\n",
      "14:15:36 DISPATCHER: register_result: lock acquired\n",
      "14:15:36 DISPATCHER: job (0, 0, 22) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:15:36 job_id: (0, 0, 22)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 1000, 'denspt': 6, 'loss': 'mse', 'numLayers': 13, 'numNeurons': 72, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 523.9869811919278, 'info': {'L1': 523.9869811919278, 'L2': 3403.3389303708946, 'MAX': 35.97773822085937, 'TrainTime': 202.9375}}\n",
      "exception: None\n",
      "\n",
      "14:15:36 job_callback for (0, 0, 22) started\n",
      "14:15:36 DISPATCHER: Trying to submit another job.\n",
      "14:15:36 job_callback for (0, 0, 22) got condition\n",
      "14:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:15:36 Only 5 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "14:15:36 HBMASTER: Trying to run another job!\n",
      "14:15:36 job_callback for (0, 0, 22) finished\n",
      "14:15:36 HBMASTER: schedule new run for iteration 0\n",
      "14:15:36 HBMASTER: trying submitting job (0, 0, 25) to dispatcher\n",
      "14:15:36 HBMASTER: submitting job (0, 0, 25) to dispatcher\n",
      "14:15:36 DISPATCHER: trying to submit job (0, 0, 25)\n",
      "14:15:36 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:15:36 HBMASTER: job (0, 0, 25) submitted to dispatcher\n",
      "14:15:36 DISPATCHER: Trying to submit another job.\n",
      "14:15:36 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:15:36 DISPATCHER: starting job (0, 0, 25) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:15:36 DISPATCHER: job (0, 0, 25) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:15:36 WORKER: start processing job (0, 0, 25)\n",
      "14:15:36 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:15:36 WORKER: args: ()\n",
      "14:15:36 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 20000 \n",
      "Batch size: 5000 \n",
      "Total batches: 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:16:19 DISPATCHER: Starting worker discovery\n",
      "14:16:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:16:19 DISPATCHER: Finished worker discovery\n",
      "14:17:19 DISPATCHER: Starting worker discovery\n",
      "14:17:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:17:19 DISPATCHER: Finished worker discovery\n",
      "14:18:11 WORKER: done with job (0, 0, 25), trying to register it.\n",
      "14:18:11 WORKER: registered result for job (0, 0, 25) with dispatcher\n",
      "14:18:11 DISPATCHER: job (0, 0, 25) finished\n",
      "14:18:11 DISPATCHER: register_result: lock acquired\n",
      "14:18:11 DISPATCHER: job (0, 0, 25) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:18:11 job_id: (0, 0, 25)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 5, 'loss': 'mae', 'numLayers': 26, 'numNeurons': 43, 'optimizer': 'SGD'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 333.31977516043173, 'info': {'L1': 333.31977516043173, 'L2': 405.08529885696726, 'MAX': 5.0544003728117675, 'TrainTime': 163.53125}}\n",
      "exception: None\n",
      "\n",
      "14:18:11 job_callback for (0, 0, 25) started\n",
      "14:18:11 DISPATCHER: Trying to submit another job.\n",
      "14:18:11 job_callback for (0, 0, 25) got condition\n",
      "14:18:11 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:18:11 Only 6 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "14:18:11 HBMASTER: Trying to run another job!\n",
      "14:18:11 job_callback for (0, 0, 25) finished\n",
      "14:18:11 HBMASTER: schedule new run for iteration 0\n",
      "14:18:11 HBMASTER: trying submitting job (0, 0, 26) to dispatcher\n",
      "14:18:11 HBMASTER: submitting job (0, 0, 26) to dispatcher\n",
      "14:18:11 DISPATCHER: trying to submit job (0, 0, 26)\n",
      "14:18:11 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:18:11 HBMASTER: job (0, 0, 26) submitted to dispatcher\n",
      "14:18:11 DISPATCHER: Trying to submit another job.\n",
      "14:18:11 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:18:11 DISPATCHER: starting job (0, 0, 26) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:18:11 DISPATCHER: job (0, 0, 26) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:18:11 WORKER: start processing job (0, 0, 26)\n",
      "14:18:11 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:18:11 WORKER: args: ()\n",
      "14:18:11 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 8, 'numNeurons': 40, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 54880 \n",
      "Batch size: 1000 \n",
      "Total batches: 55 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:18:19 DISPATCHER: Starting worker discovery\n",
      "14:18:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:18:19 DISPATCHER: Finished worker discovery\n",
      "14:19:19 DISPATCHER: Starting worker discovery\n",
      "14:19:19 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:19:20 DISPATCHER: Finished worker discovery\n",
      "14:20:20 DISPATCHER: Starting worker discovery\n",
      "14:20:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:20:20 DISPATCHER: Finished worker discovery\n",
      "14:21:20 DISPATCHER: Starting worker discovery\n",
      "14:21:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:21:20 DISPATCHER: Finished worker discovery\n",
      "14:22:20 DISPATCHER: Starting worker discovery\n",
      "14:22:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:22:20 DISPATCHER: Finished worker discovery\n",
      "14:23:20 DISPATCHER: Starting worker discovery\n",
      "14:23:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:23:20 DISPATCHER: Finished worker discovery\n",
      "14:24:20 DISPATCHER: Starting worker discovery\n",
      "14:24:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:24:20 DISPATCHER: Finished worker discovery\n",
      "14:25:20 DISPATCHER: Starting worker discovery\n",
      "14:25:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:25:20 DISPATCHER: Finished worker discovery\n",
      "14:26:20 DISPATCHER: Starting worker discovery\n",
      "14:26:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:26:20 DISPATCHER: Finished worker discovery\n",
      "14:27:20 DISPATCHER: Starting worker discovery\n",
      "14:27:20 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:27:21 DISPATCHER: Finished worker discovery\n",
      "14:28:21 DISPATCHER: Starting worker discovery\n",
      "14:28:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:28:21 DISPATCHER: Finished worker discovery\n",
      "14:29:21 DISPATCHER: Starting worker discovery\n",
      "14:29:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:29:21 DISPATCHER: Finished worker discovery\n",
      "14:30:21 DISPATCHER: Starting worker discovery\n",
      "14:30:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:30:21 DISPATCHER: Finished worker discovery\n",
      "14:31:21 DISPATCHER: Starting worker discovery\n",
      "14:31:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:31:21 DISPATCHER: Finished worker discovery\n",
      "14:32:21 DISPATCHER: Starting worker discovery\n",
      "14:32:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:32:21 DISPATCHER: Finished worker discovery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:33:21 DISPATCHER: Starting worker discovery\n",
      "14:33:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:33:21 DISPATCHER: Finished worker discovery\n",
      "14:34:21 DISPATCHER: Starting worker discovery\n",
      "14:34:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:34:21 DISPATCHER: Finished worker discovery\n",
      "14:34:54 WORKER: done with job (0, 0, 26), trying to register it.\n",
      "14:34:54 WORKER: registered result for job (0, 0, 26) with dispatcher\n",
      "14:34:54 DISPATCHER: job (0, 0, 26) finished\n",
      "14:34:54 DISPATCHER: register_result: lock acquired\n",
      "14:34:54 DISPATCHER: job (0, 0, 26) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:34:54 job_id: (0, 0, 26)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 1000, 'denspt': 7, 'loss': 'mae', 'numLayers': 8, 'numNeurons': 40, 'optimizer': 'Adam'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 108.86150342341871, 'info': {'L1': 108.86150342341871, 'L2': 82.27742355862773, 'MAX': 4.741266088806983, 'TrainTime': 1031.84375}}\n",
      "exception: None\n",
      "\n",
      "14:34:54 job_callback for (0, 0, 26) started\n",
      "14:34:54 DISPATCHER: Trying to submit another job.\n",
      "14:34:54 job_callback for (0, 0, 26) got condition\n",
      "14:34:54 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:34:54 Only 7 run(s) for budget 37.037037 available, need more than 9 -> can't build model!\n",
      "14:34:54 HBMASTER: Trying to run another job!\n",
      "14:34:54 job_callback for (0, 0, 26) finished\n",
      "14:34:54 HBMASTER: schedule new run for iteration 0\n",
      "14:34:54 HBMASTER: trying submitting job (0, 0, 27) to dispatcher\n",
      "14:34:54 HBMASTER: submitting job (0, 0, 27) to dispatcher\n",
      "14:34:54 DISPATCHER: trying to submit job (0, 0, 27)\n",
      "14:34:54 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:34:54 HBMASTER: job (0, 0, 27) submitted to dispatcher\n",
      "14:34:54 DISPATCHER: Trying to submit another job.\n",
      "14:34:54 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:34:54 DISPATCHER: starting job (0, 0, 27) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:34:54 DISPATCHER: job (0, 0, 27) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:34:54 WORKER: start processing job (0, 0, 27)\n",
      "14:34:54 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:34:54 WORKER: args: ()\n",
      "14:34:54 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:35:21 DISPATCHER: Starting worker discovery\n",
      "14:35:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:35:21 DISPATCHER: Finished worker discovery\n",
      "14:36:21 DISPATCHER: Starting worker discovery\n",
      "14:36:21 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:36:21 DISPATCHER: Finished worker discovery\n",
      "14:37:22 DISPATCHER: Starting worker discovery\n",
      "14:37:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:37:22 DISPATCHER: Finished worker discovery\n",
      "14:38:22 DISPATCHER: Starting worker discovery\n",
      "14:38:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:38:22 DISPATCHER: Finished worker discovery\n",
      "14:39:13 WORKER: done with job (0, 0, 27), trying to register it.\n",
      "14:39:13 WORKER: registered result for job (0, 0, 27) with dispatcher\n",
      "14:39:13 DISPATCHER: job (0, 0, 27) finished\n",
      "14:39:13 DISPATCHER: register_result: lock acquired\n",
      "14:39:13 DISPATCHER: job (0, 0, 27) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952 finished\n",
      "14:39:13 job_id: (0, 0, 27)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 14, 'numNeurons': 67, 'optimizer': 'RMSprop'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n",
      "result: {'loss': 439.0498292148911, 'info': {'L1': 439.0498292148911, 'L2': 673.2408799279071, 'MAX': 5.795030750012085, 'TrainTime': 274.671875}}\n",
      "exception: None\n",
      "\n",
      "14:39:13 job_callback for (0, 0, 27) started\n",
      "14:39:13 job_callback for (0, 0, 27) got condition\n",
      "14:39:13 DISPATCHER: Trying to submit another job.\n",
      "14:39:13 HBMASTER: Trying to run another job!\n",
      "14:39:13 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "14:39:13 job_callback for (0, 0, 27) finished\n",
      "14:39:13 HBMASTER: schedule new run for iteration 0\n",
      "14:39:13 HBMASTER: trying submitting job (0, 0, 28) to dispatcher\n",
      "14:39:13 HBMASTER: submitting job (0, 0, 28) to dispatcher\n",
      "14:39:13 DISPATCHER: trying to submit job (0, 0, 28)\n",
      "14:39:13 DISPATCHER: trying to notify the job_runner thread.\n",
      "14:39:13 HBMASTER: job (0, 0, 28) submitted to dispatcher\n",
      "14:39:13 DISPATCHER: Trying to submit another job.\n",
      "14:39:13 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "14:39:13 DISPATCHER: starting job (0, 0, 28) on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:39:13 DISPATCHER: job (0, 0, 28) dispatched on hpbandster.run_example1.worker.DESKTOP-NKTB8UL.596411952\n",
      "14:39:13 WORKER: start processing job (0, 0, 28)\n",
      "14:39:13 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "14:39:13 WORKER: args: ()\n",
      "14:39:13 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 30, 'numNeurons': 82, 'optimizer': 'RMSprop'}, 'budget': 37.03703703703704, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 34560 \n",
      "Batch size: 5000 \n",
      "Total batches: 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:39:22 DISPATCHER: Starting worker discovery\n",
      "14:39:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:39:22 DISPATCHER: Finished worker discovery\n",
      "14:40:22 DISPATCHER: Starting worker discovery\n",
      "14:40:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:40:22 DISPATCHER: Finished worker discovery\n",
      "14:41:22 DISPATCHER: Starting worker discovery\n",
      "14:41:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:41:22 DISPATCHER: Finished worker discovery\n",
      "14:42:22 DISPATCHER: Starting worker discovery\n",
      "14:42:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:42:22 DISPATCHER: Finished worker discovery\n",
      "14:43:22 DISPATCHER: Starting worker discovery\n",
      "14:43:22 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "14:43:22 DISPATCHER: Finished worker discovery\n"
     ]
    }
   ],
   "source": [
    "bohb = BOHB(  configspace = w.get_configspace(),\n",
    "              run_id = 'example1', nameserver='127.0.0.1',\n",
    "              min_budget=10, max_budget=1000\n",
    "           )\n",
    "res = bohb.run(n_iterations=25\n",
    "              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29a746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(args.shared_directory, 'results.pkl'), 'wb') as fh:\n",
    "    pickle.dump(res, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bohb.shutdown(shutdown_workers=True)\n",
    "NS.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95790296",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2config = res.get_id2config_mapping()\n",
    "incumbent = res.get_incumbent_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039257fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
