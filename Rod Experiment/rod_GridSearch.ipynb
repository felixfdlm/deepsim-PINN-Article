{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "979070ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpbandster.core.nameserver as hpns\n",
    "import hpbandster.core.result as hpres\n",
    "\n",
    "from hpbandster.optimizers import BOHB as BOHB\n",
    "import pickle\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d2a99fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- SCIANN 0.6.4.5 ---------------------- \n",
      "For details, check out our review paper and the documentation at: \n",
      " +  \"https://www.sciencedirect.com/science/article/pii/S0045782520307374\", \n",
      " +  \"https://arxiv.org/abs/2005.08803\", \n",
      " +  \"https://www.sciann.com\". \n",
      "\n",
      " Need support or would like to contribute, please join sciann`s slack group: \n",
      " +  \"https://join.slack.com/t/sciann/shared_invite/zt-ne1f5jlx-k_dY8RGo3ZreDXwz0f~CeA\" \n",
      " \n",
      "TensorFlow Version: 2.3.0 \n",
      "Python Version: 3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "\n",
    "import System as SEQ\n",
    "%run rod_EQS.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e17c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pinn_Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4973be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gridObj = SEQ.Grid(2,{'x':0,'t':1},[[[0,2],[0,10]]],10)\n",
    "configspecs = {\n",
    "    'denspt':[5,12],\n",
    "    'numNeurons':[10,100],\n",
    "    'numLayers':[2,50],\n",
    "    'activator':['tanh','relu','softmax','sigmoid'],\n",
    "    'loss':['mae','mse'],\n",
    "    'optimizer':['Adam','RMSprop','SGD','Nadam','Ftrl'],\n",
    "    'batch_size':[5000,10000,15000,25000]\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958646b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_n(n,x,t):\n",
    "  mu_n = (2*n+1)*np.pi/4\n",
    "  T_n =  np.exp(-t*(mu_n**2))\n",
    "  X_n = -np.cos(mu_n*x)*2.5/(mu_n**2)\n",
    "  return X_n*T_n\n",
    "\n",
    "depth = 100\n",
    "\n",
    "u_pred_Simb = (np.sum((np.array([u_n(n,test_gridObj.grid[:,0],test_gridObj.grid[:,1]) for n in range(depth)])),axis=0)+5)[:,None]\n",
    "valData = np.concatenate((test_gridObj.grid,u_pred_Simb),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89a954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying validation data to test grid\n",
      "Saving PDE and config\n",
      "Worker ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:36:38 WORKER: Connected to nameserver <Pyro4.core.Proxy at 0x27ad28f3348; connected IPv4; for PYRO:Pyro.NameServer@127.0.0.1:9090>\n",
      "21:36:38 WORKER: No dispatcher found. Waiting for one to initiate contact.\n",
      "21:36:38 WORKER: start listening for jobs\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Start a nameserver\n",
    "# Every run needs a nameserver. It could be a 'static' server with a\n",
    "# permanent address, but here it will be started for the local machine with the default port.\n",
    "# The nameserver manages the concurrent running workers across all possible threads or clusternodes.\n",
    "# Note the run_id argument. This uniquely identifies a run of any HpBandSter optimizer.\n",
    "NS = hpns.NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
    "NS.start()\n",
    "\n",
    "# Step 2: Start a worker\n",
    "# Now we can instantiate a worker, providing the mandatory information\n",
    "# Besides the sleep_interval, we need to define the nameserver information and\n",
    "# the same run_id as above. After that, we can start the worker in the background,\n",
    "# where it will wait for incoming configurations to evaluate.\n",
    "\n",
    "numWorkers = 1\n",
    "\n",
    "workers=[]\n",
    "for i in range(numWorkers):\n",
    "    \n",
    "    w = Pinn_Worker.PINN_Worker(\n",
    "    valData = valData,\n",
    "    test_gridObj=test_gridObj,\n",
    "    PDESystem=mySys,\n",
    "    configspecs = configspecs,\n",
    "    valFromFEM=False,\n",
    "    nameserver='127.0.0.1',\n",
    "    run_id='rod_GridSearch_1',id=i)\n",
    "    \n",
    "    w.run(background=True)\n",
    "    \n",
    "    workers.append(w)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691636e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:36:38 wait_for_workers trying to get the condition\n",
      "21:36:38 DISPATCHER: started the 'discover_worker' thread\n",
      "21:36:38 DISPATCHER: started the 'job_runner' thread\n",
      "21:36:38 DISPATCHER: Pyro daemon running on localhost:56195\n",
      "21:36:38 DISPATCHER: Starting worker discovery\n",
      "21:36:38 DISPATCHER: Found 1 potential workers, 0 currently in the pool.\n",
      "21:36:38 DISPATCHER: discovered new worker, hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:36:38 HBMASTER: number of workers changed to 1\n",
      "21:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:36:38 HBMASTER: only 1 worker(s) available, waiting for at least 1.\n",
      "21:36:38 adjust_queue_size: lock accquired\n",
      "21:36:38 HBMASTER: adjusted queue size to (0, 1)\n",
      "21:36:38 DISPATCHER: Finished worker discovery\n",
      "21:36:38 DISPATCHER: A new worker triggered discover_worker\n",
      "21:36:38 DISPATCHER: Trying to submit another job.\n",
      "21:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:36:38 Enough workers to start this run!\n",
      "21:36:38 DISPATCHER: Starting worker discovery\n",
      "21:36:38 HBMASTER: starting run at 1639600598.9464648\n",
      "21:36:38 start sampling a new configuration.\n",
      "21:36:38 done sampling a new configuration.\n",
      "21:36:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "21:36:38 HBMASTER: schedule new run for iteration 0\n",
      "21:36:38 HBMASTER: trying submitting job (0, 0, 0) to dispatcher\n",
      "21:36:38 HBMASTER: submitting job (0, 0, 0) to dispatcher\n",
      "21:36:38 DISPATCHER: trying to submit job (0, 0, 0)\n",
      "21:36:38 DISPATCHER: Finished worker discovery\n",
      "21:36:38 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:36:38 HBMASTER: job (0, 0, 0) submitted to dispatcher\n",
      "21:36:38 DISPATCHER: Trying to submit another job.\n",
      "21:36:38 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:36:38 DISPATCHER: starting job (0, 0, 0) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:36:38 DISPATCHER: job (0, 0, 0) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:36:38 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:36:38 WORKER: start processing job (0, 0, 0)\n",
      "21:36:38 WORKER: args: ()\n",
      "21:36:38 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 6, 'loss': 'mae', 'numLayers': 10, 'numNeurons': 40, 'optimizer': 'SGD'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "21:36:39 Popen(['git', 'version'], cwd=C:\\Users\\Felix\\Desktop\\GitHub\\deepsim-PINN-Article\\Rod Experiment, universal_newlines=False, shell=None, istream=None)\n",
      "21:36:39 Popen(['git', 'version'], cwd=C:\\Users\\Felix\\Desktop\\GitHub\\deepsim-PINN-Article\\Rod Experiment, universal_newlines=False, shell=None, istream=None)\n",
      "21:36:39 Failed checking if running in CYGWIN due to: FileNotFoundError(2, 'El sistema no puede encontrar el archivo especificado', None, 2, None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 720 \n",
      "Batch size: 720 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:37:10 WORKER: done with job (0, 0, 0), trying to register it.\n",
      "21:37:10 WORKER: registered result for job (0, 0, 0) with dispatcher\n",
      "21:37:10 DISPATCHER: job (0, 0, 0) finished\n",
      "21:37:10 DISPATCHER: register_result: lock acquired\n",
      "21:37:10 DISPATCHER: job (0, 0, 0) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:37:10 job_id: (0, 0, 0)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 6, 'loss': 'mae', 'numLayers': 10, 'numNeurons': 40, 'optimizer': 'SGD'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 50.38281659932367, 'info': {'L1': 50.38281659932367, 'L2': 67.55893235609483, 'MAX': 2.956385850906372, 'TrainTime': 15.59375}}\n",
      "exception: None\n",
      "\n",
      "21:37:10 job_callback for (0, 0, 0) started\n",
      "21:37:10 DISPATCHER: Trying to submit another job.\n",
      "21:37:10 job_callback for (0, 0, 0) got condition\n",
      "21:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:37:10 Only 1 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:37:10 HBMASTER: Trying to run another job!\n",
      "21:37:10 job_callback for (0, 0, 0) finished\n",
      "21:37:10 start sampling a new configuration.\n",
      "21:37:10 done sampling a new configuration.\n",
      "21:37:10 HBMASTER: schedule new run for iteration 0\n",
      "21:37:10 HBMASTER: trying submitting job (0, 0, 1) to dispatcher\n",
      "21:37:10 HBMASTER: submitting job (0, 0, 1) to dispatcher\n",
      "21:37:10 DISPATCHER: trying to submit job (0, 0, 1)\n",
      "21:37:10 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:37:10 HBMASTER: job (0, 0, 1) submitted to dispatcher\n",
      "21:37:10 DISPATCHER: Trying to submit another job.\n",
      "21:37:10 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:37:10 DISPATCHER: starting job (0, 0, 1) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:37:10 DISPATCHER: job (0, 0, 1) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:37:10 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:37:10 WORKER: start processing job (0, 0, 1)\n",
      "21:37:10 WORKER: args: ()\n",
      "21:37:10 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 11, 'loss': 'mae', 'numLayers': 36, 'numNeurons': 56, 'optimizer': 'Adam'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 2420 \n",
      "Batch size: 2420 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:37:35 WORKER: done with job (0, 0, 1), trying to register it.\n",
      "21:37:35 WORKER: registered result for job (0, 0, 1) with dispatcher\n",
      "21:37:35 DISPATCHER: job (0, 0, 1) finished\n",
      "21:37:35 DISPATCHER: register_result: lock acquired\n",
      "21:37:35 DISPATCHER: job (0, 0, 1) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:37:35 job_id: (0, 0, 1)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 5000, 'denspt': 11, 'loss': 'mae', 'numLayers': 36, 'numNeurons': 56, 'optimizer': 'Adam'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 55.29349100071585, 'info': {'L1': 55.29349100071585, 'L2': 80.88696878014106, 'MAX': 3.1693594455718994, 'TrainTime': 20.375}}\n",
      "exception: None\n",
      "\n",
      "21:37:35 job_callback for (0, 0, 1) started\n",
      "21:37:35 DISPATCHER: Trying to submit another job.\n",
      "21:37:35 job_callback for (0, 0, 1) got condition\n",
      "21:37:35 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:37:35 Only 2 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:37:35 HBMASTER: Trying to run another job!\n",
      "21:37:35 job_callback for (0, 0, 1) finished\n",
      "21:37:35 start sampling a new configuration.\n",
      "21:37:35 done sampling a new configuration.\n",
      "21:37:35 HBMASTER: schedule new run for iteration 0\n",
      "21:37:35 HBMASTER: trying submitting job (0, 0, 2) to dispatcher\n",
      "21:37:35 HBMASTER: submitting job (0, 0, 2) to dispatcher\n",
      "21:37:35 DISPATCHER: trying to submit job (0, 0, 2)\n",
      "21:37:35 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:37:35 HBMASTER: job (0, 0, 2) submitted to dispatcher\n",
      "21:37:35 DISPATCHER: Trying to submit another job.\n",
      "21:37:35 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:37:35 DISPATCHER: starting job (0, 0, 2) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:37:35 DISPATCHER: job (0, 0, 2) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:37:35 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:37:35 WORKER: start processing job (0, 0, 2)\n",
      "21:37:35 WORKER: args: ()\n",
      "21:37:35 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 10, 'loss': 'mae', 'numLayers': 23, 'numNeurons': 74, 'optimizer': 'Nadam'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 2000 \n",
      "Batch size: 2000 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:37:38 DISPATCHER: Starting worker discovery\n",
      "21:37:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "21:37:38 DISPATCHER: Finished worker discovery\n",
      "21:38:01 WORKER: done with job (0, 0, 2), trying to register it.\n",
      "21:38:01 WORKER: registered result for job (0, 0, 2) with dispatcher\n",
      "21:38:01 DISPATCHER: job (0, 0, 2) finished\n",
      "21:38:01 DISPATCHER: register_result: lock acquired\n",
      "21:38:01 DISPATCHER: job (0, 0, 2) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:38:01 job_id: (0, 0, 2)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 10000, 'denspt': 10, 'loss': 'mae', 'numLayers': 23, 'numNeurons': 74, 'optimizer': 'Nadam'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 21.26149211061273, 'info': {'L1': 21.26149211061273, 'L2': 12.714824570599802, 'MAX': 3.6824222015255064, 'TrainTime': 16.1875}}\n",
      "exception: None\n",
      "\n",
      "21:38:01 job_callback for (0, 0, 2) started\n",
      "21:38:01 DISPATCHER: Trying to submit another job.\n",
      "21:38:01 job_callback for (0, 0, 2) got condition\n",
      "21:38:01 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:38:01 Only 3 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:38:01 HBMASTER: Trying to run another job!\n",
      "21:38:01 job_callback for (0, 0, 2) finished\n",
      "21:38:01 start sampling a new configuration.\n",
      "21:38:01 done sampling a new configuration.\n",
      "21:38:01 HBMASTER: schedule new run for iteration 0\n",
      "21:38:01 HBMASTER: trying submitting job (0, 0, 3) to dispatcher\n",
      "21:38:01 HBMASTER: submitting job (0, 0, 3) to dispatcher\n",
      "21:38:01 DISPATCHER: trying to submit job (0, 0, 3)\n",
      "21:38:01 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:38:01 HBMASTER: job (0, 0, 3) submitted to dispatcher\n",
      "21:38:01 DISPATCHER: Trying to submit another job.\n",
      "21:38:01 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:38:01 DISPATCHER: starting job (0, 0, 3) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:01 DISPATCHER: job (0, 0, 3) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:01 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:38:01 WORKER: start processing job (0, 0, 3)\n",
      "21:38:01 WORKER: args: ()\n",
      "21:38:01 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 11, 'loss': 'mse', 'numLayers': 40, 'numNeurons': 42, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 2420 \n",
      "Batch size: 2420 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:38:25 WORKER: done with job (0, 0, 3), trying to register it.\n",
      "21:38:25 WORKER: registered result for job (0, 0, 3) with dispatcher\n",
      "21:38:25 DISPATCHER: job (0, 0, 3) finished\n",
      "21:38:25 DISPATCHER: register_result: lock acquired\n",
      "21:38:25 DISPATCHER: job (0, 0, 3) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:38:25 job_id: (0, 0, 3)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 25000, 'denspt': 11, 'loss': 'mse', 'numLayers': 40, 'numNeurons': 42, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 20.322183294226996, 'info': {'L1': 20.322183294226996, 'L2': 14.504865204213637, 'MAX': 2.2428424545445678, 'TrainTime': 16.0}}\n",
      "exception: None\n",
      "\n",
      "21:38:25 job_callback for (0, 0, 3) started\n",
      "21:38:25 job_callback for (0, 0, 3) got condition\n",
      "21:38:25 Only 4 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:38:25 DISPATCHER: Trying to submit another job.\n",
      "21:38:25 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:38:25 HBMASTER: Trying to run another job!\n",
      "21:38:25 job_callback for (0, 0, 3) finished\n",
      "21:38:25 start sampling a new configuration.\n",
      "21:38:25 done sampling a new configuration.\n",
      "21:38:25 HBMASTER: schedule new run for iteration 0\n",
      "21:38:25 HBMASTER: trying submitting job (0, 0, 4) to dispatcher\n",
      "21:38:25 HBMASTER: submitting job (0, 0, 4) to dispatcher\n",
      "21:38:25 DISPATCHER: trying to submit job (0, 0, 4)\n",
      "21:38:25 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:38:25 HBMASTER: job (0, 0, 4) submitted to dispatcher\n",
      "21:38:25 DISPATCHER: Trying to submit another job.\n",
      "21:38:25 DISPATCHER: starting job (0, 0, 4) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:25 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:38:25 DISPATCHER: job (0, 0, 4) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:25 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:38:25 WORKER: start processing job (0, 0, 4)\n",
      "21:38:25 WORKER: args: ()\n",
      "21:38:25 WORKER: kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 33, 'numNeurons': 29, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 720 \n",
      "Batch size: 720 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:38:38 DISPATCHER: Starting worker discovery\n",
      "21:38:38 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "21:38:38 DISPATCHER: Finished worker discovery\n",
      "21:38:52 WORKER: done with job (0, 0, 4), trying to register it.\n",
      "21:38:52 WORKER: registered result for job (0, 0, 4) with dispatcher\n",
      "21:38:52 DISPATCHER: job (0, 0, 4) finished\n",
      "21:38:52 DISPATCHER: register_result: lock acquired\n",
      "21:38:52 DISPATCHER: job (0, 0, 4) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:38:52 job_id: (0, 0, 4)\n",
      "kwargs: {'config': {'activator': 'softmax', 'batch_size': 5000, 'denspt': 6, 'loss': 'mse', 'numLayers': 33, 'numNeurons': 29, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 76.67645472420051, 'info': {'L1': 76.67645472420051, 'L2': 152.16708240587235, 'MAX': 4.252353191375732, 'TrainTime': 22.6875}}\n",
      "exception: None\n",
      "\n",
      "21:38:52 job_callback for (0, 0, 4) started\n",
      "21:38:52 job_callback for (0, 0, 4) got condition\n",
      "21:38:52 Only 5 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:38:52 DISPATCHER: Trying to submit another job.\n",
      "21:38:52 HBMASTER: Trying to run another job!\n",
      "21:38:52 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:38:52 job_callback for (0, 0, 4) finished\n",
      "21:38:52 start sampling a new configuration.\n",
      "21:38:52 done sampling a new configuration.\n",
      "21:38:52 HBMASTER: schedule new run for iteration 0\n",
      "21:38:52 HBMASTER: trying submitting job (0, 0, 5) to dispatcher\n",
      "21:38:52 HBMASTER: submitting job (0, 0, 5) to dispatcher\n",
      "21:38:52 DISPATCHER: trying to submit job (0, 0, 5)\n",
      "21:38:52 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:38:52 HBMASTER: job (0, 0, 5) submitted to dispatcher\n",
      "21:38:52 DISPATCHER: Trying to submit another job.\n",
      "21:38:52 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:38:52 DISPATCHER: starting job (0, 0, 5) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:52 DISPATCHER: job (0, 0, 5) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:38:52 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:38:52 WORKER: start processing job (0, 0, 5)\n",
      "21:38:52 WORKER: args: ()\n",
      "21:38:52 WORKER: kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 7, 'loss': 'mse', 'numLayers': 19, 'numNeurons': 91, 'optimizer': 'SGD'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 980 \n",
      "Batch size: 980 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:39:17 WORKER: done with job (0, 0, 5), trying to register it.\n",
      "21:39:17 WORKER: registered result for job (0, 0, 5) with dispatcher\n",
      "21:39:17 DISPATCHER: job (0, 0, 5) finished\n",
      "21:39:17 DISPATCHER: register_result: lock acquired\n",
      "21:39:17 DISPATCHER: job (0, 0, 5) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:39:17 job_id: (0, 0, 5)\n",
      "kwargs: {'config': {'activator': 'tanh', 'batch_size': 5000, 'denspt': 7, 'loss': 'mse', 'numLayers': 19, 'numNeurons': 91, 'optimizer': 'SGD'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 19.195657772492073, 'info': {'L1': 19.195657772492073, 'L2': 10.407876696759153, 'MAX': 3.3946276115291685, 'TrainTime': 19.09375}}\n",
      "exception: None\n",
      "\n",
      "21:39:17 job_callback for (0, 0, 5) started\n",
      "21:39:17 job_callback for (0, 0, 5) got condition\n",
      "21:39:17 DISPATCHER: Trying to submit another job.\n",
      "21:39:17 Only 6 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:39:17 HBMASTER: Trying to run another job!\n",
      "21:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:39:17 job_callback for (0, 0, 5) finished\n",
      "21:39:17 start sampling a new configuration.\n",
      "21:39:17 done sampling a new configuration.\n",
      "21:39:17 HBMASTER: schedule new run for iteration 0\n",
      "21:39:17 HBMASTER: trying submitting job (0, 0, 6) to dispatcher\n",
      "21:39:17 HBMASTER: submitting job (0, 0, 6) to dispatcher\n",
      "21:39:17 DISPATCHER: trying to submit job (0, 0, 6)\n",
      "21:39:17 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:39:17 HBMASTER: job (0, 0, 6) submitted to dispatcher\n",
      "21:39:17 DISPATCHER: Trying to submit another job.\n",
      "21:39:17 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:39:17 DISPATCHER: starting job (0, 0, 6) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:39:17 DISPATCHER: job (0, 0, 6) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:39:17 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:39:17 WORKER: start processing job (0, 0, 6)\n",
      "21:39:17 WORKER: args: ()\n",
      "21:39:17 WORKER: kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 9, 'loss': 'mae', 'numLayers': 17, 'numNeurons': 54, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 1620 \n",
      "Batch size: 1620 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:39:39 DISPATCHER: Starting worker discovery\n",
      "21:39:39 DISPATCHER: Found 1 potential workers, 1 currently in the pool.\n",
      "21:39:39 DISPATCHER: Finished worker discovery\n",
      "21:39:42 WORKER: done with job (0, 0, 6), trying to register it.\n",
      "21:39:42 WORKER: registered result for job (0, 0, 6) with dispatcher\n",
      "21:39:42 DISPATCHER: job (0, 0, 6) finished\n",
      "21:39:42 DISPATCHER: register_result: lock acquired\n",
      "21:39:42 DISPATCHER: job (0, 0, 6) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:39:42 job_id: (0, 0, 6)\n",
      "kwargs: {'config': {'activator': 'sigmoid', 'batch_size': 25000, 'denspt': 9, 'loss': 'mae', 'numLayers': 17, 'numNeurons': 54, 'optimizer': 'RMSprop'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 41.395411016527525, 'info': {'L1': 41.395411016527525, 'L2': 46.11974076087339, 'MAX': 2.5493987010830015, 'TrainTime': 23.015625}}\n",
      "exception: None\n",
      "\n",
      "21:39:42 job_callback for (0, 0, 6) started\n",
      "21:39:42 DISPATCHER: Trying to submit another job.\n",
      "21:39:42 job_callback for (0, 0, 6) got condition\n",
      "21:39:42 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:39:42 Only 7 run(s) for budget 185.185185 available, need more than 9 -> can't build model!\n",
      "21:39:42 HBMASTER: Trying to run another job!\n",
      "21:39:42 job_callback for (0, 0, 6) finished\n",
      "21:39:42 start sampling a new configuration.\n",
      "21:39:42 done sampling a new configuration.\n",
      "21:39:42 HBMASTER: schedule new run for iteration 0\n",
      "21:39:42 HBMASTER: trying submitting job (0, 0, 7) to dispatcher\n",
      "21:39:42 HBMASTER: submitting job (0, 0, 7) to dispatcher\n",
      "21:39:42 DISPATCHER: trying to submit job (0, 0, 7)\n",
      "21:39:42 DISPATCHER: trying to notify the job_runner thread.\n",
      "21:39:42 HBMASTER: job (0, 0, 7) submitted to dispatcher\n",
      "21:39:42 DISPATCHER: Trying to submit another job.\n",
      "21:39:42 HBMASTER: running jobs: 1, queue sizes: (0, 1) -> wait\n",
      "21:39:42 DISPATCHER: starting job (0, 0, 7) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:39:42 DISPATCHER: job (0, 0, 7) dispatched on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252\n",
      "21:39:42 DISPATCHER: jobs to submit = 0, number of idle workers = 0 -> waiting!\n",
      "21:39:42 WORKER: start processing job (0, 0, 7)\n",
      "21:39:42 WORKER: args: ()\n",
      "21:39:42 WORKER: kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 11, 'numNeurons': 23, 'optimizer': 'Ftrl'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 720 \n",
      "Batch size: 720 \n",
      "Total batches: 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:40:06 WORKER: done with job (0, 0, 7), trying to register it.\n",
      "21:40:06 WORKER: registered result for job (0, 0, 7) with dispatcher\n",
      "21:40:06 DISPATCHER: job (0, 0, 7) finished\n",
      "21:40:06 DISPATCHER: register_result: lock acquired\n",
      "21:40:06 DISPATCHER: job (0, 0, 7) on hpbandster.run_rod_GridSearch_1.worker.DESKTOP-NKTB8UL.1328.04252 finished\n",
      "21:40:06 job_id: (0, 0, 7)\n",
      "kwargs: {'config': {'activator': 'relu', 'batch_size': 5000, 'denspt': 6, 'loss': 'mae', 'numLayers': 11, 'numNeurons': 23, 'optimizer': 'Ftrl'}, 'budget': 185.18518518518516, 'working_directory': '.'}\n",
      "result: {'loss': 91.50431883739834, 'info': {'L1': 91.50431883739834, 'L2': 214.62176608774706, 'MAX': 4.995189644396305, 'TrainTime': 13.5625}}\n",
      "exception: None\n",
      "\n",
      "21:40:06 job_callback for (0, 0, 7) started\n",
      "21:40:06 job_callback for (0, 0, 7) got condition\n",
      "21:40:06 DISPATCHER: Trying to submit another job.\n",
      "21:40:06 DISPATCHER: jobs to submit = 0, number of idle workers = 1 -> waiting!\n",
      "21:40:06 HBMASTER: Trying to run another job!\n",
      "21:40:06 job_callback for (0, 0, 7) finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1328/2332826980.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mmin_budget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_budget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m            )\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbohb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_n_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumWorkers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\master.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, n_iterations, min_n_workers, iteration_kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                         \u001b[0mnext_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\hpbandster\\core\\master.py\u001b[0m in \u001b[0;36m_queue_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    277\u001b[0m                         \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'HBMASTER: running jobs: %i, queue sizes: %s -> wait'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_running_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_queue_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthread_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_submit_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbudget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf_gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bohb = BOHB(  configspace = w.get_configspace(),\n",
    "#               run_id = 'example1', nameserver='127.0.0.1',\n",
    "#               min_budget=10, max_budget=1000\n",
    "#            )\n",
    "# res = bohb.run(n_iterations=25\n",
    "#               )\n",
    "\n",
    "bohb = BOHB(  configspace = w.get_configspace(),\n",
    "              run_id = 'rod_GridSearch_1',\n",
    "              min_budget=100, max_budget=5000\n",
    "           )\n",
    "res = bohb.run(n_iterations=15, min_n_workers=numWorkers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc34189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_logical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eefa090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
