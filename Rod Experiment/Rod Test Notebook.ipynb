{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b852c3ca-7ccc-48e8-a0a1-1ce1f0a4b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is only for testing purposes.\n",
    "# Here we create an example PINN with maximum parameters (num neurons, num layers, batch size...), and \n",
    "# train it to check wether the machine can hold the experiments it must do during the grid search\n",
    "\n",
    "# Keep in mind the grid search may train multiple PINNs at the same time, so if you are using that option,\n",
    "# the testing done in this notebook may not be reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d61c444-bba8-4897-b964-5845a15278b5",
   "metadata": {},
   "source": [
    "# Imports  + Load rod equation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4fa2fbe-4d59-4b94-8ace-a7818665b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7c7ff3-c1d0-43c9-8ea5-03dea735ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load this object, we must simply run the notebook containing it:\n",
    "%run rod_EQS.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9c58f-59af-4f44-b55b-59d20964f505",
   "metadata": {},
   "source": [
    "# Maximum parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c1a502-db00-4c62-a54e-a3879a897b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max Denspt\n",
    "denspt = 12\n",
    "# Max number of neurons per layer:\n",
    "numNeurons = 100\n",
    "# Max number of layers:\n",
    "numLayers = 50\n",
    "# Maximum Batch size:\n",
    "batch_size = 25000\n",
    "\n",
    "# Other parameters do not have such a clear impact in the usage of resources. For instance, tanh and mish both rely\n",
    "# on exponents to perform calculations, so they use more resources than ReLU, but it is not clear which uses more.\n",
    "# Therefore, they are selected based on experience.\n",
    "\n",
    "# Activation function\n",
    "activator = 'tanh'\n",
    "# Loss function\n",
    "loss = 'mse'\n",
    "# Optimizer\n",
    "optimizer = 'adam'\n",
    "# Initial learning rate\n",
    "initial_lr = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26cbd0d-dd29-4937-b4f8-b392f39c22c2",
   "metadata": {},
   "source": [
    "# Building of the testing and training grid:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "274aa01c-5f8b-4493-af20-d206c21c6305",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gridObj = SEQ.Grid(2,{'x':0,'t':1},[[[0,2],[0,10]]],12)\n",
    "train_gridObj = test_gridObj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa46f4-1d86-42ee-ab6c-6738c178b289",
   "metadata": {},
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed974915-3cc1-45cd-b658-8b651cfb952a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_n(n,x,t):\n",
    "  mu_n = (2*n+1)*np.pi/4\n",
    "  T_n =  np.exp(-t*(mu_n**2))\n",
    "  X_n = -np.cos(mu_n*x)*2.5/(mu_n**2)\n",
    "  return X_n*T_n\n",
    "\n",
    "depth = 100\n",
    "\n",
    "u_pred_Simb = (np.sum((np.array([u_n(n,test_gridObj.grid[:,0],test_gridObj.grid[:,1]) for n in range(depth)])),axis=0)+5)[:,None]\n",
    "valData = np.concatenate((test_gridObj.grid,u_pred_Simb),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346c7b2-cc6a-4df3-8421-b531467b0999",
   "metadata": {},
   "source": [
    "# Building equation Functionals, PDEs, Variables and Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2ffea6-95f5-4cfa-aa00-aadcd03e87a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Functionals, PDEs, variables, params = mySys.getPDEs(numNeurons,numLayers,\n",
    "                                                              activator)\n",
    "m = sn.SciModel(list(variables.values()),PDEs,loss,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e52ce66-4cf3-4462-b039-793f9ee8430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimlist, data = mySys.evalSystem(train_gridObj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36e0cd-580d-492e-9989-43afc066a85d",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ce0f8-a6eb-4a47-ab0c-395b72b2f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 100\n",
    "history = m.train(dimlist,data, epochs = int(number_of_epochs),verbose=1,\n",
    "                        batch_size=batch_size,learning_rate=initial_lr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49234cd0-4168-469f-b80b-86e2eb853132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no errors happen during training, the gridsearch will work using 1 worker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
